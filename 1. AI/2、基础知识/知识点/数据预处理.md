---
title: "数据预处理"
category: "AI"
tags: [矩阵, 训练, 降维]
created: "2026-02-13"
updated: "2026-02-13"
---

# 数据预处理

## **具体流程**

数据预处理的主要步骤分为四步：数据清理、数据集成、数据规约和数据变换。

1. Data cleaning
1. data integration
1. data statute
1. data transformation.
### **数据清理 Data cleaning：**

- 缺失值的处理 
- 删除变量：若变量的缺失率较高（大于80%），覆盖率较低，且重要性较低，可以直接将变量删除。
- 定值填充：工程中常见用-9999进行替代
- 均值填充/中位数填充
- 插值法填充
- 哑变量填充
- 模型填充：用回归，随机森林，决策树等对缺失值进行预测填充
- 实际应用：先用pandas.isnull.sum()检测出变量的缺失比例，考虑删除或者填充，若需要填充的变量是连续型，一般采用均值法和随机差值进行填充，若变量是离散型，通常采用中位数或哑变量进行填充
- 离群点处理：通过箱线图，分位点判断异常，或用聚类算法，丢弃小的、远的cluster 
- 如果不涉及到大量信息损失，可以删除或用中位数/均值替代异常点
- 如果想保留，可以决策树，其对异常点的鲁棒性好，也可以直接scaling
- 噪声处理 
- 对数据进行平滑处理
- 如果是信号处理，可以考虑signal reconstruction (encode + decode)
### **数据集成 Data integration：**

- 实体识别问题：识别出不同字段属于同一实体
- 冗余问题
- 数据值的冲突和处理
### **数据规约 Data statute：**

- 特征选择 
- 树模型的Gini指数：训练决策树模型，提取每个变量的重要度，即Gini指数进行排序
- 降维：PCA，signal representation，奇异值分解（一般用于稀疏矩阵）
### **数据变换 Data transformation：**

- 规范化处理 
- 数据缩放（**scaling**）：是将数据按比例缩放，使之落入一个小的特定区间，意义是：KNN、K-means和SVM 等距离算法受特征范围的影响最大，因为这些算法在**使用数据点之间的距离来确定它们的相似性。**
- 缩放之归一化****Normalization：****min-maxnormalization，用最大和最小值，放缩于0和1之间
- 缩放之标准化**Standardization**：zero-meannormalization（**z-score）. The mean of the attribute becomes zero and the resultant distribution has a unit standard deviation.**
- 两者对比： 
- Normalization is good to use when you know that the distribution of your data does not follow a Gaussian distribution. This can be useful in algorithms that do not assume any distribution of the data like K-Nearest Neighbors and Neural Networks.
- Standardization, on the other hand, can be helpful in cases where the data follows a Gaussian distribution. However, this does not have to be necessarily true. Also, unlike normalization, standardization does not have a bounding range. So, even if you have outliers in your data, they will not be affected by standardization.
- 离散化处理：分箱
- 稀疏化处理：有助于模型快速收敛