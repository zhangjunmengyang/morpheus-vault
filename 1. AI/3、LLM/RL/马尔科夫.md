---
title: "马尔科夫"
category: "AI"
tags: [LLM, Ray, 强化学习, 概率论, 矩阵]
created: "2026-02-13"
updated: "2026-02-13"
---

# 马尔科夫

# 平稳分布

举个例子：

![image](assets/CCh5dvFrMoMz2pxXUaNcxwufnBd.png)

状态转移矩阵：

设初始状态分布为  ，表示初始时刻状态  的概率为  ，状态  的概率为  ，状态  的概率为  。那么经过一步状态转移或者说一次状态迭代后，新的状态分布  可通过初始状态分布  与状态转移矩阵  相乘得到。

多次相乘后用程序模拟一下，结果如下：

```
import numpy as np
pi_0 = np.array([[0.15,0.62,0.23]])
P = np.array([[0.5,0.4,0.1],[0.2,0.6,0.2],[0.05,0.45,0.5]])
for i in range(1,10+1):
    pi_0 = pi_0.dot(P)
    print(f"第{i}次迭代后状态分布为：{np.around(pi_0,3)}")
```

```
第1次迭代后状态分布为：[[0.21  0.536 0.254]]
第2次迭代后状态分布为：[[0.225 0.52  0.255]]
第3次迭代后状态分布为：[[0.229 0.517 0.254]]
第4次迭代后状态分布为：[[0.231 0.516 0.253]]
第5次迭代后状态分布为：[[0.231 0.516 0.253]]
第6次迭代后状态分布为：[[0.231 0.516 0.253]]
第7次迭代后状态分布为：[[0.232 0.516 0.253]]
第8次迭代后状态分布为：[[0.232 0.516 0.253]]
第9次迭代后状态分布为：[[0.232 0.516 0.253]]
第10次迭代后状态分布为：[[0.232 0.516 0.253]]

```

可以看出，经过多次迭代后，**状态分布逐渐趋于稳定，并最终收敛到一个固定的分布**，即  。 把初始状态分布改成其他的任意值，例如  ，再运行代码 1 ，结果如代码 3 所示，状态分布依然会收敛到同一个固定的分布  。

也就是说，无论初始状态分布如何变化，经过多次迭代后，状态分布最终都会收敛到同一个固定的分布  。 这个固定的分布就称为 **平稳分布**（  ），通常用   表示，表示在策略  指导下，从任意初始状态  开始，经过足够长时间后，系统处于状态  的概率。

简单来说，它描述了系统在长期运行后，处于各状态的概率分布。

## 条件

需要注意的是，平稳分布的存在是有前提条件的，必须是遍历（  ）的马尔可夫过程，遍历包含两个性质：

- 不可约（  ）：不可约表示从任意状态出发，都有可能到达其他任意状态，有时也叫作**连通性**（  ）
- 非周期（  ）：非周期表示系统**不会陷入某种固定的循环模式**。
**而通常情况下，强化学习中的马尔可夫过程都是遍历的（ergodic），因此平稳分布是存在的。**

## 证明

本节内容主要从数学上来推导说明为什么平稳分布是存在的，换句话说为什么马尔可夫过程在长期运行后会收敛到一个固定的分布，即“不动点”

用矩阵的语言来表示，就是转移算子  存在一个不动点

两边转置，并结合矩阵转置的性质  ，可得式

由于状态转移矩阵本身就是一个随机矩阵，即满足式

用矩阵语言来表示，就是每一列的元素和为1，且每个元素都非负

回顾线性代数相关知识，对于方阵  ，如果存在一个非零向量  和一个标量  ，使得  ，那么就称  是矩阵  的一个特征值，v 是对应的右特征向量。同时，也会有左特征向量的概念，即如果存在一个非零向量  和一个标量  ，使得  ，u 是对应的左特征向量。左特征向量和右特征向量表达的其实是同一个概念，只是左特征向量是行向量，右特征向量是列向量。

可以看出，向量  是矩阵  的右特征向量，且对应的特征值为1。因此，矩阵  也必然存在对应的左特征向量  ，也就是我们要找的平稳分布。
