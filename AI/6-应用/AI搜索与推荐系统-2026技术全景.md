---
title: "搜索与推荐系统 — 2026 技术全景与面试深度笔记"
date: 2026-02-21
tags: [面试武器, 搜索, 推荐, ranking, retrieval, embedding, 深度笔记]
domain: ai/application/search-rec
vault_note_id: 19
series: "面试武器库"
brief: "AI 搜索与推荐系统 2026 面试武器库：精排/粗排/召回/重排全链路技术深度笔记；Embedding/Ranking/CTR/多模态推荐；含实战面试高频题。"
status: active
rating: ★★★★★
archived_by: librarian
archived_date: 2026-02-21
---

# 搜索与推荐系统 — 2026 技术全景与面试深度笔记

> 搜索是"用户知道要什么"，推荐是"系统知道用户要什么"。两者共享召回-粗排-精排-重排的漏斗架构，但目标函数和交互模式截然不同。在 LLM 时代，两者正在加速融合。

---

## 一、经典漏斗架构

### 1.1 四阶漏斗

```
全量物料（千万~十亿级）
    ↓ 召回 Recall（多路）
候选集（万级）
    ↓ 粗排 Pre-Ranking
候选集（千级）
    ↓ 精排 Ranking
候选集（百级）
    ↓ 重排 Re-Ranking
最终展示（十~几十）
```

**为什么要漏斗？** 算力约束。精排模型算一个 item 可能要 1ms，十亿 item 全算需要 11.5 天。漏斗用简单模型快速缩小候选集，再用复杂模型精细排序。

**面试高频追问**：为什么不直接端到端？
- 延迟约束：在线系统 P99 < 100ms，单模型无法处理十亿候选
- 特征复杂度：精排用交叉特征（用户×物品），召回用独立特征
- 工程可维护性：各阶段独立迭代，AUC 改进可归因

### 1.2 各阶段核心指标

| 阶段 | 核心指标 | 延迟约束 | 模型复杂度 |
|------|----------|----------|-----------|
| 召回 | Recall@K, 覆盖率 | <10ms | 低（双塔/ANN）|
| 粗排 | GAUC, 排序一致性 | <5ms/item | 中（轻量网络）|
| 精排 | AUC, GAUC, NDCG | <10ms/item | 高（交叉网络）|
| 重排 | 列表级指标, 多样性 | <20ms | 高（序列模型）|

---

## 二、召回（Retrieval）

### 2.1 多路召回策略

**为什么多路？** 单路容易陷入局部最优。多路召回 = 对冲 + 互补。

1. **协同过滤路**：ItemCF / UserCF / Swing（淘宝主力）
2. **向量路**：双塔模型 → FAISS/HNSW 检索
3. **图路**：GraphSAGE / PinSage / 二部图游走
4. **热门/地域/新品路**：规则补充，保证冷启动覆盖
5. **LLM 路**（2025+）：用 LLM 直接生成 item ID 或 query 改写后召回

### 2.2 双塔模型（Two-Tower / DSSM）

```
User Tower              Item Tower
[user_id, age, ...]    [item_id, title, ...]
     ↓ DNN                  ↓ DNN
  user_emb (128d)      item_emb (128d)
          \                /
           cosine/inner product → score
```

**核心优势**：user_emb 和 item_emb 独立计算，item_emb 可离线建索引。在线只需 user_emb → ANN 查询，延迟 <5ms。

**关键技巧**：
- **负采样策略**：随机负采样 → batch 内负采样 → hard negative mining（精排模型挖掘）
- **温度系数**：score = cos(u, i) / τ，τ 越小区分度越高但训练越不稳定
- **多目标**：point-wise（BCE） vs. pair-wise（BPR） vs. list-wise（softmax CE）

**面试陷阱**：双塔模型为什么不如精排模型？
→ 双塔在 inference 时 user 和 item 没有交互（早期交互 vs 晚期交互），无法建模交叉特征（如"这个用户对红色商品的偏好"）。这是精排模型（如 DIN/DIEN）的核心优势。

### 2.3 ANN（Approximate Nearest Neighbor）

| 方法 | 原理 | 优缺点 |
|------|------|--------|
| **Flat (Brute Force)** | 全量计算 | 精确但慢 |
| **IVF (Inverted File)** | K-means 聚类 + 倒排 | 需要 nprobe 调参 |
| **HNSW** | 分层小世界图 | 内存大但速度快 |
| **PQ (Product Quantization)** | 向量压缩 + 查表 | 节省内存但精度损失 |
| **IVF-PQ** | IVF + PQ 组合 | 工业界主流 |
| **ScaNN** | 各向异性量化 | Google 方案，精度高 |

**面试追问**：HNSW 为什么快？
→ Skip-list 思想 + 小世界图。上层（稀疏）负责长距离跳转，下层（稠密）负责局部精搜。搜索从最高层开始，逐层下沉，每层贪心寻找最近邻。时间复杂度 O(log N)。

**FAISS vs Milvus vs Pinecone**：
- FAISS：Facebook 开源，C++ 核心，单机性能王
- Milvus：分布式向量数据库，支持混合搜索（标量+向量）
- Pinecone：全托管 SaaS，开箱即用但贵
- Qdrant：Rust 写的，内存效率好，2025 年增长最快

### 2.4 图召回

**PinSage**（Pinterest, KDD 2018）：
- 在物品关系图上做 GraphSAGE
- 采样策略：random walk 而非全邻居，降低计算量
- 生产规模：30 亿节点、180 亿边

**面试追问**：图召回 vs 向量召回的优劣？
→ 图召回能捕捉高阶协同信号（A→B→C 的传递关系），向量召回更灵活（可融合多模态特征）。两者互补不替代。

---

## 三、排序（Ranking）

### 3.1 特征工程（仍然重要！）

**2026 年的现实**：尽管深度学习自动学特征，手工特征工程依然贡献 30-50% 的增量。

核心特征类型：
1. **用户画像**：年龄/性别/城市/消费力/活跃度
2. **物品属性**：类目/品牌/价格段/上架时间
3. **上下文**：时间/设备/位置/页面位置
4. **交叉统计**：用户×类目 CTR、用户×品牌 CVR（最有价值！）
5. **序列特征**：最近 N 次点击/购买的 item embedding 均值
6. **实时特征**：当前 session 行为（实时更新，延迟 < 1s）

### 3.2 经典精排模型演进

```
LR → GBDT+LR → Wide&Deep → DeepFM → DCN → DIN → DIEN → DLRM → AutoInt → FinalMLP → GDCN
```

**Wide & Deep**（Google, 2016）：
- Wide 部分：手工交叉特征 + LR，负责记忆（memorization）
- Deep 部分：embedding + MLP，负责泛化（generalization）
- 面试要点：为什么不直接全用 Deep？→ Deep 对高频共现模式的记忆不如显式交叉

**DeepFM**（2017）：
- 用 FM 层替代 Wide 的手工交叉，自动学二阶交叉
- FM 的数学：$\hat{y} = w_0 + \sum w_i x_i + \sum\sum \langle v_i, v_j \rangle x_i x_j$
- 二阶交叉的计算技巧：$O(kn)$ 而非 $O(kn^2)$

**DCN / DCN v2**（Google, 2017/2021）：
- Cross Network：显式建模高阶特征交叉
- DCN v2 用矩阵替代向量，表达能力更强
- $x_{l+1} = x_0 \cdot (W_l x_l + b_l) + x_l$（残差连接）

**DIN**（阿里, 2018）：
- 核心创新：Attention 机制建模用户历史行为与候选 item 的相关性
- 不同于平均池化，DIN 对每个候选 item 计算不同的注意力权重
- Activation Unit：concat(user_behavior, candidate) → MLP → attention weight
- **面试杀手锏**：DIN 证明了"用户兴趣是多峰的"——用户喜欢手机≠喜欢手机壳

**DIEN**（阿里, 2019）：
- 在 DIN 基础上加入 GRU 建模兴趣**演化**（evolution）
- 辅助 loss：用下一次点击监督 GRU 隐状态
- AUGRU：用 attention score 门控 GRU 更新，让 GRU 只关注与候选相关的兴趣演化

### 3.3 多目标优化（Multi-Task Learning）

**为什么多目标？** 业务目标不是单一的。CTR 高不代表 CVR 高，CVR 高不代表 GMV 高。

**ESMM**（阿里, 2018）：
- $p(CVR) = p(CTR) \times p(CVR|CTR)$ — 用曝光样本训练 CTR，避免 CVR 的样本选择偏差
- 两个塔共享 embedding，梯度互相传导

**MMoE**（Google, 2018）：
- 多个 Expert 网络 + 每个 Task 一个 Gating 网络
- 各 Task 按需混合 Expert 输出
- 比 Shared-Bottom 灵活，比独立模型参数少

**PLE**（腾讯, 2020）：
- 在 MMoE 基础上区分 shared expert 和 task-specific expert
- 多层抽取网络，解决 expert 坍塌（所有 gate 选同一个 expert）问题

**面试追问**：多目标之间冲突怎么办？
→ ① Pareto 优化（MOO）② 动态权重调整（Uncertainty Weighting / GradNorm）③ 业务层面用公式融合：score = CTR^α × CVR^β × bid^γ

### 3.4 样本与 Bias

**位置偏差（Position Bias）**：
- 用户倾向于点击排在前面的结果，与相关性无关
- 解法：训练时加 position embedding，inference 时去掉或设为固定值
- PAL（Position-Aware Learning）：显式建模 P(click) = P(examine) × P(relevant)

**选择偏差（Selection Bias）**：
- CVR 模型只在点击样本上训练 → 分布偏移
- 解法：ESMM（全空间建模）、IPS（逆倾向加权）

**曝光偏差**：
- 未曝光的 item 没有反馈 → 不等于不相关
- 解法：exploration（UCB / Thompson Sampling / ε-greedy）

---

## 四、重排（Re-Ranking）

### 4.1 为什么需要重排？

精排是 point-wise 打分（独立评估每个 item），但用户看到的是一个**列表**。列表级别的优化需要考虑：
- **多样性**：不能全是同类商品
- **新鲜度**：不能全是已看过的
- **上下文效应**：item A 和 B 一起展示的效果 ≠ A 单独 + B 单独
- **广告插入**：自然结果和广告的混排

### 4.2 主要方法

**MMR（Maximal Marginal Relevance）**：
- 贪心选择：maximize λ × relevance - (1-λ) × max_similarity_to_selected
- 简单有效，但贪心不是全局最优

**PRM（Personalized Re-ranking Model, 阿里 2019）**：
- Transformer encoder 对精排输出列表建模
- 考虑 item 之间的上下文关系
- 输入：精排 score + item 特征 + 位置特征

**DLCM / SetRank**：
- 用 RNN/Attention 对整个候选列表编码
- 直接优化列表级指标（NDCG）

**DPP（Determinantal Point Process）**：
- 数学上优雅的多样性建模
- 核矩阵 L：$L_{ij} = q_i \cdot \phi_i^T \phi_j \cdot q_j$（质量 × 相似度）
- 采样概率正比于子集的行列式 → 自动惩罚相似 items

---

## 五、Embedding 技术深度

### 5.1 从 Word2Vec 到 Item2Vec

**Word2Vec 双模型**：
- CBOW：上下文预测中心词
- Skip-gram：中心词预测上下文
- 负采样：将 softmax 简化为二分类

**Item2Vec / Airbnb Embedding**（KDD 2018）：
- 将用户行为序列类比为"句子"，item 类比为"词"
- Airbnb 创新：① booking session 和 listing session 分别建模 ② 加入 listing type 的全局 embedding 解决冷启动

### 5.2 对比学习在推荐中的应用

**SimCLR → SGL → CL4Rec**：
- 数据增强：随机 mask/crop/reorder 用户行为序列
- 对比 loss：同一用户不同增强 → 正对，不同用户 → 负对
- 解决数据稀疏和长尾问题

### 5.3 LLM 时代的 Embedding

**E5 / GTE / BGE（2023-2024）**：
- 用 LLM 生成的数据训练 embedding 模型
- 支持 instruction-aware embedding（不同任务用不同 instruction）
- BGE-M3：多语言、多粒度、多功能

**2025-2026 趋势**：
- **Matryoshka Representation Learning**（MRL）：一个模型多种维度，按需截断
- **Late Interaction**（ColBERT 模式）：token-level 匹配，精度高但成本大
- **Embedding 量化**：int8/binary embedding，存储和计算减少 32x

---

## 六、LLM × 搜索推荐（2025-2026 前沿）

### 6.1 LLM as Ranker

**直接用 LLM 排序**：
- 给 LLM 一组候选，让它排序
- 方法：point-wise（逐个打分）/ pair-wise（两两比较）/ list-wise（直接排序）
- 问题：位置偏差（LLM 倾向于把第一个排在前面）、成本高、延迟不可接受

**RankGPT**（2023）：
- Sliding window + bubble sort 策略解决 list-wise 位置偏差
- 在 TREC/BEIR 上超过传统 cross-encoder

**RankLLaMA / RankZephyr**：
- 用排序数据 finetune 开源 LLM
- 比 prompt-based 方法更稳定，延迟更低

### 6.2 LLM as Feature Extractor

- 用 LLM 对 item 标题/描述生成增强特征
- KAR（Knowledge-Augmented Recommendation）：LLM 生成用户偏好解释 → embedding → 特征输入排序模型
- 离线生成，不影响在线延迟

### 6.3 Generative Retrieval

**DSI（Differentiable Search Index）**：
- 把索引存在 Transformer 的参数里
- query → Transformer → 直接生成 docID
- 问题：索引更新需要重训练

**TIGER / GENRE**：
- 用语义 ID（hierarchical clustering）替代原始 docID
- beam search 生成 ID 序列

### 6.4 对话式推荐

- 多轮对话澄清用户意图
- LLM + 推荐系统的闭环：用户说"便宜点的" → 调整价格区间 → 重新召回排序
- 2026 趋势：Agent + 推荐（自主决定何时追问、何时推荐）

---

## 七、冷启动

### 7.1 用户冷启动

- **兴趣探索**：新用户前 N 次展示多样化内容，用 bandit 策略快速收敛
- **画像迁移**：用注册信息（年龄/性别/地域）匹配相似用户群的行为分布
- **LLM 对话**：直接问用户喜好（"你喜欢什么类型的电影？"），2025+ 新趋势

### 7.2 物品冷启动

- **内容特征**：用标题/图片/描述的 embedding 替代行为 embedding
- **元学习（MAML）**：few-shot 快速适应新 item
- **流量倾斜**：给新 item 额外曝光机会（explore-exploit trade-off）

### 7.3 系统冷启动

- 无历史数据，只能靠内容特征 + 人工规则
- 种子用户行为收集 → 快速过渡到协同过滤

---

## 八、在线学习与实时推荐

### 8.1 为什么需要在线学习？

- 用户兴趣快速变化（"刚搜了机票"→ "现在想看酒店"）
- 新 item 不断上架
- 离线模型有 day-level 延迟

### 8.2 实现架构

```
用户行为 → Kafka → Flink（特征计算）→ Feature Store
                                         ↓
                            Model Serving（精排）
                                         ↑
离线训练 → 增量训练 → Model Registry → 在线加载
```

**关键组件**：
- **Feature Store**：统一在线/离线特征计算，避免 training-serving skew
- **增量训练**：不从头训练，基于新数据微调（warm start）
- **AB 实验**：分流 + 指标监控 + 自动回滚

### 8.3 实时特征

- **用户实时行为序列**：最近 N 次点击/购买
- **实时统计**：过去 1 小时的 item CTR
- **上下文**：当前 session 行为、搜索 query

**面试追问**：训练用离线特征，serving 用实时特征，会有 skew 吗？
→ 会。解法：① Feature Store 统一逻辑 ② 训练时也用实时特征回放 ③ 监控特征分布漂移

---

## 九、评估指标

### 9.1 离线指标

| 指标 | 公式/说明 | 适用场景 |
|------|-----------|----------|
| AUC | ROC 曲线下面积 | CTR 预估 |
| GAUC | 按用户分组的 AUC 均值 | 比 AUC 更贴近线上效果 |
| NDCG@K | 考虑位置的排序质量 | 排序评估 |
| MAP | 平均精度均值 | 搜索评估 |
| MRR | 第一个相关结果的排名倒数 | QA/搜索 |
| Recall@K | Top-K 中相关 item 比例 | 召回评估 |
| HitRate@K | 至少命中一个相关 item | 召回评估（更宽松）|
| Diversity | intra-list diversity | 列表多样性 |
| Coverage | 被推荐过的 item 比例 | 长尾覆盖 |

### 9.2 在线指标

- **CTR / CVR / GMV**：业务核心
- **停留时长**：信息流场景
- **用户留存率**：长期价值
- **DAU / MAU**：平台健康度

**面试追问**：离线 AUC 涨了但线上 CTR 没涨，为什么？
→ ① 离线数据有选择偏差 ② 特征 skew（训练-serving 不一致）③ 在线环境有位置偏差等因素 ④ AUC 衡量排序能力，线上 CTR 还受流量分布影响

---

## 十、搜索引擎专题

### 10.1 倒排索引

```
Term → [DocID: tf, positions]

"深度学习" → [(doc1, 3, [5,12,89]), (doc7, 1, [42])]
"推荐系统" → [(doc1, 2, [1,15]), (doc3, 5, [3,7,18,25,60])]
```

**面试追问**：倒排索引如何支持布尔查询？
→ AND = 交集（跳表加速），OR = 并集，NOT = 差集。跳表将交集从 O(n+m) 优化到 O(√(nm))。

### 10.2 BM25

$$BM25(q, d) = \sum_{t \in q} IDF(t) \cdot \frac{tf(t,d) \cdot (k_1 + 1)}{tf(t,d) + k_1 \cdot (1 - b + b \cdot \frac{|d|}{avgdl})}$$

- **IDF**：逆文档频率，罕见词权重高
- **tf 饱和**：k1 控制词频增益的衰减速度
- **长度归一化**：b 控制文档长度的惩罚程度
- 默认参数：k1=1.2, b=0.75

### 10.3 Learning to Rank（LTR）

**三种范式**：
- **Point-wise**：回归/分类，预测绝对相关性。简单但忽略排序关系
- **Pair-wise**：RankNet / LambdaRank / LambdaMART。优化 pair 的相对顺序
- **List-wise**：ListNet / ListMLE / SoftRank。直接优化 NDCG 等列表指标

**LambdaMART**（微软, 2010）：
- GBDT + lambda 梯度
- 至今仍是 LTR 最强 baseline 之一
- XGBoost/LightGBM 实现

**面试杀手锏**：为什么 LambdaMART 至今不死？
→ ① 特征工程友好，可解释性强 ② 对噪声标签鲁棒 ③ 训练快，不需要 GPU ④ 在文档级特征丰富的场景（如 Bing 搜索）仍然有竞争力

### 10.4 Neural IR（2024-2026）

**Cross-Encoder**：
- query 和 document 拼接后过 BERT
- 精度最高但速度慢（不能预计算 document embedding）
- 适合 re-ranking 阶段

**ColBERT**：
- Late Interaction：query token 和 document token 分别编码，用 MaxSim 匹配
- 精度接近 Cross-Encoder，速度接近 Bi-Encoder
- ColBERT v2：残差压缩，索引大小减少 6-10x

**SPLADE**：
- 学习稀疏表示，可直接用倒排索引
- 结合了 neural 的语义理解和 BM25 的高效检索

---

## 十一、工业界案例

### 11.1 阿里（淘宝推荐）

- 召回：Swing（图方法） + 双塔 + TDM（树模型）
- 精排：DIEN → BST（Behavior Sequence Transformer）→ SIM（长序列，10000+ 行为）
- 多目标：ESMM → DBMTL
- 特色：全链路优化（MLR + DIN + DIEN + SIM + CAN）

### 11.2 字节（抖音推荐）

- 召回：多路（双塔+兴趣图谱+热门+地域）
- 精排：PPNet（Parameter Personalized Net）— 用用户特征生成网络权重
- 特色：实时性极强（秒级特征更新），exploration 做得好

### 11.3 美团（搜索+推荐）

- LBS（Location-Based Service）场景的特殊性：地理围栏、配送时效
- 多业务融合排序：外卖+酒店+打车，不同品类的排序目标不同
- 特色：上下文特征（时间/天气/位置）极其重要

### 11.4 Google（YouTube 推荐）

- 经典论文：Deep Neural Networks for YouTube Recommendations（2016）
- 两阶段：候选生成（DNN + softmax over items） + 排序
- 工程优化：serving 时用 user embedding 查最近邻
- 后续：MMoE 多目标、强化学习长期优化

---

## 十二、2026 趋势

1. **LLM-native 推荐**：从"LLM 辅助"到"LLM 原生"，直接用 LLM 理解用户意图并生成推荐
2. **多模态推荐**：图片/视频/文本联合 embedding，CLIP 在电商搜索的应用
3. **因果推断去偏**：从关联到因果，IPS/DR/doubly robust 方法工业化
4. **隐私保护推荐**：联邦学习 + 差分隐私，苹果 on-device 推荐
5. **Agent × 推荐**：推荐系统作为 Agent 的工具，Agent 主动管理用户信息获取和推荐时机
6. **端上推荐**：小模型部署到手机端，减少延迟和隐私泄露

---

## 十三、面试高频题精选

### Q1: 推荐系统和搜索系统的核心区别？
→ 搜索：用户有明确 query，目标是相关性排序。推荐：无显式 query，目标是挖掘潜在兴趣。搜索更重 precision，推荐更重 recall + serendipity。

### Q2: 双塔模型和交叉模型各自的适用场景？
→ 双塔适合召回（需要 ANN 索引），交叉模型适合精排（需要 user-item 交互特征）。不能反过来：交叉模型无法建索引，双塔精度不够精排。

### Q3: 如何评估推荐系统的公平性？
→ ① 曝光公平（长尾 item 是否有机会）② 用户公平（不同群体的推荐质量一致）③ 供给侧公平（商家/创作者的曝光分配）。度量：Gini 系数、group-wise AUC 差异。

### Q4: 负采样策略对模型效果的影响？
→ 随机负采样：简单但 easy negative 太多，模型学不到有区分度的表示。Hard negative（从精排候选中挖掘）：更有信息量，但太难的负例可能是误标注。最佳实践：混合策略，70% 随机 + 30% hard。

### Q5: 推荐系统如何处理实时性？
→ 四层实时化：① 特征实时（Flink 流计算）② 模型实时（在线学习/增量训练）③ 索引实时（向量索引热更新）④ 策略实时（实时 AB 决策）。工程挑战：训练-serving 一致性、特征回放、实时监控。

### Q6: 大规模推荐系统的工程挑战？
→ ① 特征 serving：Feature Store 毫秒级读取 ② 模型 serving：GPU inference 多模型编排 ③ 数据一致性：训练和 serving 的特征必须一致 ④ AB 实验：分流正交性、长期效果评估 ⑤ 监控：指标异常实时报警。

---

_Vault 笔记 #19 | 搜索与推荐系统 | 首次创建 2026-02-21 | 面试武器库系列_


## See Also

- [[Career/目录|Career MOC]] — 职业发展知识域索引
- [[AI面试速查手册|AI 面试速查手册]] — 速查层（面试武器系列同伴）
- [[AI/6-应用/RAG/_MOC|RAG MOC]] — 检索增强生成（搜索系统的 AI 升级方向）
- [[向量数据库选型|向量数据库选型]] — 向量检索基础设施（搜索推荐共用）
- [[Projects/LLM-Recommendation/推荐系统|推荐系统]] — Vault 内已有推荐系统基础笔记，本文是其面试升级版

---

## See Also（馆长补充）

- [[Career/目录|Career MOC]] — 职业发展知识域全索引
- [[AI面试速查手册|AI 面试速查手册]] — 同系列速查版
- [[AI/6-应用/RAG/_MOC|RAG MOC]] — 检索增强生成（搜索系统 AI 升级方向）
- [[向量数据库选型|向量数据库选型]] — 向量检索基础设施（搜索推荐共用）
- [[Projects/LLM-Recommendation/推荐系统|推荐系统]] — Vault 内已有推荐系统基础笔记，本文是其面试升级版
