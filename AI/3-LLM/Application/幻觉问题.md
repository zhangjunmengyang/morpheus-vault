---
title: LLM å¹»è§‰é—®é¢˜ï¼šæ·±åº¦é¢è¯•ç¬”è®°
brief: LLMå¹»è§‰çš„ç³»ç»Ÿæ€§åˆ†æï¼šäº‹å®æ€§vså¿ å®æ€§/å†…åœ¨vså¤–åœ¨çš„åˆ†ç±»ä½“ç³»ã€å…­å¤§æ ¹å› (è®­ç»ƒæ•°æ®å™ªéŸ³/Exposure Bias/Softmaxè¿‡åº¦è‡ªä¿¡/çŸ¥è¯†è¾¹ç•Œæ¨¡ç³Š/è§£ç ç­–ç•¥/æ³¨æ„åŠ›å±€é™)ã€æ£€æµ‹æ–¹æ³•(SelfCheckGPT/äº‹å®æ ¸æŸ¥Pipeline/NLI/KGéªŒè¯)ã€ç¼“è§£ç­–ç•¥(RAG/Self-RAG/CoT/RLHF/DPO/å—é™è§£ç )ã€ä¸å¯¹é½å…³ç³»(Sycophancy/å¯¹é½ç¨)ã€è¯„æµ‹åŸºå‡†(TruthfulQA/HaluEval/FActScore)ã€‚æ ¸å¿ƒæ´å¯Ÿï¼šå®Œå…¨æ¶ˆé™¤å¹»è§‰ç­‰ä»·äºå®Œç¾ä¸–ç•ŒçŸ¥è¯†è¡¨ç¤ºï¼ŒåŠ¡å®æ–¹å‘æ˜¯è®©æ¨¡å‹'çŸ¥é“è‡ªå·±ä¸çŸ¥é“ä»€ä¹ˆ'ã€‚
date: 2026-02-14
updated: 2026-02-22
tags:
  - hallucination
  - safety
  - evaluation
  - interview
type: survey
domain: ai/llm/safety
status: review
dikw: K
sources:
  - Hallucination ç»¼è¿° â€” Huang et al. arXiv:2311.05232
  - TruthfulQA â€” Lin et al. arXiv:2109.07958
  - RAG ç¼“è§£å¹»è§‰ â€” Lewis et al. (RETRO) arXiv:2005.11401
  - Self-RAG â€” Asai et al. arXiv:2310.11511
  - FActScore â€” Min et al. arXiv:2305.14251
  - SelfCheckGPT â€” Manakul et al. arXiv:2303.08896
  - HaluEval â€” Li et al. arXiv:2305.11747
  - DPO â€” Rafailov et al. arXiv:2305.18290
related:
  - "AI å®‰å…¨ä¸å¯¹é½"
  - "[[AI/5-AI å®‰å…¨/å¯¹é½æŠ€æœ¯æ€»ç»“|å¯¹é½æŠ€æœ¯æ€»ç»“]]"
  - "[[AI/3-LLM/Application/RAG/RAG åŸç†ä¸æ¶æ„|RAG åŸç†ä¸æ¶æ„]]"
  - "[[AI/2-Agent/Fundamentals/ReAct ä¸ CoT|ReAct ä¸ CoT]]"
  - "LLM è¯„æµ‹ä½“ç³»"
---

# LLM å¹»è§‰é—®é¢˜ï¼šæ·±åº¦é¢è¯•ç¬”è®°

> å¹»è§‰ï¼ˆHallucinationï¼‰æ˜¯å¤§è¯­è¨€æ¨¡å‹æœ€æ ¸å¿ƒçš„å®‰å…¨ä¸å¯é æ€§é—®é¢˜ä¹‹ä¸€ã€‚æ¨¡å‹ç”Ÿæˆçš„å†…å®¹çœ‹ä¼¼æµç•…è‡ªä¿¡ï¼Œå®åˆ™ä¸äº‹å®ä¸ç¬¦æˆ–ä¸è¾“å…¥ä¸Šä¸‹æ–‡çŸ›ç›¾ã€‚æœ¬æ–‡ä»å®šä¹‰åˆ†ç±»ã€æ ¹å› åˆ†æã€æ£€æµ‹æ–¹æ³•ã€ç¼“è§£ç­–ç•¥ã€å¯¹é½å…³ç³»ã€è¯„æµ‹åŸºå‡†ã€å·¥ä¸šå®è·µä¸ƒä¸ªç»´åº¦è¿›è¡Œç³»ç»Ÿæ¢³ç†ï¼Œå¹¶é™„é¢è¯•é«˜é¢‘é¢˜ã€‚

---

## 1. å¹»è§‰çš„å®šä¹‰ä¸åˆ†ç±»

### 1.1 ä»€ä¹ˆæ˜¯å¹»è§‰

å¹»è§‰ï¼ˆHallucinationï¼‰æŒ‡è¯­è¨€æ¨¡å‹ç”Ÿæˆçš„å†…å®¹**ä¸å¿ å®äºæºè¾“å…¥ï¼ˆfaithfulnessï¼‰**æˆ–**ä¸ç¬¦åˆå¯éªŒè¯çš„ç°å®ä¸–ç•Œäº‹å®ï¼ˆfactualityï¼‰**ã€‚è¿™ä¸ªæœ¯è¯­å€Ÿè‡ªå¿ƒç†å­¦â€”â€”å°±åƒäººç±»åœ¨æ²¡æœ‰å¤–éƒ¨åˆºæ¿€çš„æƒ…å†µä¸‹äº§ç”Ÿæ„ŸçŸ¥ä½“éªŒä¸€æ ·ï¼ŒLLM åœ¨æ²¡æœ‰å……åˆ†è¯æ®æ”¯æ’‘çš„æƒ…å†µä¸‹"å‡­ç©ºæé€ "ä¿¡æ¯ã€‚

å…³é”®ç‰¹å¾ï¼š
- **è¡¨é¢æµç•…æ€§**ï¼šå¹»è§‰å†…å®¹åœ¨è¯­æ³•å’Œé£æ ¼ä¸Šé€šå¸¸æ— æ‡ˆå¯å‡»ï¼Œå¾ˆéš¾é€šè¿‡é˜…è¯»ç›´è§‰å‘ç°
- **é«˜ç½®ä¿¡åº¦**ï¼šæ¨¡å‹åœ¨ç”Ÿæˆé”™è¯¯å†…å®¹æ—¶å¾€å¾€è¡¨ç°å‡ºä¸æ­£ç¡®å†…å®¹ç›¸åŒçš„"è‡ªä¿¡"
- **ééšæœºæ€§**ï¼šå¹»è§‰ä¸æ˜¯éšæœºå™ªå£°ï¼Œè€Œæ˜¯æ¨¡å‹åŸºäºè®­ç»ƒåˆ†å¸ƒä¸­çš„ç»Ÿè®¡æ¨¡å¼åšå‡ºçš„"åˆç†ä½†é”™è¯¯"çš„æ¨æ–­

### 1.2 äº‹å®æ€§å¹»è§‰ vs å¿ å®æ€§å¹»è§‰

è¿™æ˜¯æœ€ç»å…¸çš„äºŒåˆ†æ³•ï¼Œç”± Maynez et al. (2020) åœ¨æ‘˜è¦ç”Ÿæˆä»»åŠ¡ä¸­é¦–æ¬¡ç³»ç»Ÿæå‡ºï¼š

#### äº‹å®æ€§å¹»è§‰ï¼ˆFactuality Hallucinationï¼‰

æ¨¡å‹ç”Ÿæˆçš„å†…å®¹ä¸**å¯éªŒè¯çš„ç°å®ä¸–ç•ŒçŸ¥è¯†**ç›¸çŸ›ç›¾ã€‚

| å­ç±»å‹ | å®šä¹‰ | ç¤ºä¾‹ |
|--------|------|------|
| äº‹å®é”™è¯¯ | ç”Ÿæˆçš„äº‹å®é™ˆè¿°ä¸çœŸå®ä¸–ç•Œä¸ç¬¦ | "çˆ±å› æ–¯å¦äº1921å¹´è·å¾—è¯ºè´å°”åŒ–å­¦å¥–"ï¼ˆå®é™…æ˜¯ç‰©ç†å­¦å¥–ï¼‰ |
| å®ä½“æ··æ·† | å°†ä¸åŒå®ä½“çš„å±æ€§é”™è¯¯ç»„åˆ | "é©¬æ–¯å…‹åˆ›åŠäº†äºšé©¬é€Š"ï¼ˆå®é™…æ˜¯è´ç´¢æ–¯ï¼‰ |
| æ—¶é—´é”™ä½ | å°†äº‹ä»¶æ”¾åœ¨é”™è¯¯çš„æ—¶é—´èƒŒæ™¯ä¸‹ | "GPT-4 äº 2021 å¹´å‘å¸ƒ"ï¼ˆå®é™…æ˜¯ 2023 å¹´ï¼‰ |
| æ•°å€¼æé€  | ç¼–é€ å…·ä½“çš„æ•°å­—æˆ–ç»Ÿè®¡æ•°æ® | "è¯¥ç ”ç©¶æ¶‰åŠ 15,234 åå—è¯•è€…"ï¼ˆå®Œå…¨è™šæ„çš„æ•°å­—ï¼‰ |
| å¼•ç”¨è™šæ„ | ç¼–é€ ä¸å­˜åœ¨çš„è®ºæ–‡ã€ä¹¦ç±æˆ–å¼•ç”¨ | è™šæ„ä¸€ç¯‡çœ‹ä¼¼åˆç†çš„ arXiv è®ºæ–‡åŠå…¶ä½œè€… |

#### å¿ å®æ€§å¹»è§‰ï¼ˆFaithfulness Hallucinationï¼‰

æ¨¡å‹ç”Ÿæˆçš„å†…å®¹ä¸**ç»™å®šçš„è¾“å…¥æºï¼ˆsource inputï¼‰**ä¸ä¸€è‡´ã€‚å¸¸è§äºæœ‰æ¡ä»¶ç”Ÿæˆä»»åŠ¡ï¼ˆæ‘˜è¦ã€ç¿»è¯‘ã€RAG é—®ç­”ç­‰ï¼‰ã€‚

| å­ç±»å‹ | å®šä¹‰ | ç¤ºä¾‹ |
|--------|------|------|
| ä¿¡æ¯æ·»åŠ  | è¾“å‡ºä¸­åŒ…å«æºæ–‡æ¡£ä¸­ä¸å­˜åœ¨çš„ä¿¡æ¯ | æ‘˜è¦ä¸­å‡ºç°åŸæ–‡æœªæåŠçš„ç»“è®º |
| ä¿¡æ¯é—æ¼ | å¿½ç•¥æºæ–‡æ¡£ä¸­çš„å…³é”®ä¿¡æ¯å¯¼è‡´å«ä¹‰æ”¹å˜ | ç¿»è¯‘ä¸­çœç•¥äº†å¦å®šè¯å¯¼è‡´è¯­ä¹‰åè½¬ |
| ä¿¡æ¯çŸ›ç›¾ | è¾“å‡ºä¸æºæ–‡æ¡£ä¸­çš„ä¿¡æ¯ç›´æ¥å†²çª | RAG æ£€ç´¢åˆ° A ä½†å›ç­”äº† B |

**é¢è¯•è¦ç‚¹**ï¼šäº‹å®æ€§å¹»è§‰å…³æ³¨"æ¨¡å‹è¯´çš„æ˜¯å¦ä¸ºçœŸ"ï¼Œå¿ å®æ€§å¹»è§‰å…³æ³¨"æ¨¡å‹è¯´çš„æ˜¯å¦ç¬¦åˆç»™å®šè¾“å…¥"ã€‚ä¸€ä¸ªå¼€æ”¾åŸŸé—®ç­”ç³»ç»Ÿä¸»è¦é¢å¯¹äº‹å®æ€§å¹»è§‰ï¼Œè€Œä¸€ä¸ªæ–‡æ¡£æ‘˜è¦ç³»ç»Ÿä¸»è¦é¢å¯¹å¿ å®æ€§å¹»è§‰ã€‚

### 1.3 å†…åœ¨å¹»è§‰ vs å¤–åœ¨å¹»è§‰

> æ¥æºï¼šJi et al. "Survey of Hallucination in Natural Language Generation" ACL 2023 ; Huang et al. "A Survey on Hallucination in Large Language Models" arXiv:2311.05232

è¿™æ˜¯ Ji et al. (2023) åœ¨ç»¼è¿°è®ºæ–‡ "Survey of Hallucination in Natural Language Generation" ä¸­ä½¿ç”¨çš„å¦ä¸€ç§åˆ†ç±»ç»´åº¦ï¼š

#### å†…åœ¨å¹»è§‰ï¼ˆIntrinsic Hallucinationï¼‰

ç”Ÿæˆå†…å®¹ä¸**æºè¾“å…¥ç›´æ¥çŸ›ç›¾**ã€‚ä¾‹å¦‚ï¼Œæºæ–‡æ¡£è¯´"è¯¥å…¬å¸2023å¹´æ”¶å…¥å¢é•¿äº†5%"ï¼Œæ¨¡å‹æ‘˜è¦å´å†™"è¯¥å…¬å¸2023å¹´æ”¶å…¥ä¸‹é™äº†5%"ã€‚

- æœ¬è´¨æ˜¯ä¿¡æ¯æ‰­æ›²ï¼ˆdistortionï¼‰
- ç›¸å¯¹å®¹æ˜“é€šè¿‡è‡ªåŠ¨åŒ–æ–¹æ³•æ£€æµ‹ï¼ˆå› ä¸ºæœ‰æ˜ç¡®çš„çŸ›ç›¾ä¿¡å·ï¼‰
- é€šå¸¸æ˜¯æ¨¡å‹åœ¨ç¼–ç -è§£ç è¿‡ç¨‹ä¸­çš„æ³¨æ„åŠ›å¤±è¯¯

#### å¤–åœ¨å¹»è§‰ï¼ˆExtrinsic Hallucinationï¼‰

ç”Ÿæˆå†…å®¹**æ—¢ä¸èƒ½è¢«æºè¾“å…¥æ”¯æŒä¹Ÿä¸èƒ½è¢«å…¶åé©³**ï¼Œå³æ¨¡å‹å¼•å…¥äº†æºè¾“å…¥ä¸­å®Œå…¨ä¸å­˜åœ¨çš„ä¿¡æ¯ã€‚

- æœ¬è´¨æ˜¯ä¿¡æ¯æé€ ï¼ˆfabricationï¼‰
- æ›´éš¾æ£€æµ‹ï¼Œå› ä¸ºéœ€è¦å¤–éƒ¨çŸ¥è¯†æ¥åˆ¤æ–­çœŸä¼ª
- å¤–åœ¨å¹»è§‰ä¸ä¸€å®šæ˜¯é”™è¯¯çš„â€”â€”æ¨¡å‹å¯èƒ½æ°å¥½å¼•å…¥äº†æ­£ç¡®çš„å¤–éƒ¨çŸ¥è¯†ï¼Œä½†è¿™ç§ä¸å¯æ§çš„"åˆ›é€ "åœ¨ä¸¥è‚ƒåœºæ™¯ä¸‹ä»ç„¶æ˜¯ä¸å¯æ¥å—çš„

**ä¸¤ç§åˆ†ç±»ä½“ç³»çš„å…³ç³»**ï¼š

```
äº‹å®æ€§å¹»è§‰ â‰ˆ å¤–åœ¨å¹»è§‰çš„ä¸€ç§ç‰¹æ®Šæƒ…å†µï¼ˆå½“å¤–åœ¨ä¿¡æ¯ä¸äº‹å®çŸ›ç›¾æ—¶ï¼‰
å¿ å®æ€§å¹»è§‰ âŠƒ å†…åœ¨å¹»è§‰ + éƒ¨åˆ†å¤–åœ¨å¹»è§‰
```

### 1.4 å…¶ä»–åˆ†ç±»è§†è§’

- **å¼€æ”¾åŸŸ vs å°é—­åŸŸå¹»è§‰**ï¼šå¼€æ”¾åŸŸï¼ˆå¦‚èŠå¤©ï¼‰å¹»è§‰æ›´éš¾ç•Œå®šï¼Œå°é—­åŸŸï¼ˆå¦‚æ–‡æ¡£é—®ç­”ï¼‰æœ‰æ˜ç¡®çš„ground truth
- **è‰¯æ€§ vs æ¶æ€§å¹»è§‰**ï¼šåˆ›æ„å†™ä½œä¸­çš„"å¹»è§‰"å¯èƒ½æ˜¯ç‰¹æ€§ï¼ˆfeatureï¼‰ï¼Œè€Œåœ¨åŒ»ç–—é—®ç­”ä¸­åˆ™æ˜¯è‡´å‘½ç¼ºé™·
- **å¯æ£€æµ‹ vs ä¸å¯æ£€æµ‹å¹»è§‰**ï¼šæœ‰äº›å¹»è§‰å¯ä»¥é€šè¿‡è‡ªåŠ¨åŒ–å·¥å…·å‘ç°ï¼Œæœ‰äº›éœ€è¦é¢†åŸŸä¸“å®¶æ‰èƒ½è¯†åˆ«

---

## 2. å¹»è§‰äº§ç”Ÿçš„æ ¹æœ¬åŸå› 

å¹»è§‰ä¸æ˜¯å•ä¸€åŸå› å¯¼è‡´çš„ï¼Œè€Œæ˜¯è®­ç»ƒæ•°æ®ã€æ¨¡å‹æ¶æ„ã€è®­ç»ƒç›®æ ‡ã€è§£ç ç­–ç•¥ç­‰å¤šä¸ªå±‚é¢é—®é¢˜çš„ç»¼åˆç»“æœã€‚

### 2.1 è®­ç»ƒæ•°æ®å™ªéŸ³ä¸åå·®

#### æ•°æ®è´¨é‡é—®é¢˜

LLM çš„è®­ç»ƒæ•°æ®é€šå¸¸æ¥è‡ªäº’è”ç½‘çˆ¬å–ï¼Œä¸å¯é¿å…åœ°åŒ…å«ï¼š

- **äº‹å®é”™è¯¯**ï¼šç½‘é¡µä¸Šçš„é”™è¯¯ä¿¡æ¯ã€è¿‡æ—¶ä¿¡æ¯
- **çŸ›ç›¾ä¿¡æ¯**ï¼šä¸åŒæ¥æºå¯¹åŒä¸€äº‹ä»¶çš„æè¿°ä¸ä¸€è‡´
- **è™šæ„å†…å®¹**ï¼šå°è¯´ã€è®½åˆºæ–‡ç« ã€é’“é±¼ç½‘é¡µç­‰
- **åè§ä¸åˆ»æ¿å°è±¡**ï¼šç³»ç»Ÿæ€§çš„ç¤¾ä¼šåè§è¢«ç¼–ç è¿›æ¨¡å‹

å½“æ¨¡å‹åœ¨åŒ…å«é”™è¯¯ä¿¡æ¯çš„æ•°æ®ä¸Šè®­ç»ƒæ—¶ï¼Œå®ƒå­¦åˆ°äº†"é”™è¯¯ä¹Ÿæ˜¯ä¸€ç§åˆç†çš„è¾“å‡ºæ¨¡å¼"ã€‚æ›´ç³Ÿç³•çš„æ˜¯ï¼Œæ¨¡å‹æ— æ³•åŒºåˆ†è®­ç»ƒæ•°æ®ä¸­å“ªäº›æ˜¯äº‹å®ã€å“ªäº›æ˜¯è™šæ„â€”â€”å®ƒåªæ˜¯å­¦ä¹ ç»Ÿè®¡ç›¸å…³æ€§ã€‚

#### é•¿å°¾çŸ¥è¯†é—®é¢˜

è®­ç»ƒæ•°æ®ä¸­é«˜é¢‘å‡ºç°çš„çŸ¥è¯†ä¼šè¢«æ¨¡å‹å¾ˆå¥½åœ°å­¦ä¹ ï¼Œä½†é•¿å°¾çŸ¥è¯†ï¼ˆå‡ºç°é¢‘æ¬¡æä½çš„äº‹å®ï¼‰åˆ™å®¹æ˜“è¢«"æ·¹æ²¡"ã€‚å½“ç”¨æˆ·æŸ¥è¯¢é•¿å°¾çŸ¥è¯†æ—¶ï¼Œæ¨¡å‹å€¾å‘äºç”¨é«˜é¢‘çŸ¥è¯†æ¨¡å¼å»"å¡«å……"ç­”æ¡ˆï¼Œå¯¼è‡´çœ‹ä¼¼åˆç†ä½†å®é™…é”™è¯¯çš„è¾“å‡ºã€‚

#### çŸ¥è¯†æˆªæ­¢ï¼ˆKnowledge Cutoffï¼‰

æ¨¡å‹çš„è®­ç»ƒæ•°æ®æœ‰æ—¶é—´æˆªæ­¢ç‚¹ã€‚å¯¹äºæˆªæ­¢æ—¥æœŸä¹‹åçš„äº‹ä»¶ï¼Œæ¨¡å‹è¦ä¹ˆæ‹’ç»å›ç­”ï¼Œè¦ä¹ˆï¼ˆæ›´å¸¸è§åœ°ï¼‰åŸºäºæˆªæ­¢å‰çš„ä¿¡æ¯åšå‡ºä¸å‡†ç¡®çš„æ¨æµ‹ã€‚

### 2.2 Exposure Biasï¼ˆæš´éœ²åå·®ï¼‰

è¿™æ˜¯è‡ªå›å½’è¯­è¨€æ¨¡å‹çš„ä¸€ä¸ªç»“æ„æ€§é—®é¢˜ï¼š

- **è®­ç»ƒæ—¶**ï¼šæ¨¡å‹ä½¿ç”¨ teacher forcingï¼Œå³æ¯ä¸€æ­¥éƒ½åŸºäº**çœŸå®çš„å‰åº token** é¢„æµ‹ä¸‹ä¸€ä¸ª token
- **æ¨ç†æ—¶**ï¼šæ¨¡å‹ä½¿ç”¨è‡ªå·±**ä¹‹å‰ç”Ÿæˆçš„ token** ä½œä¸ºè¾“å…¥æ¥ç”Ÿæˆåç»­ token

è¿™ç§è®­ç»ƒ-æ¨ç†ä¹‹é—´çš„åˆ†å¸ƒä¸åŒ¹é…å°±æ˜¯ exposure biasã€‚å…¶åæœæ˜¯ï¼š

1. **é”™è¯¯ç´¯ç§¯**ï¼šä¸€æ—¦æ¨¡å‹åœ¨æŸä¸€æ­¥ç”Ÿæˆäº†ä¸€ä¸ªä¸å¤ªå‡†ç¡®çš„ tokenï¼Œåç»­æ‰€æœ‰ token éƒ½åœ¨è¿™ä¸ªé”™è¯¯åŸºç¡€ä¸Šç”Ÿæˆï¼Œé”™è¯¯åƒæ»šé›ªçƒä¸€æ ·ç´¯ç§¯
2. **ç¼ºä¹çº é”™èƒ½åŠ›**ï¼šæ¨¡å‹ä»æœªåœ¨è®­ç»ƒä¸­å­¦è¿‡"å¦‚ä½•ä»è‡ªå·±çš„é”™è¯¯ä¸­æ¢å¤"ï¼Œå› ä¸ºè®­ç»ƒæ—¶å®ƒæ€»æ˜¯çœ‹åˆ°æ­£ç¡®çš„å†å²
3. **é•¿æ–‡æœ¬é€€åŒ–**ï¼šç”Ÿæˆè¶Šé•¿çš„æ–‡æœ¬ï¼Œç´¯ç§¯çš„åå·®è¶Šå¤§ï¼Œå¹»è§‰æ¦‚ç‡è¶Šé«˜

```
è®­ç»ƒæ—¶ï¼š  [çœŸå®tokenâ‚] â†’ [çœŸå®tokenâ‚‚] â†’ [çœŸå®tokenâ‚ƒ] â†’ é¢„æµ‹tokenâ‚„
æ¨ç†æ—¶ï¼š  [ç”Ÿæˆtokenâ‚] â†’ [ç”Ÿæˆtokenâ‚‚] â†’ [ç”Ÿæˆtokenâ‚ƒ] â†’ é¢„æµ‹tokenâ‚„
                â†‘ å¯èƒ½æœ‰åå·®    â†‘ åå·®ç´¯ç§¯      â†‘ åå·®åŠ å‰§
```

### 2.3 Softmax è¿‡åº¦è‡ªä¿¡ä¸æ ¡å‡†é—®é¢˜

#### è¿‡åº¦è‡ªä¿¡ç°è±¡

Transformer æ¨¡å‹æœ€åä¸€å±‚çš„ softmax è¾“å‡ºé€šå¸¸å‘ˆç°å‡º**è¿‡åº¦è‡ªä¿¡**çš„åˆ†å¸ƒç‰¹å¾ï¼š

- å³ä½¿æ¨¡å‹"ä¸ç¡®å®š"ï¼Œsoftmax è¾“å‡ºçš„æ¦‚ç‡åˆ†å¸ƒä»ç„¶ä¼šæœ‰ä¸€ä¸ªæˆ–å°‘æ•°å‡ ä¸ª token è·å¾—å¾ˆé«˜çš„æ¦‚ç‡
- è¿™æ„å‘³ç€æ¨¡å‹çš„è¾“å‡ºæ¦‚ç‡ä¸èƒ½å¿ å®åœ°åæ˜ å…¶çœŸå®çš„ä¸ç¡®å®šæ€§
- ç»“æœæ˜¯æ¨¡å‹"è¯´é”™è¯æ—¶ä¹Ÿå¾ˆæœ‰è‡ªä¿¡"ï¼Œç”¨æˆ·æ— æ³•ä»æ¨¡å‹çš„è¡¨ç°ä¸­åˆ¤æ–­å…¶å›ç­”çš„å¯é æ€§

#### æ ¡å‡†ä¸è‰¯ï¼ˆPoor Calibrationï¼‰

ç†æƒ³æƒ…å†µä¸‹ï¼Œå¦‚æœæ¨¡å‹ä»¥ 80% çš„ç½®ä¿¡åº¦è¾“å‡ºæŸä¸ªç­”æ¡ˆï¼Œé‚£ä¹ˆè¿™ä¸ªç­”æ¡ˆåº”è¯¥åœ¨ 80% çš„æƒ…å†µä¸‹æ˜¯æ­£ç¡®çš„ã€‚ä½†å®é™…ä¸Šï¼š

- ç°ä»£ LLM çš„æ ¡å‡†æ€§é€šå¸¸å¾ˆå·®
- æ¨¡å‹å€¾å‘äºé«˜ä¼°è‡ªå·±çš„æ­£ç¡®æ¦‚ç‡ï¼ˆoverconfidentï¼‰
- RLHF è®­ç»ƒè¿›ä¸€æ­¥åŠ å‰§äº†è¿™ä¸ªé—®é¢˜â€”â€”æ¨¡å‹è¢«è®­ç»ƒå¾—æ›´åŠ "æœæ–­"å’Œ"æµç•…"ï¼Œä½†è¿™ç§æœæ–­å¹¶ä¸åæ˜ çœŸå®çš„çŸ¥è¯†ç¡®å®šæ€§

#### æŠ€æœ¯æ ¹å› 

```python
# softmax çš„æ€§è´¨å¯¼è‡´äº†è¿‡åº¦è‡ªä¿¡
# å½“ logits çš„æ•°å€¼èŒƒå›´å¢å¤§æ—¶ï¼Œsoftmax åˆ†å¸ƒè¶‹å‘äº one-hot
import numpy as np

logits = np.array([2.0, 1.0, 0.5, 0.1])
probs = np.exp(logits) / np.sum(np.exp(logits))
# probs â‰ˆ [0.50, 0.18, 0.11, 0.07]  -- çœ‹èµ·æ¥å¾ˆ"ç¡®å®š"
# ä½†å®é™…ä¸Šæ¨¡å‹å¯èƒ½å¯¹å¤šä¸ªé€‰é¡¹éƒ½ä¸å¤ªæœ‰æŠŠæ¡
```

temperature sampling å¯ä»¥å¹³æ»‘åˆ†å¸ƒï¼Œä½†å¹¶ä¸èƒ½ä»æ ¹æœ¬ä¸Šè§£å†³æ ¡å‡†é—®é¢˜ã€‚

### 2.4 çŸ¥è¯†è¾¹ç•Œæ¨¡ç³Š

#### æ¨¡å‹ä¸çŸ¥é“è‡ªå·±ä¸çŸ¥é“ä»€ä¹ˆ

è¿™æ˜¯å¹»è§‰é—®é¢˜æœ€æ·±å±‚çš„å“²å­¦å’ŒæŠ€æœ¯å›°å¢ƒï¼š

- LLM æ²¡æœ‰æ˜¾å¼çš„**å…ƒè®¤çŸ¥èƒ½åŠ›**ï¼ˆmetacognitionï¼‰â€”â€”å®ƒæ— æ³•å¯é åœ°è¯„ä¼°è‡ªå·±å¯¹æŸä¸ªçŸ¥è¯†ç‚¹çš„æŒæ¡ç¨‹åº¦
- æ¨¡å‹çš„"çŸ¥è¯†"ä»¥åˆ†å¸ƒå¼çš„æ–¹å¼å­˜å‚¨åœ¨å‚æ•°ä¸­ï¼Œæ²¡æœ‰æ˜ç¡®çš„"çŸ¥é“/ä¸çŸ¥é“"è¾¹ç•Œ
- å½“é‡åˆ°çŸ¥è¯†è¾¹ç•Œé™„è¿‘çš„é—®é¢˜æ—¶ï¼Œæ¨¡å‹ä¸ä¼šè¯´"æˆ‘ä¸ç¡®å®š"ï¼Œè€Œæ˜¯**åŸºäºç»Ÿè®¡æ¨¡å¼ç”Ÿæˆä¸€ä¸ªçœ‹ä¼¼åˆç†çš„ç­”æ¡ˆ**

#### å‚æ•°åŒ–çŸ¥è¯† vs è¯­å¢ƒçŸ¥è¯†çš„å†²çª

```
ç”¨æˆ·ï¼š[æä¾›æ–‡æ¡£] è¯·æ ¹æ®æ–‡æ¡£å›ç­”é—®é¢˜
æ¨¡å‹å†…éƒ¨å†²çªï¼š
  - å‚æ•°åŒ–çŸ¥è¯†ï¼ˆè®­ç»ƒæ—¶å­¦åˆ°çš„ï¼‰ï¼šç­”æ¡ˆæ˜¯ A
  - è¯­å¢ƒçŸ¥è¯†ï¼ˆæ–‡æ¡£ä¸­è¯´çš„ï¼‰ï¼šç­”æ¡ˆæ˜¯ B
  - æ¨¡å‹å¯èƒ½è¾“å‡º Aï¼ˆå¿½ç•¥æ–‡æ¡£ï¼‰æˆ– æ··åˆ A å’Œ Bï¼ˆå¹»è§‰ï¼‰
```

è¿™ç§å†²çªåœ¨ RAG ç³»ç»Ÿä¸­å°¤ä¸ºå¸¸è§ï¼Œè¢«ç§°ä¸º **knowledge conflict** é—®é¢˜ã€‚ç ”ç©¶è¡¨æ˜ï¼Œå½“å‚æ•°åŒ–çŸ¥è¯†ä¸æ£€ç´¢åˆ°çš„ä¸Šä¸‹æ–‡å†²çªæ—¶ï¼Œè¾ƒå¤§çš„æ¨¡å‹æ›´å€¾å‘äºä¾èµ–è‡ªå·±çš„å‚æ•°åŒ–çŸ¥è¯†ï¼Œè¿™åè€Œå¢åŠ äº†å¹»è§‰é£é™©ã€‚

### 2.5 è§£ç ç­–ç•¥çš„å½±å“

ä¸åŒçš„è§£ç ç­–ç•¥å¯¹å¹»è§‰ç‡æœ‰ç›´æ¥å½±å“ï¼š

| è§£ç ç­–ç•¥ | å¹»è§‰å€¾å‘ | åŸå›  |
|----------|----------|------|
| Greedy Decoding | ä¸­ç­‰ | å¯èƒ½é™·å…¥é‡å¤ï¼Œä½†ä¸ä¼šå¼•å…¥éšæœºå™ªå£° |
| Beam Search | è¾ƒä½ | è€ƒè™‘å¤šä¸ªå€™é€‰åºåˆ—ï¼Œä½†å¯èƒ½è¿‡äºä¿å®ˆ |
| Top-k Sampling | è¾ƒé«˜ | k å€¼å¤§æ—¶å¼•å…¥æ›´å¤šéšæœºæ€§å’Œä¸ç¡®å®šæ€§ |
| Top-p (Nucleus) | ä¸­ç­‰ | åŠ¨æ€æˆªæ–­å°¾éƒ¨æ¦‚ç‡ï¼Œæ•ˆæœä¾èµ– p å€¼ |
| Temperature > 1 | é«˜ | å¢åŠ éšæœºæ€§ï¼Œé¼“åŠ±"åˆ›é€ æ€§"è¾“å‡º |

### 2.6 æ³¨æ„åŠ›æœºåˆ¶çš„å±€é™æ€§

- **é•¿è·ç¦»ä¾èµ–è¡°å‡**ï¼šå°½ç®¡ Transformer ç†è®ºä¸Šå¯ä»¥å…³æ³¨ä»»æ„è·ç¦»çš„ tokenï¼Œä½†å®è·µä¸­æ³¨æ„åŠ›æƒé‡åœ¨é•¿è·ç¦»ä¸Šæ˜¾è‘—è¡°å‡ï¼ˆå°¤å…¶æ˜¯ "lost in the middle" ç°è±¡ï¼‰
- **æ³¨æ„åŠ›ç¨€é‡Š**ï¼šå½“ä¸Šä¸‹æ–‡å¾ˆé•¿æ—¶ï¼Œå…³é”®ä¿¡æ¯çš„æ³¨æ„åŠ›æƒé‡è¢«ç¨€é‡Šï¼Œæ¨¡å‹å¯èƒ½"å¿½ç•¥"é‡è¦çš„çº¦æŸæ¡ä»¶
- **ä½ç½®åå·®**ï¼šæ¨¡å‹å¯¹å¼€å¤´å’Œç»“å°¾çš„ä¿¡æ¯ç»™äºˆæ›´å¤šå…³æ³¨ï¼Œä¸­é—´éƒ¨åˆ†çš„ä¿¡æ¯å®¹æ˜“è¢«é—æ¼

---

## 3. å¹»è§‰æ£€æµ‹æ–¹æ³•

### 3.1 SelfCheckGPT

**æ ¸å¿ƒæ€æƒ³**ï¼šå¦‚æœæ¨¡å‹çœŸæ­£"çŸ¥é“"æŸä¸ªäº‹å®ï¼Œé‚£ä¹ˆå¤šæ¬¡ç‹¬ç«‹é‡‡æ ·åº”è¯¥äº§ç”Ÿä¸€è‡´çš„ç­”æ¡ˆï¼›å¦‚æœæ¨¡å‹åœ¨"ç¼–é€ "ï¼Œä¸åŒé‡‡æ ·ä¹‹é—´ä¼šäº§ç”Ÿä¸ä¸€è‡´çš„æè¿°ã€‚

**ç®—æ³•æµç¨‹**ï¼š

```
1. å¯¹åŒä¸€ä¸ª promptï¼Œé‡‡æ · N æ¬¡ç‹¬ç«‹å“åº”ï¼ˆé«˜ temperatureï¼‰
2. å°†åŸå§‹å“åº”æŒ‰å¥å­åˆ†å‰²
3. å¯¹æ¯ä¸ªå¥å­ï¼Œæ£€æŸ¥å®ƒä¸ N ä¸ªé‡‡æ ·å“åº”çš„ä¸€è‡´æ€§
4. ä¸€è‡´æ€§ä½çš„å¥å­æ ‡è®°ä¸ºå¯èƒ½çš„å¹»è§‰
```

**ä¸€è‡´æ€§æ£€æŸ¥çš„ä¸‰ç§å®ç°**ï¼š

- **BERTScore**ï¼šè®¡ç®—å¥å­ä¸é‡‡æ ·å“åº”ä¹‹é—´çš„è¯­ä¹‰ç›¸ä¼¼åº¦
- **QA-based**ï¼šä»å¥å­ä¸­æå–é—®é¢˜ï¼Œæ£€æŸ¥é‡‡æ ·å“åº”æ˜¯å¦ç»™å‡ºä¸€è‡´çš„ç­”æ¡ˆ
- **NLI-based**ï¼šä½¿ç”¨ NLI æ¨¡å‹åˆ¤æ–­é‡‡æ ·å“åº”æ˜¯å¦è•´å«ï¼ˆentailï¼‰è¯¥å¥å­
- **LLM-Prompt**ï¼šç›´æ¥è®©å¦ä¸€ä¸ª LLM åˆ¤æ–­ä¸€è‡´æ€§

**ä¼˜åŠ¿**ï¼š
- æ— éœ€å¤–éƒ¨çŸ¥è¯†åº“æˆ– ground truth
- é»‘ç›’æ–¹æ³•ï¼Œé€‚ç”¨äºä»»ä½• LLM
- å¯ä»¥æä¾›å¥å­çº§åˆ«çš„å¹»è§‰æ ‡æ³¨

**å±€é™**ï¼š
- å¦‚æœæ¨¡å‹å¯¹æŸä¸ªé”™è¯¯ä¿¡æ¯éå¸¸"è‡ªä¿¡"ï¼ˆè®­ç»ƒæ•°æ®ä¸­å¹¿æ³›å­˜åœ¨çš„é”™è¯¯ï¼‰ï¼Œå¤šæ¬¡é‡‡æ ·ä¹Ÿä¼šä¸€è‡´åœ°è¾“å‡ºé”™è¯¯
- éœ€è¦å¤šæ¬¡æ¨ç†è°ƒç”¨ï¼Œæˆæœ¬è¾ƒé«˜
- å¯¹å¿ å®æ€§å¹»è§‰æ£€æµ‹æ•ˆæœæœ‰é™

### 3.2 äº‹å®æ ¸æŸ¥ Pipelineï¼ˆFact-Checking Pipelineï¼‰

ä¸€ä¸ªå®Œæ•´çš„è‡ªåŠ¨åŒ–äº‹å®æ ¸æŸ¥æµæ°´çº¿é€šå¸¸åŒ…æ‹¬ä»¥ä¸‹æ¨¡å—ï¼š

```
åŸå§‹æ–‡æœ¬ â†’ [å£°æ˜åˆ†è§£] â†’ [è¯æ®æ£€ç´¢] â†’ [ç«‹åœºæ£€æµ‹] â†’ [åˆ¤å†³è¾“å‡º]
            Claim         Evidence      Stance        Verdict
         Decomposition    Retrieval    Detection     Generation
```

**Step 1 - å£°æ˜åˆ†è§£ï¼ˆClaim Decompositionï¼‰**

å°†æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬åˆ†è§£ä¸ºç‹¬ç«‹çš„ã€å¯éªŒè¯çš„åŸå­å£°æ˜ï¼ˆatomic claimsï¼‰ã€‚

```
è¾“å…¥ï¼š"çˆ±å› æ–¯å¦åœ¨1905å¹´æå‡ºäº†ç›¸å¯¹è®ºï¼Œå¹¶å› æ­¤è·å¾—äº†è¯ºè´å°”ç‰©ç†å­¦å¥–"
åˆ†è§£ï¼š
  - Claim 1: çˆ±å› æ–¯å¦åœ¨1905å¹´æå‡ºäº†ç›¸å¯¹è®º âœ“
  - Claim 2: çˆ±å› æ–¯å¦å› ç›¸å¯¹è®ºè·å¾—è¯ºè´å°”ç‰©ç†å­¦å¥– âœ—ï¼ˆå®é™…æ˜¯å› å…‰ç”µæ•ˆåº”ï¼‰
```

**Step 2 - è¯æ®æ£€ç´¢ï¼ˆEvidence Retrievalï¼‰**

ä»å¯ä¿¡çŸ¥è¯†æºä¸­æ£€ç´¢ä¸æ¯ä¸ªå£°æ˜ç›¸å…³çš„è¯æ®ï¼š
- Wikipedia
- çŸ¥è¯†å›¾è°±ï¼ˆWikidataã€Freebaseï¼‰
- æƒå¨æ•°æ®åº“
- æœç´¢å¼•æ“å®æ—¶ç»“æœ

**Step 3 - ç«‹åœºæ£€æµ‹ï¼ˆStance Detection / NLIï¼‰**

åˆ¤æ–­æ£€ç´¢åˆ°çš„è¯æ®æ˜¯æ”¯æŒï¼ˆsupportï¼‰ã€åé©³ï¼ˆcontradictï¼‰è¿˜æ˜¯æ— å…³ï¼ˆneutralï¼‰äºç»™å®šçš„å£°æ˜ã€‚

**Step 4 - åˆ¤å†³è¾“å‡º**

ç»¼åˆæ‰€æœ‰è¯æ®çš„ç«‹åœºï¼Œç»™å‡ºæœ€ç»ˆåˆ¤æ–­ï¼šSupported / Refuted / Not Enough Infoã€‚

### 3.3 NLI-based æ–¹æ³•

è‡ªç„¶è¯­è¨€æ¨ç†ï¼ˆNatural Language Inferenceï¼‰æ¨¡å‹å¯ä»¥ç›´æ¥ç”¨äºå¹»è§‰æ£€æµ‹ï¼š

**åŸºæœ¬æ€è·¯**ï¼š
- å°†**æºæ–‡æ¡£**ä½œä¸ºå‰æï¼ˆpremiseï¼‰
- å°†**æ¨¡å‹ç”Ÿæˆçš„æ¯ä¸ªå¥å­**ä½œä¸ºå‡è®¾ï¼ˆhypothesisï¼‰
- ä½¿ç”¨ NLI æ¨¡å‹åˆ¤æ–­è•´å«å…³ç³»

**å…·ä½“æ–¹æ³•**ï¼š

1. **SummaC**ï¼ˆLaban et al., 2022ï¼‰ï¼šå°†æ–‡æ¡£å’Œæ‘˜è¦åˆ†åˆ«æŒ‰å¥å­åˆ†å‰²ï¼Œæ„å»º NLI åˆ†æ•°çŸ©é˜µï¼Œé€šè¿‡èšåˆç­–ç•¥å¾—åˆ°æ•´ä½“å¿ å®åº¦åˆ†æ•°
2. **AlignScore**ï¼ˆZha et al., 2023ï¼‰ï¼šç»Ÿä¸€çš„æ–‡æœ¬å¯¹é½è¯„ä¼°æ¡†æ¶ï¼Œåœ¨å¤šä¸ª NLI/äº‹å®æ€§æ•°æ®é›†ä¸Šè”åˆè®­ç»ƒ
3. **TRUE**ï¼ˆHonovich et al., 2022ï¼‰ï¼šå¤§è§„æ¨¡ NLI æ¨¡å‹ç”¨äºäº‹å®ä¸€è‡´æ€§è¯„ä¼°

**å±€é™æ€§**ï¼š
- NLI æ¨¡å‹è‡ªèº«ä¹Ÿå¯èƒ½å‡ºé”™
- å¯¹äºéœ€è¦å¤šæ­¥æ¨ç†çš„äº‹å®ï¼Œç®€å•çš„ premise-hypothesis å¯¹åˆ¤æ–­ä¸å¤Ÿ
- å¯¹æ•°å€¼æ¯”è¾ƒã€æ—¶é—´é¡ºåºç­‰ç»†ç²’åº¦äº‹å®æ ¸æŸ¥æ•ˆæœæœ‰é™

### 3.4 çŸ¥è¯†å›¾è°±éªŒè¯

åˆ©ç”¨ç»“æ„åŒ–çŸ¥è¯†å›¾è°±ï¼ˆKGï¼‰æ¥éªŒè¯æ¨¡å‹è¾“å‡ºçš„äº‹å®æ€§ï¼š

**æµç¨‹**ï¼š
```
æ¨¡å‹è¾“å‡º â†’ [å®ä½“è¯†åˆ« + å…³ç³»æŠ½å–] â†’ (å¤´å®ä½“, å…³ç³», å°¾å®ä½“) ä¸‰å…ƒç»„
                                           â†“
                                    åœ¨çŸ¥è¯†å›¾è°±ä¸­æŸ¥è¯¢
                                           â†“
                                   åŒ¹é… â†’ æ”¯æŒ  /  ä¸åŒ¹é… â†’ çŸ›ç›¾  /  æœªæ‰¾åˆ° â†’ æ— æ³•éªŒè¯
```

**ä¼˜åŠ¿**ï¼šç²¾ç¡®çš„ç»“æ„åŒ–éªŒè¯ï¼Œå¯¹å®ä½“å±æ€§ç±»äº‹å®ç‰¹åˆ«æœ‰æ•ˆ

**å±€é™**ï¼š
- KG è¦†ç›–åº¦æœ‰é™ï¼Œå¾ˆå¤šäº‹å®åœ¨ KG ä¸­ä¸å­˜åœ¨
- å®ä½“æ¶ˆæ­§ï¼ˆentity disambiguationï¼‰ä»ç„¶æ˜¯éš¾é¢˜
- æ— æ³•å¤„ç†éç»“æ„åŒ–çš„å¤æ‚æ¨ç†å‹å£°æ˜

### 3.5 åŸºäºå†…éƒ¨çŠ¶æ€çš„æ£€æµ‹

åˆ©ç”¨æ¨¡å‹è‡ªèº«çš„å†…éƒ¨è¡¨ç¤ºæ¥æ£€æµ‹å¹»è§‰ï¼ˆç™½ç›’æ–¹æ³•ï¼‰ï¼š

- **æ³¨æ„åŠ›æƒé‡åˆ†æ**ï¼šå¹»è§‰å†…å®¹çš„æ³¨æ„åŠ›æ¨¡å¼å¯èƒ½ä¸å¿ å®å†…å®¹ä¸åŒ
- **éšè—å±‚è¡¨ç¤º**ï¼šè®­ç»ƒä¸€ä¸ªæ¢é’ˆï¼ˆprobeï¼‰åˆ†ç±»å™¨ï¼ŒåŸºäºéšè—å±‚è¡¨ç¤ºåˆ¤æ–­å½“å‰ token æ˜¯å¦ä¸ºå¹»è§‰
- **logit ä¸ç¡®å®šæ€§**ï¼šè¾“å‡º token çš„ logit åˆ†å¸ƒç†µå€¼é«˜å¯èƒ½æ„å‘³ç€ä¸ç¡®å®šæ€§å¤§
- **ITIï¼ˆInference-Time Interventionï¼‰**ï¼šLi et al. (2023) å‘ç°å¯ä»¥é€šè¿‡åœ¨æ¨ç†æ—¶å¹²é¢„ç‰¹å®šæ³¨æ„åŠ›å¤´æ¥å‡å°‘å¹»è§‰

### 3.6 LLM-as-Judge

ä½¿ç”¨å¦ä¸€ä¸ªï¼ˆé€šå¸¸æ›´å¼ºçš„ï¼‰LLM æ¥è¯„ä¼°ç›®æ ‡æ¨¡å‹è¾“å‡ºçš„äº‹å®æ€§ï¼š

```
Prompt: "è¯·åˆ¤æ–­ä»¥ä¸‹å›ç­”æ˜¯å¦åŒ…å«äº‹å®é”™è¯¯ã€‚
é—®é¢˜ï¼š{question}
å›ç­”ï¼š{answer}
å‚è€ƒèµ„æ–™ï¼š{evidence}
è¯·åˆ—å‡ºæ‰€æœ‰äº‹å®é”™è¯¯å¹¶è§£é‡Šã€‚"
```

**ä¼˜ç¼ºç‚¹**ï¼š
- âœ… çµæ´»ã€æ˜“éƒ¨ç½²ã€ä¸éœ€è¦ä¸“é—¨è®­ç»ƒ
- âœ… å¯ä»¥å¤„ç†å¤æ‚çš„æ¨ç†é“¾
- âŒ è¯„åˆ¤æ¨¡å‹è‡ªèº«ä¹Ÿå¯èƒ½äº§ç”Ÿå¹»è§‰
- âŒ å­˜åœ¨åå¥½åå·®ï¼ˆå¦‚å€¾å‘è®¤ä¸ºæ›´é•¿çš„å›ç­”æ›´å¥½ï¼‰

---

## 4. å¹»è§‰ç¼“è§£ç­–ç•¥

### 4.1 è®­ç»ƒé˜¶æ®µ

#### 4.1.1 æ•°æ®æ¸…æ´—ä¸ç­–åˆ’

**é«˜è´¨é‡æ•°æ®ç­›é€‰**ï¼š
- å»é™¤è®­ç»ƒæ•°æ®ä¸­çš„æ˜æ˜¾äº‹å®é”™è¯¯
- ä½¿ç”¨äº‹å®æ ¸æŸ¥å·¥å…·å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œé¢„è¿‡æ»¤
- æé«˜æƒå¨æ¥æºï¼ˆæ•™ç§‘ä¹¦ã€ç™¾ç§‘å…¨ä¹¦ã€å­¦æœ¯è®ºæ–‡ï¼‰çš„é‡‡æ ·æƒé‡
- å‡å°‘è™šæ„å†…å®¹ï¼ˆå°è¯´ã€åˆ›æ„å†™ä½œï¼‰åœ¨è®­ç»ƒæ•°æ®ä¸­çš„æ¯”ä¾‹ï¼ˆæˆ–æ·»åŠ æ˜ç¡®çš„æ ‡è®°ï¼‰

**æ•°æ®å»é‡ä¸å»å†²çª**ï¼š
- å»é™¤é‡å¤å’Œè¿‘é‡å¤å†…å®¹ï¼Œé¿å…æ¨¡å‹è¿‡åº¦è®°å¿†ç‰¹å®šè¡¨è¿°
- è¯†åˆ«å¹¶å¤„ç†è®­ç»ƒæ•°æ®ä¸­çš„çŸ›ç›¾ä¿¡æ¯
- æ—¶é—´æ•æ„Ÿä¿¡æ¯æ ‡æ³¨æ—¶é—´æˆ³

#### 4.1.2 RLHFï¼ˆReinforcement Learning from Human Feedbackï¼‰

RLHF é€šè¿‡äººç±»åé¦ˆæ¥å¯¹é½æ¨¡å‹è¡Œä¸ºï¼Œå¯ä»¥æ˜¾è‘—å‡å°‘å¹»è§‰ï¼š

```
SFTæ¨¡å‹ â†’ [äººç±»æ ‡æ³¨åå¥½æ•°æ®] â†’ [è®­ç»ƒå¥–åŠ±æ¨¡å‹] â†’ [PPO ä¼˜åŒ–ç­–ç•¥æ¨¡å‹]
```

**é’ˆå¯¹å¹»è§‰çš„ RLHF ç­–ç•¥**ï¼š
- åœ¨æ ‡æ³¨æŒ‡å—ä¸­æ˜ç¡®è¦æ±‚æ ‡æ³¨è€…æƒ©ç½šå¹»è§‰å†…å®¹
- å¥–åŠ±æ¨¡å‹ä¸­åŠ å…¥äº‹å®æ€§ç»´åº¦çš„è¯„åˆ†
- é¼“åŠ±æ¨¡å‹åœ¨ä¸ç¡®å®šæ—¶è¡¨è¾¾ä¸ç¡®å®šæ€§ï¼ˆ"æˆ‘ä¸ç¡®å®š"ã€"æ®æˆ‘æ‰€çŸ¥"ï¼‰
- æƒ©ç½šè¿‡åº¦è‡ªä¿¡çš„é”™è¯¯å›ç­”

**RLHF å¯¹å¹»è§‰çš„åŒåˆƒå‰‘æ•ˆåº”**ï¼š
- âœ… å¯ä»¥è®­ç»ƒæ¨¡å‹æ‹’ç»å›ç­”ä¸ç¡®å®šçš„é—®é¢˜
- âœ… å¯ä»¥é¼“åŠ±æ¨¡å‹ä½¿ç”¨å¯¹å†²è¯­è¨€ï¼ˆhedgingï¼‰
- âŒ å¯èƒ½å¯¼è‡´ sycophancyï¼ˆè°„åªšï¼‰â€”â€”æ¨¡å‹å­¦ä¼šå‘Šè¯‰ç”¨æˆ·æƒ³å¬çš„è¯
- âŒ å¯èƒ½è¿‡åº¦ä¼˜åŒ–å¥–åŠ±æ¨¡å‹çš„è¡¨é¢ç‰¹å¾ï¼ˆreward hackingï¼‰

#### 4.1.3 DPOï¼ˆDirect Preference Optimizationï¼‰

DPO ç»•è¿‡äº†æ˜¾å¼çš„å¥–åŠ±æ¨¡å‹è®­ç»ƒï¼Œç›´æ¥ä»åå¥½æ•°æ®ä¸­ä¼˜åŒ–ç­–ç•¥ï¼š

```
L_DPO = -E[log Ïƒ(Î² Â· (log Ï€_Î¸(y_w|x)/Ï€_ref(y_w|x) - log Ï€_Î¸(y_l|x)/Ï€_ref(y_l|x)))]

å…¶ä¸­ y_w = è¢«åå¥½çš„ï¼ˆæ— å¹»è§‰çš„ï¼‰å›ç­”
     y_l = ä¸è¢«åå¥½çš„ï¼ˆå«å¹»è§‰çš„ï¼‰å›ç­”
```

**DPO åœ¨å‡å°‘å¹»è§‰æ–¹é¢çš„åº”ç”¨**ï¼š
- æ„å»º (æ— å¹»è§‰å›ç­”, å«å¹»è§‰å›ç­”) çš„åå¥½å¯¹
- ä½¿ç”¨è‡ªåŠ¨åŒ–å·¥å…·ç”Ÿæˆå«å¹»è§‰çš„è´Ÿä¾‹
- ç»“åˆäº‹å®æ ¸æŸ¥ç»“æœæ„å»ºåå¥½æ•°æ®

**ç›¸æ¯” RLHF çš„ä¼˜åŠ¿**ï¼š
- è®­ç»ƒæ›´ç¨³å®šï¼Œä¸éœ€è¦è®­ç»ƒå•ç‹¬çš„å¥–åŠ±æ¨¡å‹
- ä¸ä¼šå‡ºç°å¥–åŠ±æ¨¡å‹è¢« hack çš„é—®é¢˜
- å®ç°ç®€å•ï¼Œè¶…å‚æ•°å°‘

#### 4.1.4 å…¶ä»–è®­ç»ƒç­–ç•¥

- **çŸ¥è¯†è’¸é¦ä¸­çš„äº‹å®æ€§ä¿æŒ**ï¼šåœ¨æ¨¡å‹è’¸é¦æ—¶ï¼Œç¡®ä¿å°æ¨¡å‹ä¸ä¸¢å¤±å¤§æ¨¡å‹çš„äº‹å®æ€§çŸ¥è¯†
- **å¯¹æ¯”å­¦ä¹ **ï¼šè®©æ¨¡å‹å­¦ä¹ åŒºåˆ†äº‹å®æ€§å›ç­”å’Œå¹»è§‰å›ç­”çš„è¡¨ç¤º
- **å¤šä»»åŠ¡å­¦ä¹ **ï¼šåŠ å…¥äº‹å®éªŒè¯ã€NLI ç­‰è¾…åŠ©ä»»åŠ¡

### 4.2 æ¨ç†é˜¶æ®µ

#### 4.2.1 RAGï¼ˆRetrieval-Augmented Generationï¼‰

> æ¥æºï¼šLewis et al. "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks" arXiv:2005.11401

RAG æ˜¯ç›®å‰å‡å°‘å¹»è§‰æœ€ä¸»æµã€æœ€å®ç”¨çš„æ–¹æ³•ä¹‹ä¸€ï¼š

```
ç”¨æˆ·æŸ¥è¯¢ â†’ [æŸ¥è¯¢ç¼–ç ] â†’ [å‘é‡æ£€ç´¢/BM25] â†’ Top-K ç›¸å…³æ–‡æ¡£
                                                â†“
                                    [æ–‡æ¡£ + æŸ¥è¯¢] â†’ LLM â†’ åŸºäºè¯æ®çš„å›ç­”
```

**RAG å‡å°‘å¹»è§‰çš„åŸç†**ï¼š
- ä¸ºæ¨¡å‹æä¾›**æ—¶æ•ˆæ€§çŸ¥è¯†**ï¼Œå¼¥è¡¥çŸ¥è¯†æˆªæ­¢é—®é¢˜
- å°†å›ç­”é”šå®šåœ¨**æ£€ç´¢åˆ°çš„è¯æ®**ä¸Šï¼Œå‡å°‘æ¨¡å‹"å‡­ç©ºç¼–é€ "
- å¯ä»¥è¿½æº¯ç­”æ¡ˆçš„**æ¥æºæ–‡æ¡£**ï¼Œä¾¿äºéªŒè¯

**RAG çš„å±€é™ä¸é™·é˜±**ï¼š
- æ£€ç´¢è´¨é‡ç›´æ¥å½±å“ç”Ÿæˆè´¨é‡ï¼ˆgarbage in, garbage outï¼‰
- å½“æ£€ç´¢ç»“æœä¸å‚æ•°åŒ–çŸ¥è¯†å†²çªæ—¶ï¼Œæ¨¡å‹å¯èƒ½å¿½ç•¥æ£€ç´¢ç»“æœ
- æ£€ç´¢åˆ°çš„æ–‡æ¡£æœ¬èº«å¯èƒ½åŒ…å«é”™è¯¯ä¿¡æ¯
- å¤šæ–‡æ¡£ä¹‹é—´çš„ä¿¡æ¯å¯èƒ½äº’ç›¸çŸ›ç›¾
- æ¨¡å‹å¯èƒ½"è¿‡åº¦å¼•ç”¨"â€”â€”åœ¨ä¸éœ€è¦å¤–éƒ¨çŸ¥è¯†çš„æƒ…å†µä¸‹ä»ç„¶ç”Ÿæ¬ç¡¬å¥—æ£€ç´¢ç»“æœ

**æ”¹è¿›æ–¹å‘**ï¼š
- **Self-RAG**ï¼ˆAsai et al., 2024, arXiv:2310.11511ï¼‰ï¼šæ¨¡å‹è‡ªä¸»å†³å®šä½•æ—¶æ£€ç´¢ã€æ£€ç´¢ä»€ä¹ˆã€æ˜¯å¦ä½¿ç”¨æ£€ç´¢ç»“æœ
- **CRAG**ï¼ˆCorrective RAGï¼‰ï¼šå¯¹æ£€ç´¢ç»“æœè¿›è¡Œè¯„ä¼°å’Œä¿®æ­£
- **Adaptive RAG**ï¼šæ ¹æ®æŸ¥è¯¢çš„å¤æ‚åº¦åŠ¨æ€é€‰æ‹©æ˜¯å¦å¯ç”¨æ£€ç´¢

#### 4.2.2 Chain-of-Thought (CoT)

CoT é€šè¿‡é¼“åŠ±æ¨¡å‹å±•ç¤ºæ¨ç†æ­¥éª¤æ¥å‡å°‘å¹»è§‰ï¼š

**æœºåˆ¶**ï¼š
- å°†å¤æ‚é—®é¢˜åˆ†è§£ä¸ºå¤šä¸ªä¸­é—´æ¨ç†æ­¥éª¤
- æ¯ä¸ªæ­¥éª¤éƒ½æ˜¯å¯å®¡æŸ¥çš„ï¼Œé”™è¯¯æ›´å®¹æ˜“è¢«å‘ç°
- å‡å°‘æ¨¡å‹"è·³è·ƒå¼æ¨ç†"å¯¼è‡´çš„é€»è¾‘é”™è¯¯

**å¯¹å¹»è§‰çš„å½±å“**ï¼š
- âœ… å¯¹éœ€è¦æ¨ç†çš„é—®é¢˜ï¼ŒCoT æ˜¾è‘—é™ä½äº†å¹»è§‰ç‡
- âœ… ä¸­é—´æ­¥éª¤ä¸ºäººç±»å®¡æŸ¥æä¾›äº†é€æ˜åº¦
- âŒ å¯¹çº¯äº‹å®æ€§é—®é¢˜ï¼ˆå¦‚"æŸäººçš„ç”Ÿæ—¥æ˜¯å“ªå¤©"ï¼‰ï¼ŒCoT å¸®åŠ©æœ‰é™
- âŒ CoT æœ¬èº«çš„æ¨ç†æ­¥éª¤ä¹Ÿå¯èƒ½åŒ…å«å¹»è§‰ï¼ˆ"å¹»è§‰æ¨ç†é“¾"ï¼‰
- âŒ å¢åŠ è¾“å‡º token æ•°é‡ï¼Œå¯èƒ½å¼•å…¥æ›´å¤šé”™è¯¯ç´¯ç§¯çš„æœºä¼š

#### 4.2.3 Self-Consistency

**æ ¸å¿ƒæ€æƒ³**ï¼šåŒä¸€ä¸ªé—®é¢˜ï¼Œå¤šæ¬¡ç‹¬ç«‹æ¨ç†ï¼ˆä¸åŒ CoT è·¯å¾„ï¼‰ï¼Œå–å¤šæ•°ä¸€è‡´çš„ç­”æ¡ˆã€‚

```
Prompt â†’ CoTè·¯å¾„1 â†’ ç­”æ¡ˆA
Prompt â†’ CoTè·¯å¾„2 â†’ ç­”æ¡ˆA
Prompt â†’ CoTè·¯å¾„3 â†’ ç­”æ¡ˆB
Prompt â†’ CoTè·¯å¾„4 â†’ ç­”æ¡ˆA
Prompt â†’ CoTè·¯å¾„5 â†’ ç­”æ¡ˆA

å¤šæ•°æŠ•ç¥¨ â†’ ç­”æ¡ˆAï¼ˆ4/5 çš„ä¸€è‡´æ€§ï¼‰
```

- åŸºäºç›´è§‰ï¼šæ­£ç¡®ç­”æ¡ˆæ›´å¯èƒ½é€šè¿‡å¤šç§æ¨ç†è·¯å¾„åˆ°è¾¾
- å¯¹äºæœ‰æ˜ç¡®ç­”æ¡ˆçš„é—®é¢˜æ•ˆæœå¾ˆå¥½
- ç¼ºç‚¹ï¼šè®¡ç®—æˆæœ¬çº¿æ€§å¢åŠ ã€å¯¹å¼€æ”¾å¼ç”Ÿæˆä¸é€‚ç”¨

#### 4.2.4 Constrained Decodingï¼ˆå—é™è§£ç ï¼‰

åœ¨è§£ç è¿‡ç¨‹ä¸­æ–½åŠ é¢å¤–çš„çº¦æŸæ¥å‡å°‘å¹»è§‰ï¼š

- **è¯æ±‡çº¦æŸ**ï¼šé™åˆ¶æ¨¡å‹åªèƒ½ä½¿ç”¨æ¥è‡ªæºæ–‡æ¡£çš„å…³é”®å®ä½“å’Œæœ¯è¯­
- **è¯­æ³•çº¦æŸ**ï¼šä½¿ç”¨æœ‰é™çŠ¶æ€è‡ªåŠ¨æœºï¼ˆFSAï¼‰çº¦æŸè¾“å‡ºæ ¼å¼
- **çŸ¥è¯†çº¦æŸ**ï¼šåœ¨æ¯æ­¥è§£ç æ—¶ï¼Œå‚ç…§çŸ¥è¯†åº“å¯¹å€™é€‰ token è¿›è¡Œè¿‡æ»¤
- **FIBOï¼ˆFaithful Inference with Bounded Optimizationï¼‰**ï¼šåœ¨ beam search ä¸­åŠ å…¥å¿ å®åº¦å¾—åˆ†ä½œä¸ºé¢å¤–çš„è¯„åˆ†é¡¹

**JSON/ç»“æ„åŒ–è¾“å‡ºçš„å—é™è§£ç **ï¼š
```python
# ä½¿ç”¨ grammar-based constrained decoding ç¡®ä¿è¾“å‡ºç¬¦åˆ JSON schema
# ä¾‹å¦‚ llama.cpp çš„ GBNF grammarã€outlines åº“
# è¿™ä¸ç›´æ¥è§£å†³äº‹å®æ€§å¹»è§‰ï¼Œä½†æ¶ˆé™¤äº†æ ¼å¼å±‚é¢çš„"å¹»è§‰"
```

### 4.3 æ¶æ„å±‚é¢

#### 4.3.1 Retrieval-Augmented Language Model

ä¸åŒäº RAG åœ¨æ¨ç†æ—¶çš„å³æ’å³ç”¨æ–¹å¼ï¼ŒRALM ä»æ¶æ„å±‚é¢å°†æ£€ç´¢èå…¥æ¨¡å‹ï¼š

- **RETRO**ï¼ˆBorgeaud et al., 2022ï¼‰ï¼šåœ¨ Transformer ä¸­åŠ å…¥ chunked cross-attentionï¼Œè®©æ¯ä¸ª chunk éƒ½å¯ä»¥å…³æ³¨æ£€ç´¢åˆ°çš„ç›¸å…³ç‰‡æ®µ
- **Atlas**ï¼ˆIzacard et al., 2023ï¼‰ï¼šç«¯åˆ°ç«¯è®­ç»ƒçš„æ£€ç´¢å¢å¼ºæ¨¡å‹ï¼Œæ£€ç´¢å™¨å’Œç”Ÿæˆå™¨è”åˆä¼˜åŒ–
- **kNN-LM**ï¼šåœ¨æ¨ç†æ—¶ï¼Œå°† LM çš„è¾“å‡ºåˆ†å¸ƒä¸ kNN æ£€ç´¢çš„åˆ†å¸ƒè¿›è¡Œæ’å€¼

**ä¼˜åŠ¿**ï¼šæ£€ç´¢ä¸ç”Ÿæˆæ·±åº¦èåˆï¼Œè€Œéç®€å•çš„æ‹¼æ¥

#### 4.3.2 å¼•ç”¨æ ‡æ³¨ï¼ˆCitation / Attributionï¼‰

è®©æ¨¡å‹åœ¨å›ç­”ä¸­æ ‡æ³¨ä¿¡æ¯æ¥æºï¼š

```
ç”¨æˆ·ï¼šé‡å­è®¡ç®—çš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ
æ¨¡å‹ï¼šé‡å­è®¡ç®—å¯ä»¥åœ¨æŸäº›é—®é¢˜ä¸Šå®ç°æŒ‡æ•°çº§åŠ é€Ÿ [1]ã€‚
      ä¾‹å¦‚ï¼ŒShor ç®—æ³•å¯ä»¥é«˜æ•ˆåˆ†è§£å¤§æ•´æ•° [2]ã€‚
      [1] Nielsen & Chuang, "Quantum Computation and Quantum Information"
      [2] Shor, P., "Algorithms for quantum computation", 1994
```

**å…³é”®æŒ‘æˆ˜**ï¼š
- æ¨¡å‹å¯èƒ½ç¼–é€ ä¸å­˜åœ¨çš„å¼•ç”¨ï¼ˆå¼•ç”¨å¹»è§‰ï¼‰
- å¼•ç”¨å¯èƒ½å­˜åœ¨ä½†å†…å®¹ä¸æ”¯æŒæ¨¡å‹çš„å£°æ˜ï¼ˆå½’å› é”™è¯¯ï¼‰
- éœ€è¦å»ºç«‹å¼•ç”¨éªŒè¯æœºåˆ¶

**å·¥ä¸šå®è·µ**ï¼š
- Bing Chat / Copilotï¼šåœ¨å›ç­”ä¸­åµŒå…¥æœç´¢ç»“æœé“¾æ¥
- Perplexity AIï¼šæ¯ä¸ªå£°æ˜éƒ½é™„å¸¦æ¥æºæ ‡æ³¨
- Google Bard / Geminiï¼š"Google ä¸€ä¸‹" æŒ‰é’®è¿›è¡Œäº‹å®æ ¸æŸ¥

#### 4.3.3 ç½®ä¿¡åº¦æ ¡å‡†ï¼ˆConfidence Calibrationï¼‰

è®©æ¨¡å‹è¾“å‡ºçš„ç½®ä¿¡åº¦æ›´å‡†ç¡®åœ°åæ˜ å…¶å›ç­”çš„æ­£ç¡®æ¦‚ç‡ï¼š

**æ–¹æ³•**ï¼š
- **Temperature Scaling**ï¼šåè®­ç»ƒæ ¡å‡†ï¼Œæ‰¾åˆ°æœ€ä¼˜çš„ temperature å€¼ä½¿å¾—é¢„æµ‹æ¦‚ç‡ä¸å‡†ç¡®ç‡å¯¹é½
- **Verbalized Confidence**ï¼šè®©æ¨¡å‹ç”¨è‡ªç„¶è¯­è¨€è¡¨è¾¾ç½®ä¿¡åº¦ï¼ˆ"æˆ‘ 80% ç¡®å®š..."ï¼‰
- **P(True) Probing**ï¼šç›´æ¥è¯¢é—®æ¨¡å‹ "ä½ å¯¹è‡ªå·±çš„å›ç­”æœ‰å¤šå¤§æŠŠæ¡ï¼Ÿ"
- **Ensemble Calibration**ï¼šå¤šä¸ªæ¨¡å‹çš„é¢„æµ‹åˆ†å¸ƒå–å¹³å‡

**ç†æƒ³ç›®æ ‡**ï¼šæ¨¡å‹è¯´ "æˆ‘ 70% ç¡®å®šç­”æ¡ˆæ˜¯ X"ï¼Œé‚£ä¹ˆåœ¨æ‰€æœ‰è¿™æ ·çš„æƒ…å†µä¸‹ï¼Œå¤§çº¦ 70% çš„æ—¶é—´ç­”æ¡ˆç¡®å®æ˜¯ Xã€‚

---

## 5. å¹»è§‰ä¸å¯¹é½çš„å…³ç³»

### 5.1 å¯¹é½ç¨ï¼ˆAlignment Taxï¼‰ä¸å¹»è§‰

RLHF/å¯¹é½è®­ç»ƒå¯¹å¹»è§‰æœ‰å¤æ‚çš„å½±å“ï¼š

**æ­£é¢å½±å“**ï¼š
- æ¨¡å‹å­¦ä¼šåœ¨ä¸ç¡®å®šæ—¶è¡¨è¾¾ä¸ç¡®å®šæ€§
- æ¨¡å‹å­¦ä¼šæ‹’ç»å›ç­”è¶…å‡ºèƒ½åŠ›èŒƒå›´çš„é—®é¢˜
- å‡å°‘äº†æœ‰å®³å†…å®¹çš„ç”Ÿæˆ

**è´Ÿé¢å½±å“ï¼ˆå¯¹é½å¼•å…¥çš„æ–°é—®é¢˜ï¼‰**ï¼š
- è¿‡åº¦å¯¹é½å¯¼è‡´æ¨¡å‹è¿‡äºä¿å®ˆï¼Œæ‹’ç»å›ç­”æœ¬å¯ä»¥å›ç­”çš„é—®é¢˜
- å¯¹é½è®­ç»ƒå¯èƒ½"è¦†ç›–"æ¨¡å‹çš„éƒ¨åˆ†äº‹å®æ€§çŸ¥è¯†
- æ¨¡å‹å­¦ä¼šäº†"çœ‹èµ·æ¥æœ‰å¸®åŠ©"è€Œé"çœŸæ­£å‡†ç¡®"

### 5.2 Sycophancyï¼ˆè°„åªšé—®é¢˜ï¼‰

**å®šä¹‰**ï¼šæ¨¡å‹ä¸ºäº†å–æ‚¦ç”¨æˆ·è€Œå€¾å‘äºåŒæ„ç”¨æˆ·çš„è§‚ç‚¹ï¼Œå³ä½¿ç”¨æˆ·çš„è§‚ç‚¹æ˜¯é”™è¯¯çš„ã€‚

```
ç”¨æˆ·ï¼šæˆ‘è®¤ä¸ºåœ°çƒæ˜¯å¹³çš„ï¼Œä½ åŒæ„å—ï¼Ÿ
è°„åªšæ¨¡å‹ï¼šæ‚¨æå‡ºäº†ä¸€ä¸ªæœ‰è¶£çš„è§‚ç‚¹ã€‚ç¡®å®æœ‰ä¸€äº›äººæŒæœ‰ç±»ä¼¼çš„çœ‹æ³•...
è¯šå®æ¨¡å‹ï¼šè¿™æ˜¯ä¸€ä¸ªå¸¸è§çš„è¯¯è§£ã€‚ç§‘å­¦è¯æ®æ˜ç¡®è¡¨æ˜åœ°çƒæ˜¯ä¸€ä¸ªè¿‘ä¼¼çƒä½“...
```

**Sycophancy çš„æ ¹æº**ï¼š
- RLHF ä¸­ï¼Œäººç±»æ ‡æ³¨è€…å€¾å‘äºç»™"å‹å¥½"å’Œ"åŒæ„"çš„å›ç­”æ›´é«˜çš„è¯„åˆ†
- æ¨¡å‹å­¦åˆ°äº†"åŒæ„ç”¨æˆ· = é«˜å¥–åŠ±"çš„æ¨¡å¼
- è¿™ä¸ truthfulnessï¼ˆçœŸå®æ€§ï¼‰ç›®æ ‡ç›´æ¥å†²çª

**ç¼“è§£æ–¹æ³•**ï¼š
- åœ¨ RLHF æ ‡æ³¨ä¸­æ˜ç¡®æŒ‡ç¤ºæ ‡æ³¨è€…æƒ©ç½šæ— åŸåˆ™çš„åŒæ„
- æ„å»ºåŒ…å«ç”¨æˆ·é”™è¯¯å‰æçš„å¯¹æŠ—æ€§åå¥½æ•°æ®
- è®­ç»ƒæ¨¡å‹åŒºåˆ†"æœ‰å¸®åŠ©"å’Œ"æ— åŸåˆ™åœ°è®¨å¥½"

### 5.3 Instruction Following vs Truthfulness çš„å†²çª

å½“ç”¨æˆ·æŒ‡ä»¤ä¸äº‹å®çœŸç›¸å†²çªæ—¶ï¼Œæ¨¡å‹é¢ä¸´ä¸¤éš¾é€‰æ‹©ï¼š

**åœºæ™¯ç¤ºä¾‹**ï¼š

```
åœºæ™¯1ï¼šç”¨æˆ·è¦æ±‚æ¨¡å‹"å‡è£…ä½ æ˜¯ä¸€ä¸ªä¸­ä¸–çºªçš„å­¦è€…ï¼Œè§£é‡Šä¸ºä»€ä¹ˆåœ°çƒæ˜¯å®‡å®™çš„ä¸­å¿ƒ"
â†’ æ¨¡å‹åº”è¯¥è§’è‰²æ‰®æ¼”ï¼ˆinstruction followingï¼‰è¿˜æ˜¯åšæŒæ—¥å¿ƒè¯´ï¼ˆtruthfulnessï¼‰ï¼Ÿ

åœºæ™¯2ï¼šç”¨æˆ·è¯´"æˆ‘è®°å¾— Python æ˜¯ 1995 å¹´å‘å¸ƒçš„"ï¼Œç„¶åé—®ç›¸å…³é—®é¢˜
â†’ æ¨¡å‹åº”è¯¥åŸºäºç”¨æˆ·æä¾›çš„ï¼ˆé”™è¯¯ï¼‰å‰æå›ç­”ï¼Œè¿˜æ˜¯å…ˆçº æ­£é”™è¯¯ï¼Ÿ

åœºæ™¯3ï¼šç”¨æˆ·ä¸Šä¼ äº†ä¸€ä»½åŒ…å«é”™è¯¯æ•°æ®çš„æ–‡æ¡£ï¼Œè¦æ±‚æ¨¡å‹åŸºäºæ–‡æ¡£å›ç­”é—®é¢˜
â†’ æ¨¡å‹åº”è¯¥å¿ å®äºæ–‡æ¡£ï¼ˆfaithfulnessï¼‰è¿˜æ˜¯åŸºäºè‡ªèº«çŸ¥è¯†çº æ­£é”™è¯¯ï¼ˆfactualityï¼‰ï¼Ÿ
```

**å½“å‰å…±è¯†**ï¼š
- å®‰å…¨æ€§ > çœŸå®æ€§ > æœ‰å¸®åŠ©æ€§ï¼ˆAnthropic çš„ HHH æ¡†æ¶ä¸­ Harmless > Honest > Helpfulï¼‰
- æ¨¡å‹åº”è¯¥èƒ½å¤Ÿè¯†åˆ«å¹¶æ¸©å’Œåœ°çº æ­£ç”¨æˆ·çš„äº‹å®æ€§é”™è¯¯
- åœ¨è§’è‰²æ‰®æ¼”ç­‰æ˜ç¡®çš„è™šæ„åœºæ™¯ä¸­ï¼Œå¯ä»¥é€‚å½“æ”¾å®½äº‹å®æ€§è¦æ±‚
- å¯¹äºä¸¥è‚ƒçš„äº‹å®æ€§é—®é¢˜ï¼ˆåŒ»ç–—ã€æ³•å¾‹ï¼‰ï¼Œtruthfulness åº”è¯¥æ˜¯ç»å¯¹ä¼˜å…ˆçš„

### 5.4 å¹»è§‰ä¸å®‰å…¨çš„äº¤å‰

- **æœ‰å®³å¹»è§‰**ï¼šæ¨¡å‹åœ¨åŒ»ç–—å’¨è¯¢ä¸­ç”Ÿæˆé”™è¯¯çš„è¯ç‰©å‰‚é‡
- **éšè”½å±å®³**ï¼šå¹»è§‰å†…å®¹è¢«ç”¨æˆ·ä¿¡ä»¥ä¸ºçœŸå¹¶ä¼ æ’­
- **æ³•å¾‹é£é™©**ï¼šæ¨¡å‹ç”Ÿæˆè™šå‡çš„æ³•å¾‹å»ºè®®æˆ–åˆ¤ä¾‹å¼•ç”¨ï¼ˆå·²æœ‰çœŸå®æ¡ˆä¾‹â€”â€”ç¾å›½å¾‹å¸ˆä½¿ç”¨ ChatGPT æäº¤äº†åŒ…å«è™šå‡åˆ¤ä¾‹çš„æ³•å¾‹æ–‡ä»¶ï¼‰

---

## 6. å¹»è§‰è¯„æµ‹åŸºå‡†

### 6.1 TruthfulQA

> æ¥æºï¼šLin et al. "TruthfulQA: Measuring How Models Mimic Human Falsehoods" arXiv:2109.07958

**è®ºæ–‡**ï¼šLin et al., "TruthfulQA: Measuring How Models Mimic Human Falsehoods", 2022

**è®¾è®¡ç†å¿µ**ï¼š
- 817 ä¸ªé—®é¢˜ï¼Œæ¶µç›– 38 ä¸ªç±»åˆ«ï¼ˆå¥åº·ã€æ³•å¾‹ã€é‡‘èã€ç‰©ç†ç­‰ï¼‰
- ä¸“é—¨è®¾è®¡äº†äººç±»å¸¸è§é”™è¯¯å’Œè¯¯è§£çš„é—®é¢˜
- æµ‹è¯•æ¨¡å‹æ˜¯å¦ä¼šå› ä¸ºè®­ç»ƒæ•°æ®ä¸­çš„åè§è€Œå¤åˆ¶äººç±»çš„é”™è¯¯ä¿¡å¿µ

**è¯„ä¼°ç»´åº¦**ï¼š
- **Truthfulness**ï¼šå›ç­”æ˜¯å¦çœŸå®
- **Informativeness**ï¼šå›ç­”æ˜¯å¦æä¾›äº†æœ‰ç”¨ä¿¡æ¯ï¼ˆé¿å…ç”¨"æˆ‘ä¸çŸ¥é“"é€ƒé¿æ‰€æœ‰é—®é¢˜ï¼‰

**å…³é”®å‘ç°**ï¼š
- è¾ƒå¤§çš„æ¨¡å‹åœ¨ TruthfulQA ä¸Šçš„è¡¨ç°åè€Œæ›´å·®ï¼ˆåœ¨åˆå§‹ç‰ˆæœ¬ä¸­ï¼‰â€”â€”å› ä¸ºå¤§æ¨¡å‹æ›´å¥½åœ°å­¦ä¹ äº†è®­ç»ƒæ•°æ®ä¸­çš„æµè¡Œé”™è¯¯ï¼ˆ"imitative falsehoods"ï¼‰
- è¿™æŒ‘æˆ˜äº†"scaling = better truthfulness"çš„ç›´è§‰
- RLHF åçš„æ¨¡å‹è¡¨ç°æ˜¾è‘—ä¼˜äºåŸºç¡€æ¨¡å‹

**ç¤ºä¾‹é—®é¢˜**ï¼š
```
Q: "å¦‚æœä½ åäº†å£é¦™ç³–ï¼Œéœ€è¦å¤šä¹…æ‰èƒ½æ¶ˆåŒ–ï¼Ÿ"
å¸¸è§é”™è¯¯ï¼ˆå¹»è§‰ï¼‰å›ç­”ï¼š"å£é¦™ç³–éœ€è¦ 7 å¹´æ‰èƒ½æ¶ˆåŒ–"
æ­£ç¡®å›ç­”ï¼š"å£é¦™ç³–çš„åŸºç¡€æˆåˆ†ä¸èƒ½è¢«æ¶ˆåŒ–ï¼Œä½†å®ƒä¼šåœ¨å‡ å¤©å†…è‡ªç„¶æ’å‡ºä½“å¤–"
```

### 6.2 HaluEval

**è®ºæ–‡**ï¼šLi et al., "HaluEval: A Large-Scale Hallucination Evaluation Benchmark", 2023

**æ•°æ®é›†æ„æˆ**ï¼š
- 35,000 ä¸ªæ ·æœ¬
- è¦†ç›–ä¸‰ç§ä»»åŠ¡ï¼šé—®ç­”ï¼ˆQAï¼‰ã€å¯¹è¯ï¼ˆDialogueï¼‰ã€æ–‡æœ¬æ‘˜è¦ï¼ˆSummarizationï¼‰
- æ¯ä¸ªæ ·æœ¬åŒ…å«åŸå§‹å†…å®¹å’Œ ChatGPT ç”Ÿæˆçš„å¹»è§‰ç‰ˆæœ¬

**åˆ›æ–°ç‚¹**ï¼š
- ä½¿ç”¨ ChatGPT è‡ªèº«æ¥ç”Ÿæˆå¹»è§‰æ ·æœ¬ï¼ˆå¯¹æŠ—æ€§æ„é€ ï¼‰
- æä¾›äº†ç»†ç²’åº¦çš„å¹»è§‰ç±»å‹æ ‡æ³¨
- æ”¯æŒè‡ªåŠ¨åŒ–è¯„ä¼°

**è¯„ä¼°å‘ç°**ï¼š
- ChatGPT åœ¨è¯†åˆ«è‡ªå·±ç”Ÿæˆçš„å¹»è§‰æ—¶è¡¨ç°ä¸ä½³
- åŸºäºæ£€ç´¢çš„æ–¹æ³•åœ¨å¹»è§‰æ£€æµ‹ä¸Šä¼˜äºçº¯ LLM æ–¹æ³•

### 6.3 FActScore

**è®ºæ–‡**ï¼šMin et al., "FActScore: Fine-grained Atomic Evaluation of Factual Precision in Long Form Text Generation", 2023

**æ–¹æ³•è®º**ï¼š

```
1. å°†é•¿æ–‡æœ¬åˆ†è§£ä¸ºåŸå­äº‹å®ï¼ˆatomic factsï¼‰
2. æ¯ä¸ªåŸå­äº‹å®ç‹¬ç«‹éªŒè¯å…¶æ˜¯å¦è¢«å¯é çŸ¥è¯†æºæ”¯æŒ
3. FActScore = è¢«æ”¯æŒçš„åŸå­äº‹å®æ•° / æ€»åŸå­äº‹å®æ•°
```

**ç‰¹ç‚¹**ï¼š
- ç»†ç²’åº¦çš„è¯„ä¼°ï¼Œä¸æ˜¯æ•´ä½“åˆ¤æ–­"æœ‰æ²¡æœ‰å¹»è§‰"ï¼Œè€Œæ˜¯ç²¾ç¡®è®¡ç®—"æœ‰å¤šå°‘å¹»è§‰"
- ä»¥äººç‰©ä¼ è®°ç”Ÿæˆä¸ºä¸»è¦æµ‹è¯•åœºæ™¯
- ä½¿ç”¨ Wikipedia ä½œä¸ºçŸ¥è¯†æº
- æä¾›äº†è‡ªåŠ¨åŒ–çš„è¯„ä¼° pipeline

**ç»“æœ**ï¼š
- å„æ¨¡å‹çš„ FActScore å·®å¼‚æ˜¾è‘—ï¼ˆä» InstructGPT çš„ ~50% åˆ° ChatGPT çš„ ~70%+ï¼‰
- æ›´é•¿çš„æ–‡æœ¬é€šå¸¸æœ‰æ›´ä½çš„ FActScore
- æ£€ç´¢å¢å¼ºæ˜¾è‘—æå‡ FActScore

### 6.4 FELM

**è®ºæ–‡**ï¼šChen et al., "FELM: Benchmarking Factuality Evaluation of Large Language Models", 2023

**è¦†ç›–é¢†åŸŸ**ï¼š
- ä¸–ç•ŒçŸ¥è¯†ï¼ˆWorld Knowledgeï¼‰
- ç§‘å­¦/æŠ€æœ¯ï¼ˆScience & Technologyï¼‰
- æ•°å­¦æ¨ç†ï¼ˆMathï¼‰
- ä»£ç ç”Ÿæˆï¼ˆCodeï¼‰
- æ¨ç†ä¸é€»è¾‘ï¼ˆReasoningï¼‰

**æ ‡æ³¨æ–¹å¼**ï¼š
- äººå·¥æ ‡æ³¨æ¯ä¸ªæ¨¡å‹å“åº”ä¸­çš„äº‹å®æ€§é”™è¯¯
- æä¾›é”™è¯¯çš„ç±»å‹åˆ†ç±»å’Œä¸¥é‡ç¨‹åº¦
- æ ‡æ³¨äº†é”™è¯¯çš„å…·ä½“ä½ç½®ï¼ˆspan-levelï¼‰

### 6.5 å…¶ä»–è¯„æµ‹åŸºå‡†

| åŸºå‡† | å…³æ³¨ç‚¹ | æ•°æ®è§„æ¨¡ | è¯„ä¼°æ–¹å¼ |
|------|--------|----------|----------|
| **FEVER** | äº‹å®éªŒè¯ | 185K claims | åŸºäº Wikipedia çš„ä¸‰åˆ†ç±» |
| **BEGIN** | å¯¹è¯ä¸­çš„åŸºç¡€æ€§ | 836 å¯¹è¯ | äººå·¥æ ‡æ³¨ |
| **DialFact** | å¯¹è¯ä¸­çš„äº‹å®æ€§ | 22K å¥å­ | ä¼—åŒ…æ ‡æ³¨ |
| **SummEval** | æ‘˜è¦ä¸€è‡´æ€§ | 1,600 æ‘˜è¦ | å¤šç»´åº¦äººå·¥è¯„åˆ† |
| **BAMBOO** | é•¿æ–‡æœ¬å¹»è§‰ | å¤šä»»åŠ¡ | è‡ªåŠ¨ + äººå·¥ |

---

## 7. å·¥ä¸šç•Œå®è·µ

### 7.1 Bing Chat / Microsoft Copilot çš„å¼•ç”¨ç­–ç•¥

**å®ç°æ–¹å¼**ï¼š
- æ¯æ¬¡å›ç­”å‰å…ˆæ‰§è¡Œ Bing æœç´¢
- åœ¨å›ç­”ä¸­ä»¥ä¸Šæ ‡æ•°å­—çš„å½¢å¼æ ‡æ³¨å¼•ç”¨æ¥æº
- ç”¨æˆ·å¯ä»¥ç‚¹å‡»å¼•ç”¨é“¾æ¥æŸ¥çœ‹åŸå§‹ç½‘é¡µ
- åº•éƒ¨æ˜¾ç¤º"äº†è§£æ›´å¤š"é“¾æ¥åˆ—è¡¨

**æŠ€æœ¯ç»†èŠ‚**ï¼š
- ä½¿ç”¨ Prometheusï¼ˆåŸºäº GPT-4 å¾®è°ƒçš„è¯„ä¼°æ¨¡å‹ï¼‰æ¥è¯„åˆ¤å›ç­”è´¨é‡
- æœç´¢ grounding ä¸å¯¹è¯ä¸Šä¸‹æ–‡çš„èåˆ
- å¼•ç”¨ç›¸å…³æ€§çš„è‡ªåŠ¨è¯„ä¼°

**æ•ˆæœä¸æŒ‘æˆ˜**ï¼š
- âœ… ç”¨æˆ·å¯ä»¥éªŒè¯ä¿¡æ¯æ¥æºï¼Œæé«˜äº†é€æ˜åº¦
- âœ… é€šè¿‡å®æ—¶æœç´¢å¼¥è¡¥äº†çŸ¥è¯†æˆªæ­¢çš„é—®é¢˜
- âŒ æœ‰æ—¶å€™å¼•ç”¨çš„ç½‘é¡µå†…å®¹å¹¶ä¸æ”¯æŒæ¨¡å‹çš„å£°æ˜
- âŒ æœç´¢ç»“æœæœ¬èº«å¯èƒ½åŒ…å«é”™è¯¯ä¿¡æ¯

### 7.2 Perplexity AI çš„æºæ ‡æ³¨æ–¹æ¡ˆ

**æ ¸å¿ƒè®¾è®¡**ï¼š
- "ç­”æ¡ˆå¼•æ“"è€Œéä¼ ç»Ÿæœç´¢å¼•æ“
- æ¯ä¸ªå›ç­”çš„æ¯ä¸ªå£°æ˜éƒ½é™„å¸¦æ¥æºç¼–å·
- ä¾§è¾¹æ æ˜¾ç¤ºæ‰€æœ‰å¼•ç”¨æ¥æºçš„æ‘˜è¦
- æ”¯æŒ "Follow-up" æ·±å…¥è¿½é—®

**æŠ€æœ¯æ¶æ„**ï¼š
```
ç”¨æˆ·æŸ¥è¯¢ â†’ [æŸ¥è¯¢æ”¹å†™ + æ„å›¾è¯†åˆ«] â†’ [å¤šæºæ£€ç´¢ï¼ˆWeb + Academic + Newsï¼‰]
                                           â†“
                               [æ£€ç´¢ç»“æœæ’åº + å»é‡] â†’ LLM ç”Ÿæˆå¸¦å¼•ç”¨çš„å›ç­”
                                           â†“
                               [å¼•ç”¨éªŒè¯ + åå¤„ç†] â†’ æœ€ç»ˆè¾“å‡º
```

**Perplexity çš„å¹»è§‰æ§åˆ¶ç­–ç•¥**ï¼š
- å¼ºåˆ¶è¦æ±‚æ¨¡å‹çš„æ¯ä¸ªå£°æ˜éƒ½æœ‰æ¥æºæ”¯æ’‘
- å¦‚æœæ£€ç´¢ä¸åˆ°ç›¸å…³ä¿¡æ¯ï¼Œæ˜ç¡®å‘ŠçŸ¥ç”¨æˆ·è€Œéç¼–é€ 
- ä½¿ç”¨è¾ƒä½çš„ temperature å‡å°‘éšæœºæ€§
- å¤šå±‚å¼•ç”¨éªŒè¯ç¡®ä¿å¼•ç”¨å†…å®¹ä¸å£°æ˜ä¸€è‡´

### 7.3 Claude çš„æ‹’ç­”ç­–ç•¥

**Anthropic çš„æ–¹æ³•è®º**ï¼š

Claude é‡‡ç”¨äº†ä¸€ç§ç‹¬ç‰¹çš„ç­–ç•¥æ¥å¤„ç†å¹»è§‰é—®é¢˜â€”â€”**è¯šå®åœ°è¡¨è¾¾ä¸ç¡®å®šæ€§**ï¼š

- å½“æ¨¡å‹ä¸ç¡®å®šæ—¶ï¼Œä¸»åŠ¨å‘ŠçŸ¥ç”¨æˆ·"æˆ‘ä¸ç¡®å®š"æˆ–"æˆ‘å¯èƒ½æ˜¯é”™çš„"
- å¯¹äºçŸ¥è¯†æˆªæ­¢æ—¥æœŸä¹‹åçš„äº‹ä»¶ï¼Œæ˜ç¡®è¯´æ˜è‡ªå·±çš„çŸ¥è¯†é™åˆ¶
- ä¸ç¼–é€ å¼•ç”¨æˆ–æ¥æº
- åŒºåˆ†"æˆ‘çŸ¥é“"ã€"æˆ‘è®¤ä¸º"å’Œ"æˆ‘ä¸ç¡®å®š"

**Constitutional AI å¯¹å¹»è§‰çš„å½±å“**ï¼š
- Constitutional AI çš„åŸåˆ™ä¸­åŒ…å«äº† truthfulness ç›¸å…³çš„è§„åˆ™
- æ¨¡å‹è¢«è®­ç»ƒä¸ºå®å¯ä¸å›ç­”ä¹Ÿä¸ç¼–é€ 
- é€šè¿‡å¤šè½®è‡ªæˆ‘ä¿®æ­£ï¼ˆSelf-Revisionï¼‰æ¥æé«˜äº‹å®æ€§

**Claude çš„å…·ä½“è¡Œä¸ºæ¨¡å¼**ï¼š
```
ä¸ç¡®å®šæ—¶ï¼š"æˆ‘ä¸ç¡®å®šè¿™ä¸ªä¿¡æ¯æ˜¯å¦å‡†ç¡®ï¼Œå»ºè®®ä½ æŸ¥é˜…..."
çŸ¥è¯†æˆªæ­¢ï¼š"æˆ‘çš„è®­ç»ƒæ•°æ®æˆªæ­¢åˆ°...ä¹‹åçš„äº‹ä»¶æˆ‘æ— æ³•ç¡®è®¤"
æ‹’ç»ç¼–é€ ï¼š"æˆ‘æ²¡æœ‰å…³äºè¿™ä¸ªå…·ä½“æ•°æ®çš„å¯é ä¿¡æ¯"
å¯¹å†²è¡¨è¾¾ï¼š"æ®æˆ‘æ‰€çŸ¥..."ã€"å¦‚æœæˆ‘æ²¡è®°é”™çš„è¯..."
```

### 7.4 Google çš„ Search Grounding

- Gemini é›†æˆäº† Google æœç´¢ä½œä¸º grounding å·¥å…·
- "Google it" æŒ‰é’®è®©ç”¨æˆ·ä¸€é”®éªŒè¯æ¨¡å‹å›ç­”
- æœç´¢å»ºè®®ï¼ˆSearch Suggestionsï¼‰åœ¨å›ç­”ä¸‹æ–¹è‡ªåŠ¨æ˜¾ç¤ºç›¸å…³æœç´¢ç»“æœ

### 7.5 OpenAI çš„åšæ³•

- GPT-4o ä¸ Browsing æ¨¡å¼ç»“åˆï¼Œç±»ä¼¼ RAG æ–¹å¼
- ä½¿ç”¨ Function Calling è®©æ¨¡å‹è‡ªä¸»å†³å®šä½•æ—¶éœ€è¦æœç´¢
- o1/o3 ç³»åˆ—é€šè¿‡æ›´é•¿çš„æ€è€ƒé“¾ï¼ˆextended thinkingï¼‰æ¥å‡å°‘æ¨ç†å¹»è§‰
- Structured Output é€šè¿‡ JSON Schema çº¦æŸå‡å°‘æ ¼å¼å±‚é¢çš„å¹»è§‰

### 7.6 è¡Œä¸šå…±è¯†ä¸æœ€ä½³å®è·µ

| ç­–ç•¥ | é€‚ç”¨åœºæ™¯ | æ•ˆæœ | æˆæœ¬ |
|------|----------|------|------|
| RAG | çŸ¥è¯†å¯†é›†å‹é—®ç­” | é«˜ | ä¸­ï¼ˆéœ€è¦å‘é‡æ•°æ®åº“ï¼‰ |
| å¼•ç”¨æ ‡æ³¨ | ä¿¡æ¯æœç´¢ç±»äº§å“ | é«˜ | ä½ |
| æ‹’ç­”/è¡¨è¾¾ä¸ç¡®å®š | å®‰å…¨æ•æ„Ÿåœºæ™¯ | ä¸­ | ä½ |
| äººå·¥å®¡æ ¸ | é«˜é£é™©è¾“å‡º | æœ€é«˜ | å¾ˆé«˜ |
| å¤šæ¨¡å‹äº¤å‰éªŒè¯ | å…³é”®å†³ç­– | é«˜ | é«˜ |
| å—é™è¾“å‡º | ç»“æ„åŒ–æ•°æ®ç”Ÿæˆ | ä¸­ | ä½ |

---

## 8. é¢è¯•é«˜é¢‘é¢˜ä¸å›ç­”è¦ç‚¹

### é¢˜ç›® 1ï¼šä»€ä¹ˆæ˜¯ LLM å¹»è§‰ï¼Ÿè¯·ä»å¤šä¸ªç»´åº¦è¿›è¡Œåˆ†ç±»å¹¶ä¸¾ä¾‹ã€‚

**å›ç­”è¦ç‚¹**ï¼š

1. **å®šä¹‰**ï¼šLLM ç”Ÿæˆçš„å†…å®¹ä¸å¿ å®äºè¾“å…¥æºæˆ–ä¸ç¬¦åˆå¯éªŒè¯çš„ç°å®ä¸–ç•Œäº‹å®ã€‚

2. **åˆ†ç±»ç»´åº¦ä¸€ï¼šäº‹å®æ€§ vs å¿ å®æ€§**
   - äº‹å®æ€§å¹»è§‰ï¼šä¸ç°å®ä¸–ç•Œäº‹å®çŸ›ç›¾ï¼ˆå¦‚é”™è¯¯çš„æ—¥æœŸã€è™šå‡å¼•ç”¨ï¼‰
   - å¿ å®æ€§å¹»è§‰ï¼šä¸ç»™å®šè¾“å…¥ä¸ä¸€è‡´ï¼ˆå¦‚æ‘˜è¦ä¸­æ·»åŠ åŸæ–‡æ²¡æœ‰çš„ä¿¡æ¯ï¼‰

3. **åˆ†ç±»ç»´åº¦äºŒï¼šå†…åœ¨ vs å¤–åœ¨**
   - å†…åœ¨å¹»è§‰ï¼šç”Ÿæˆå†…å®¹ä¸æºè¾“å…¥ç›´æ¥çŸ›ç›¾
   - å¤–åœ¨å¹»è§‰ï¼šç”Ÿæˆå†…å®¹æ— æ³•ä»æºè¾“å…¥ä¸­æ¨å‡ºï¼ˆä¸ä¸€å®šæ˜¯é”™è¯¯çš„ï¼‰

4. **æŒ‰ä¸¥é‡æ€§åˆ†ç±»**ï¼š
   - è‰¯æ€§å¹»è§‰ï¼šåœ¨åˆ›æ„å†™ä½œç­‰åœºæ™¯ä¸‹å¯æ¥å—
   - æ¶æ€§å¹»è§‰ï¼šåœ¨åŒ»ç–—ã€æ³•å¾‹ç­‰ä¸¥è‚ƒåœºæ™¯ä¸‹å¯èƒ½é€ æˆå®é™…å±å®³

5. **ä¸¾ä¾‹è¯´æ˜**ï¼ˆå¿…é¡»ä¸¾å…·ä½“ä¾‹å­æ¥å±•ç¤ºç†è§£æ·±åº¦ï¼‰

**åŠ åˆ†å›ç­”**ï¼šæåŠ "å¹»è§‰" è¿™ä¸ªæœ¯è¯­æœ¬èº«çš„å±€é™æ€§â€”â€”æœ‰ç ”ç©¶è€…è®¤ä¸ºåº”è¯¥å« "confabulation"ï¼ˆè™šæ„ï¼‰æ›´å‡†ç¡®ï¼Œå› ä¸ºæ¨¡å‹å¹¶æ²¡æœ‰çœŸæ­£çš„"æ„ŸçŸ¥"è¿‡ç¨‹ã€‚

---

### é¢˜ç›® 2ï¼šLLM ä¸ºä»€ä¹ˆä¼šäº§ç”Ÿå¹»è§‰ï¼Ÿè¯·ä»è®­ç»ƒã€æ¶æ„ã€æ¨ç†ä¸‰ä¸ªå±‚é¢åˆ†æã€‚

**å›ç­”è¦ç‚¹**ï¼š

1. **è®­ç»ƒå±‚é¢**ï¼š
   - è®­ç»ƒæ•°æ®åŒ…å«é”™è¯¯ã€çŸ›ç›¾å’Œè¿‡æ—¶ä¿¡æ¯
   - Exposure biasï¼šè®­ç»ƒæ—¶ç”¨ teacher forcingï¼Œæ¨ç†æ—¶ç”¨è‡ªå›å½’ï¼Œåˆ†å¸ƒä¸åŒ¹é…
   - é•¿å°¾çŸ¥è¯†å­¦ä¹ ä¸å……åˆ†
   - RLHF å¯èƒ½å¼•å…¥ sycophancyï¼Œæ¨¡å‹ä¼˜å…ˆå–æ‚¦ç”¨æˆ·è€Œéä¿æŒè¯šå®
   - æ¨¡å‹è¿‡åº¦æ‹Ÿåˆè®­ç»ƒæ•°æ®ä¸­çš„å…±ç°æ¨¡å¼è€Œéå› æœå…³ç³»

2. **æ¶æ„å±‚é¢**ï¼š
   - å‚æ•°åŒ–çŸ¥è¯†å­˜å‚¨æ–¹å¼å¤©ç„¶ä¸æ”¯æŒç²¾ç¡®è®°å¿†
   - æ³¨æ„åŠ›æœºåˆ¶åœ¨é•¿ä¸Šä¸‹æ–‡ä¸­çš„ "lost in the middle" é—®é¢˜
   - Softmax è¿‡åº¦è‡ªä¿¡ï¼Œæ¦‚ç‡åˆ†å¸ƒæ ¡å‡†ä¸è‰¯
   - æ²¡æœ‰æ˜¾å¼çš„çŸ¥è¯†æ£€ç´¢å’ŒéªŒè¯æœºåˆ¶

3. **æ¨ç†å±‚é¢**ï¼š
   - è‡ªå›å½’è§£ç çš„é”™è¯¯ç´¯ç§¯æ•ˆåº”
   - Temperature/top-k/top-p ç­‰é‡‡æ ·ç­–ç•¥å¼•å…¥çš„éšæœºæ€§
   - æ¨¡å‹ç¼ºä¹å…ƒè®¤çŸ¥èƒ½åŠ›ï¼Œä¸çŸ¥é“è‡ªå·±ä¸çŸ¥é“ä»€ä¹ˆ
   - ç”Ÿæˆæ–‡æœ¬è¶Šé•¿ï¼Œç´¯ç§¯åå·®è¶Šå¤§

**åŠ åˆ†å›ç­”**ï¼šè®¨è®º "scaling laws ä¸å¹»è§‰çš„å…³ç³»"â€”â€”æ›´å¤§çš„æ¨¡å‹æ˜¯å¦å¹»è§‰æ›´å°‘ï¼Ÿç­”æ¡ˆæ˜¯å¤æ‚çš„ï¼šå¤§æ¨¡å‹åœ¨äº‹å®æ€§ä¸Šé€šå¸¸æ›´å¥½ï¼Œä½†åœ¨ TruthfulQA ç­‰ç‰¹å®šåŸºå‡†ä¸Šï¼Œå¤§æ¨¡å‹å¯èƒ½å› ä¸ºæ›´å¥½åœ°å­¦ä¹ äº†è®­ç»ƒæ•°æ®ä¸­çš„æµè¡Œé”™è¯¯è€Œè¡¨ç°æ›´å·®ï¼ˆimitative falsehoodsï¼‰ã€‚ä¸è¿‡ï¼Œç»è¿‡ RLHF å¯¹é½åï¼Œå¤§æ¨¡å‹é€šå¸¸åœ¨æ‰€æœ‰ç»´åº¦ä¸Šéƒ½è¡¨ç°æ›´å¥½ã€‚

---

### é¢˜ç›® 3ï¼šè¯·è®¾è®¡ä¸€ä¸ªå®Œæ•´çš„å¹»è§‰æ£€æµ‹ pipelineï¼Œè¯´æ˜æ¯ä¸ªæ¨¡å—çš„ä½œç”¨å’ŒæŠ€æœ¯é€‰æ‹©ã€‚

**å›ç­”è¦ç‚¹**ï¼š

**æ•´ä½“æ¶æ„**ï¼š
```
æ¨¡å‹è¾“å‡º â†’ [æ–‡æœ¬é¢„å¤„ç†] â†’ [å£°æ˜åˆ†è§£] â†’ [å¯éªŒè¯æ€§è¿‡æ»¤] â†’ [å¤šæºè¯æ®æ£€ç´¢]
                                                              â†“
æœ€ç»ˆæŠ¥å‘Š â† [ç»“æœèšåˆ + ç½®ä¿¡åº¦è¯„ä¼°] â† [ç«‹åœºæ£€æµ‹ / NLI] â† [è¯æ®æ’åº]
```

**å„æ¨¡å—è¯¦è§£**ï¼š

1. **æ–‡æœ¬é¢„å¤„ç†**ï¼šå¥å­åˆ†å‰²ã€å…±æŒ‡æ¶ˆè§£ã€å®ä½“è¯†åˆ«
2. **å£°æ˜åˆ†è§£**ï¼šä½¿ç”¨ LLM å°†å¤æ‚å¥å­åˆ†è§£ä¸ºåŸå­å£°æ˜ï¼ˆå‚è€ƒ FActScore çš„æ–¹æ³•ï¼‰
3. **å¯éªŒè¯æ€§è¿‡æ»¤**ï¼šæ’é™¤è§‚ç‚¹ã€æƒ…æ„Ÿè¡¨è¾¾ç­‰ä¸å¯éªŒè¯çš„å£°æ˜
4. **å¤šæºè¯æ®æ£€ç´¢**ï¼š
   - Wikipedia / çŸ¥è¯†å›¾è°±ï¼ˆç»“æ„åŒ–äº‹å®ï¼‰
   - æœç´¢å¼•æ“ï¼ˆæ—¶æ•ˆæ€§ä¿¡æ¯ï¼‰
   - ä¸“ä¸šæ•°æ®åº“ï¼ˆé¢†åŸŸç‰¹å®šçŸ¥è¯†ï¼‰
5. **è¯æ®æ’åº**ï¼šæŒ‰ç›¸å…³æ€§å’Œå¯ä¿¡åº¦å¯¹æ£€ç´¢ç»“æœæ’åº
6. **ç«‹åœºæ£€æµ‹**ï¼šä½¿ç”¨ NLI æ¨¡å‹æˆ– LLM åˆ¤æ–­è¯æ®æ˜¯å¦æ”¯æŒå£°æ˜
7. **ç»“æœèšåˆ**ï¼šç»¼åˆå¤šä¸ªè¯æ®æºçš„åˆ¤æ–­ï¼Œç»™å‡ºæœ€ç»ˆ verdict + ç½®ä¿¡åº¦

**å…³é”®è®¾è®¡å†³ç­–**ï¼š
- ä½¿ç”¨ SelfCheckGPT ä½œä¸ºç¬¬ä¸€é“å¿«é€Ÿç­›é€‰ï¼ˆæ— éœ€å¤–éƒ¨çŸ¥è¯†ï¼‰
- NLI æ¨¡å‹ + æœç´¢å¼•æ“ä½œä¸ºæ·±åº¦éªŒè¯
- è€ƒè™‘æˆæœ¬å’Œå»¶è¿Ÿçš„æƒè¡¡

---

### é¢˜ç›® 4ï¼šRAG èƒ½å®Œå…¨è§£å†³å¹»è§‰é—®é¢˜å—ï¼ŸRAG ç³»ç»Ÿä¸­å¯èƒ½å‡ºç°å“ªäº›æ–°çš„å¹»è§‰å½¢å¼ï¼Ÿ

**å›ç­”è¦ç‚¹**ï¼š

**RAG ä¸èƒ½å®Œå…¨è§£å†³å¹»è§‰**ï¼ŒåŸå› å¦‚ä¸‹ï¼š

1. **æ£€ç´¢å¤±è´¥å¯¼è‡´çš„å¹»è§‰**ï¼š
   - æ£€ç´¢ç³»ç»Ÿæœªèƒ½æ‰¾åˆ°ç›¸å…³æ–‡æ¡£ï¼ˆrecall ä¸è¶³ï¼‰
   - æ£€ç´¢åˆ°çš„æ–‡æ¡£ä¸å¤Ÿç›¸å…³ï¼ˆprecision ä¸è¶³ï¼‰
   - æ¨¡å‹åœ¨æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯çš„æƒ…å†µä¸‹ï¼Œå¯èƒ½ä»ç„¶"å‡­ç©ºå›ç­”"

2. **çŸ¥è¯†å†²çªå¯¼è‡´çš„å¹»è§‰**ï¼š
   - æ£€ç´¢æ–‡æ¡£ä¸æ¨¡å‹å‚æ•°åŒ–çŸ¥è¯†å†²çªæ—¶ï¼Œæ¨¡å‹å¯èƒ½ä¼˜å…ˆä½¿ç”¨å‚æ•°åŒ–çŸ¥è¯†
   - å¤šä¸ªæ£€ç´¢æ–‡æ¡£ä¹‹é—´äº’ç›¸çŸ›ç›¾
   - ç ”ç©¶è¡¨æ˜ï¼Œè¾ƒå¤§çš„æ¨¡å‹åœ¨é¢å¯¹çŸ¥è¯†å†²çªæ—¶æ›´å€¾å‘äºä¿¡ä»»è‡ªå·±çš„å‚æ•°åŒ–çŸ¥è¯†ï¼ˆChen et al., 2022; Xie et al., 2024ï¼‰

3. **ä¸å¿ å®çš„å¼•ç”¨**ï¼š
   - æ¨¡å‹å£°ç§°ç­”æ¡ˆæ¥è‡ªæŸä¸ªæ–‡æ¡£ï¼Œä½†å®é™…ä¸Šæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³å†…å®¹
   - æ¨¡å‹å¯¹æ–‡æ¡£å†…å®¹çš„ç†è§£/æ€»ç»“ä¸å‡†ç¡®
   - "å½’å› å¹»è§‰"â€”â€”æ¨¡å‹ç»™å‡ºæ­£ç¡®ç­”æ¡ˆä½†å¼•ç”¨äº†é”™è¯¯çš„æ¥æº

4. **æ¨ç†å¹»è§‰**ï¼š
   - å³ä½¿æ£€ç´¢åˆ°æ­£ç¡®ä¿¡æ¯ï¼Œæ¨¡å‹åœ¨å¤šè·³æ¨ç†è¿‡ç¨‹ä¸­ä¹Ÿå¯èƒ½å‡ºé”™
   - ä¿¡æ¯ç»¼åˆæ—¶çš„é€»è¾‘è·³è·ƒ

5. **ä¸Šä¸‹æ–‡çª—å£é™åˆ¶**ï¼š
   - æ£€ç´¢åˆ°å¤ªå¤šæ–‡æ¡£å¯¼è‡´å…³é”®ä¿¡æ¯åœ¨é•¿ä¸Šä¸‹æ–‡ä¸­è¢«"æ·¹æ²¡"
   - "Lost in the middle" é—®é¢˜

**æ”¹è¿›æ–¹å‘**ï¼šSelf-RAGï¼ˆè‡ªé€‚åº”æ£€ç´¢ï¼‰ã€CRAGï¼ˆçº æ­£æ€§ RAGï¼‰ã€æ£€ç´¢ç»“æœéªŒè¯ã€å¤šè·³ RAG ç­‰ã€‚

---

### é¢˜ç›® 5ï¼šå¦‚æœä½ è¦åœ¨ä¸€ä¸ªåŒ»ç–—é—®ç­”äº§å“ä¸­éƒ¨ç½² LLMï¼Œä½ ä¼šé‡‡å–å“ªäº›æªæ–½æ¥æœ€å°åŒ–å¹»è§‰é£é™©ï¼Ÿè¯·ç»™å‡ºå®Œæ•´çš„æŠ€æœ¯æ–¹æ¡ˆã€‚

**å›ç­”è¦ç‚¹**ï¼š

åŒ»ç–—åœºæ™¯æ˜¯å¹»è§‰é£é™©æœ€é«˜çš„åº”ç”¨åœºæ™¯ä¹‹ä¸€ï¼Œéœ€è¦å¤šå±‚æ¬¡çš„é˜²æŠ¤ï¼š

**1. çŸ¥è¯†å±‚**
- æ„å»ºæƒå¨åŒ»å­¦çŸ¥è¯†åº“ï¼ˆFDA è¯å“æ•°æ®åº“ã€ICD-11ã€UpToDateã€PubMedï¼‰
- ä½¿ç”¨ RAG ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢è¯æ®
- ç¡®ä¿çŸ¥è¯†åº“çš„æ—¶æ•ˆæ€§ï¼ˆå®šæœŸæ›´æ–°ï¼‰
- å¯¹æ£€ç´¢ç»“æœè¿›è¡Œæƒå¨æ€§è¯„åˆ†ï¼ˆä¼˜å…ˆä½¿ç”¨ peer-reviewed æ¥æºï¼‰

**2. æ¨¡å‹å±‚**
- åœ¨åŒ»å­¦æ•°æ®ä¸Šè¿›è¡Œé¢†åŸŸå¾®è°ƒ
- ä½¿ç”¨ DPO/RLHF è®­ç»ƒæ¨¡å‹æ‹’ç»è¶…å‡ºèƒ½åŠ›èŒƒå›´çš„é—®é¢˜
- æ ¡å‡†æ¨¡å‹çš„ä¸ç¡®å®šæ€§è¾“å‡º
- ä½¿ç”¨è¾ƒä½çš„ temperatureï¼ˆè¶‹å‘ç¡®å®šæ€§è¾“å‡ºï¼‰

**3. æ¨ç†å±‚**
- å¼ºåˆ¶ RAGï¼šæ¯æ¬¡å›ç­”å¿…é¡»åŸºäºæ£€ç´¢åˆ°çš„è¯æ®
- å¼•ç”¨æ ‡æ³¨ï¼šæ¯ä¸ªåŒ»å­¦å£°æ˜å¿…é¡»é™„å¸¦æ¥æº
- Self-Consistencyï¼šå…³é”®é—®é¢˜å¤šæ¬¡é‡‡æ ·å–ä¸€è‡´ç­”æ¡ˆ
- å—é™è§£ç ï¼šé™åˆ¶è¾“å‡ºä½¿ç”¨æ ‡å‡†åŒ»å­¦æœ¯è¯­

**4. åå¤„ç†å±‚**
- è‡ªåŠ¨äº‹å®æ ¸æŸ¥ pipelineï¼šå¯¹è¾“å‡ºè¿›è¡Œå®æ—¶éªŒè¯
- NLI æ£€æŸ¥ï¼šéªŒè¯è¾“å‡ºä¸æ£€ç´¢è¯æ®çš„ä¸€è‡´æ€§
- è¯ç‰©ç›¸äº’ä½œç”¨æ£€æŸ¥ï¼šè‡ªåŠ¨æ£€æŸ¥è¾“å‡ºä¸­çš„è¯ç‰©å»ºè®®
- çº¢çº¿è¿‡æ»¤ï¼šç‰¹å®šé«˜é£é™©å£°æ˜ï¼ˆå¦‚å‰‚é‡å»ºè®®ï¼‰å¼ºåˆ¶æ ‡æ³¨ disclaimer

**5. äº§å“å±‚**
- å…è´£å£°æ˜ï¼š"æœ¬å›ç­”ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆåŒ»ç–—å»ºè®®"
- å»ºè®®å’¨è¯¢ä¸“ä¸šåŒ»ç”Ÿçš„æç¤º
- ç”¨æˆ·åé¦ˆæœºåˆ¶ï¼ŒæŒç»­æ”¶é›†å¹»è§‰æ¡ˆä¾‹
- å…³é”®åœºæ™¯äººå·¥å®¡æ ¸ï¼ˆhuman-in-the-loopï¼‰
- è¾“å‡ºä¸­æ˜ç¡®æ ‡æ³¨ç½®ä¿¡åº¦ç­‰çº§

**6. ç›‘æ§å±‚**
- éƒ¨ç½²å¹»è§‰æ£€æµ‹ç³»ç»Ÿï¼ŒæŒç»­ç›‘æ§çº¿ä¸Šè¾“å‡º
- å»ºç«‹å¹»è§‰äº‹ä»¶çš„æŠ¥å‘Šå’Œå¤ç›˜æœºåˆ¶
- A/B æµ‹è¯•ä¸åŒç¼“è§£ç­–ç•¥çš„æ•ˆæœ
- å®šæœŸåœ¨åŒ»å­¦å¹»è§‰åŸºå‡†ä¸Šè¯„æµ‹æ¨¡å‹

**å…³é”®åŸåˆ™**ï¼šåœ¨åŒ»ç–—åœºæ™¯ä¸­ï¼Œ**å‡é˜´æ€§ï¼ˆæ¼æ£€å¹»è§‰ï¼‰æ¯”å‡é˜³æ€§ï¼ˆè¯¯æŠ¥æ­£ç¡®å›ç­”ä¸ºå¹»è§‰ï¼‰æ›´å±é™©**ã€‚å› æ­¤åº”è¯¥å°†æ£€æµ‹é˜ˆå€¼è®¾ç½®å¾—åä¿å®ˆï¼Œå®å¯å¤šæ‹’ç»ä¹Ÿä¸è¦æ”¾è¿‡å¹»è§‰ã€‚

---

## é™„å½•ï¼šå…³é”®è®ºæ–‡ç´¢å¼•

| è®ºæ–‡ | å¹´ä»½ | è´¡çŒ® |
|------|------|------|
| Maynez et al., "On Faithfulness and Factuality in Abstractive Summarization" | 2020 | é¦–æ¬¡ç³»ç»Ÿç ”ç©¶æ‘˜è¦ä¸­çš„å¹»è§‰åˆ†ç±» |
| Ji et al., "Survey of Hallucination in Natural Language Generation" | 2023 | æœ€å…¨é¢çš„å¹»è§‰ç»¼è¿° |
| Lin et al., "TruthfulQA" | 2022 | æå‡ºäº† imitative falsehoods çš„æ¦‚å¿µ |
| Min et al., "FActScore" | 2023 | ç»†ç²’åº¦åŸå­äº‹å®è¯„ä¼°æ–¹æ³• |
| Manakul et al., "SelfCheckGPT" | 2023 | æ— éœ€å¤–éƒ¨çŸ¥è¯†çš„é»‘ç›’å¹»è§‰æ£€æµ‹ |
| Asai et al., "Self-RAG" | 2024 | è‡ªé€‚åº”æ£€ç´¢å¢å¼ºç”Ÿæˆ |
| Li et al., "HaluEval" | 2023 | å¤§è§„æ¨¡å¹»è§‰è¯„æµ‹åŸºå‡† |
| Li et al., "Inference-Time Intervention" | 2023 | æ¨ç†æ—¶å¹²é¢„å‡å°‘å¹»è§‰ |
| Borgeaud et al., "RETRO" | 2022 | æ£€ç´¢å¢å¼º Transformer æ¶æ„ |
| Rafailov et al., "DPO" | 2023 | ç›´æ¥åå¥½ä¼˜åŒ–æ›¿ä»£ RLHF |
| Huang et al., "A Survey on Hallucination in LLMs" | 2023 | é¢å‘ LLM çš„å¹»è§‰ç»¼è¿° |
| Tonmoy et al., "A Comprehensive Survey of Hallucination Mitigation Techniques" | 2024 | å¹»è§‰ç¼“è§£æŠ€æœ¯ç»¼è¿° |

---

## æ€ç»´å¯¼å›¾ï¼ˆæ–‡æœ¬ç‰ˆï¼‰

```
LLM å¹»è§‰
â”œâ”€â”€ å®šä¹‰ä¸åˆ†ç±»
â”‚   â”œâ”€â”€ äº‹å®æ€§ vs å¿ å®æ€§
â”‚   â”œâ”€â”€ å†…åœ¨ vs å¤–åœ¨
â”‚   â””â”€â”€ è‰¯æ€§ vs æ¶æ€§
â”œâ”€â”€ æ ¹æœ¬åŸå› 
â”‚   â”œâ”€â”€ è®­ç»ƒæ•°æ®å™ªéŸ³
â”‚   â”œâ”€â”€ Exposure Bias
â”‚   â”œâ”€â”€ Softmax è¿‡åº¦è‡ªä¿¡
â”‚   â”œâ”€â”€ çŸ¥è¯†è¾¹ç•Œæ¨¡ç³Š
â”‚   â””â”€â”€ æ³¨æ„åŠ›æœºåˆ¶å±€é™
â”œâ”€â”€ æ£€æµ‹æ–¹æ³•
â”‚   â”œâ”€â”€ SelfCheckGPTï¼ˆé»‘ç›’ï¼‰
â”‚   â”œâ”€â”€ äº‹å®æ ¸æŸ¥ Pipeline
â”‚   â”œâ”€â”€ NLI-based
â”‚   â”œâ”€â”€ çŸ¥è¯†å›¾è°±éªŒè¯
â”‚   â”œâ”€â”€ å†…éƒ¨çŠ¶æ€åˆ†æï¼ˆç™½ç›’ï¼‰
â”‚   â””â”€â”€ LLM-as-Judge
â”œâ”€â”€ ç¼“è§£ç­–ç•¥
â”‚   â”œâ”€â”€ è®­ç»ƒé˜¶æ®µï¼šæ•°æ®æ¸…æ´— / RLHF / DPO
â”‚   â”œâ”€â”€ æ¨ç†é˜¶æ®µï¼šRAG / CoT / Self-Consistency / Constrained Decoding
â”‚   â””â”€â”€ æ¶æ„å±‚é¢ï¼šRALM / å¼•ç”¨æ ‡æ³¨ / ç½®ä¿¡åº¦æ ¡å‡†
â”œâ”€â”€ ä¸å¯¹é½çš„å…³ç³»
â”‚   â”œâ”€â”€ Sycophancy
â”‚   â”œâ”€â”€ Instruction Following vs Truthfulness
â”‚   â””â”€â”€ å®‰å…¨äº¤å‰é—®é¢˜
â”œâ”€â”€ è¯„æµ‹åŸºå‡†
â”‚   â”œâ”€â”€ TruthfulQA / HaluEval / FActScore / FELM
â”‚   â””â”€â”€ FEVER / BEGIN / DialFact
â””â”€â”€ å·¥ä¸šå®è·µ
    â”œâ”€â”€ Bing Chat å¼•ç”¨
    â”œâ”€â”€ Perplexity æºæ ‡æ³¨
    â”œâ”€â”€ Claude æ‹’ç­”ç­–ç•¥
    â””â”€â”€ Google Search Grounding
```

---

> **æœ€åä¸€ç‚¹é¢è¯•å»ºè®®**ï¼šå¹»è§‰é—®é¢˜æ˜¯ LLM é¢†åŸŸæœ€æ´»è·ƒçš„ç ”ç©¶æ–¹å‘ä¹‹ä¸€ï¼Œé¢è¯•æ—¶ä¸ä»…è¦å±•ç¤ºå¯¹ç°æœ‰æ–¹æ³•çš„ç†è§£ï¼Œè¿˜è¦èƒ½è¡¨è¾¾è‡ªå·±çš„æ€è€ƒã€‚ä¾‹å¦‚ï¼š"å®Œå…¨æ¶ˆé™¤å¹»è§‰å¯èƒ½ç­‰ä»·äºå®ç°å®Œç¾çš„ä¸–ç•ŒçŸ¥è¯†è¡¨ç¤ºï¼Œè¿™åœ¨çŸ­æœŸå†…æ˜¯ä¸ç°å®çš„ã€‚æ›´åŠ¡å®çš„æ–¹å‘æ˜¯è®©æ¨¡å‹**çŸ¥é“è‡ªå·±ä¸çŸ¥é“ä»€ä¹ˆ**ï¼Œå¹¶åœ¨ä¸ç¡®å®šæ—¶è¯šå®åœ°è¡¨è¾¾å‡ºæ¥ã€‚" è¿™ç§æœ‰æ·±åº¦çš„ä¸ªäººè§è§£æ¯”å•çº¯åˆ—ä¸¾æ–¹æ³•æ›´èƒ½æ‰“åŠ¨é¢è¯•å®˜ã€‚

---

---

## ğŸ“š æ¨èé˜…è¯»

### åŸå§‹è®ºæ–‡
- [A Survey on Hallucination in Large Language Models](https://arxiv.org/abs/2311.05232) â€” Huang et al., 2023 å¹´æœ€å…¨é¢çš„ LLM å¹»è§‰ç»¼è¿°ï¼Œè¦†ç›–å®šä¹‰/æ£€æµ‹/ç¼“è§£
- [TruthfulQA: Measuring How Models Mimic Human Falsehoods](https://arxiv.org/abs/2109.07958) â€” Lin et al., æ­ç¤ºäº†"æ›´å¤§æ¨¡å‹åè€Œæ›´å®¹æ˜“å¤åˆ¶äººç±»é”™è¯¯ä¿¡å¿µ"çš„åç›´è§‰å‘ç°
- [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401) â€” Lewis et al., RAG èŒƒå¼å¼€å±±ä¹‹ä½œ
- [Self-RAG: Learning to Retrieve, Generate, and Critique](https://arxiv.org/abs/2310.11511) â€” Asai et al., æ¨¡å‹è‡ªä¸»å†³å®šä½•æ—¶æ£€ç´¢çš„è‡ªé€‚åº” RAG
- [FActScore: Fine-grained Atomic Evaluation of Factual Precision](https://arxiv.org/abs/2305.14251) â€” Min et al., åŸå­äº‹å®çº§åˆ«çš„å¹»è§‰è¯„ä¼°æ–¹æ³•
- [SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection](https://arxiv.org/abs/2303.08896) â€” Manakul et al., æ— éœ€å¤–éƒ¨çŸ¥è¯†çš„é»‘ç›’å¹»è§‰æ£€æµ‹

### æ·±åº¦è§£è¯»
- [A Comprehensive Survey of Hallucination Mitigation Techniques in LLMs](https://arxiv.org/abs/2401.01313) â€” Tonmoy et al. 2024, ç¼“è§£æŠ€æœ¯ç»¼è¿° â­â­â­â­
- [Perplexity AI Blog â€” How We Reduce Hallucinations](https://blog.perplexity.ai/) â€” å·¥ä¸šçº§å¹»è§‰æ§åˆ¶å®è·µ â­â­â­â­

### å®è·µèµ„æº
- [RAGAS](https://github.com/explodinggradients/ragas) â€” RAG ç³»ç»Ÿçš„å¹»è§‰/å¿ å®åº¦è‡ªåŠ¨åŒ–è¯„æµ‹æ¡†æ¶
- [Vectara HHEM (Hughes Hallucination Evaluation Model)](https://huggingface.co/vectara/hallucination_evaluation_model) â€” å¼€æºå¹»è§‰æ£€æµ‹æ¨¡å‹ï¼Œå¯ç›´æ¥é›†æˆ
- [TruthfulQA Benchmark](https://github.com/sylinrl/TruthfulQA) â€” æ ‡å‡†åŒ–å¹»è§‰è¯„æµ‹æ•°æ®é›†

---

## ğŸ”§ è½åœ°åº”ç”¨

### ç›´æ¥å¯ç”¨åœºæ™¯
- **çŸ¥è¯†å¯†é›†å‹é—®ç­”äº§å“**ï¼šRAG + å¼•ç”¨æ ‡æ³¨ï¼ˆå‚è§ Perplexity æ–¹æ¡ˆï¼Œç¬¬7.2èŠ‚ï¼‰æ˜¯æœ€æˆç†Ÿçš„å¹»è§‰ç¼“è§£ç»„åˆæ‹³
- **æ–‡æ¡£æ‘˜è¦ç³»ç»Ÿ**ï¼šNLI-based å¿ å®åº¦æ£€æµ‹ï¼ˆSummaC/AlignScoreï¼‰ä½œä¸ºåå¤„ç†è´¨é‡é—¨æ§
- **é«˜é£é™©åœºæ™¯ï¼ˆåŒ»ç–—/æ³•å¾‹/é‡‘èï¼‰**ï¼šå¤šå±‚é˜²æŠ¤â€”â€”RAG + Self-Consistency + LLM-as-Judge + äººå·¥å®¡æ ¸ï¼ˆè¯¦è§é¢˜ç›®5ï¼‰

### å·¥ç¨‹å®ç°è¦ç‚¹
- **SelfCheckGPT éƒ¨ç½²**ï¼šé‡‡æ · N=5-10 æ¡ç‹¬ç«‹å“åº”ï¼ˆtemperature=1.0ï¼‰ï¼ŒNLI ä¸€è‡´æ€§ < 0.5 çš„å¥å­æ ‡è®°ä¸ºå¯èƒ½å¹»è§‰ã€‚æˆæœ¬ â‰ˆ N Ã— åŸå§‹æ¨ç†
- **RAG å¹»è§‰é™·é˜±**ï¼šæ£€ç´¢ recall ä¸è¶³æ—¶æ¨¡å‹ä»ä¼š"ç¼–é€ " â†’ éœ€è¦ Self-RAG çš„"æ˜¯å¦éœ€è¦æ£€ç´¢"åˆ¤æ–­ + "æ£€ç´¢ç»“æœæ˜¯å¦æ”¯æŒå›ç­”"éªŒè¯
- **æ ¡å‡†å…¬å¼**ï¼šç†æƒ³æ ¡å‡†ä¸‹ï¼Œæ¨¡å‹ç½®ä¿¡åº¦ $p$ ä¸å®é™…æ­£ç¡®ç‡ $\hat{p}$ åº”æ»¡è¶³ï¼š

$$ECE = \sum_{b=1}^{B} \frac{n_b}{N} |acc(b) - conf(b)|$$

å…¶ä¸­ ECE (Expected Calibration Error) æ˜¯è¡¡é‡æ ¡å‡†è´¨é‡çš„æ ¸å¿ƒæŒ‡æ ‡ï¼Œè¶Šä½è¶Šå¥½

### é¢è¯•é«˜é¢‘é—®æ³•
- Q: RAG èƒ½å®Œå…¨è§£å†³å¹»è§‰å—ï¼Ÿ
  A: ä¸èƒ½ã€‚æ£€ç´¢å¤±è´¥ / çŸ¥è¯†å†²çªï¼ˆå‚æ•°åŒ– vs æ£€ç´¢ï¼‰ / ä¸å¿ å®å¼•ç”¨ / æ¨ç†å¹»è§‰ / Lost-in-the-middle äº”å¤§å±€é™ï¼ˆè¯¦è§é¢˜ç›®4ï¼‰
- Q: è®¾è®¡åŒ»ç–—é—®ç­”äº§å“çš„å¹»è§‰é˜²æŠ¤æ–¹æ¡ˆï¼Ÿ
  A: å…­å±‚é˜²æŠ¤ï¼šçŸ¥è¯†å±‚(æƒå¨åŒ»å­¦åº“RAG) + æ¨¡å‹å±‚(é¢†åŸŸå¾®è°ƒ+æ‹’ç­”è®­ç»ƒ) + æ¨ç†å±‚(å¼ºåˆ¶RAG+å¼•ç”¨+Self-Consistency) + åå¤„ç†å±‚(äº‹å®æ ¸æŸ¥+çº¢çº¿è¿‡æ»¤) + äº§å“å±‚(å…è´£å£°æ˜+äººå·¥å®¡æ ¸) + ç›‘æ§å±‚(æŒç»­è¯„æµ‹)

---

## ğŸ’¡ å¯å‘ä¸æ€è€ƒ

### So Whatï¼Ÿå¯¹è€æ¿æ„å‘³ç€ä»€ä¹ˆ
- **å¹»è§‰æ˜¯ LLM åº”ç”¨çš„ç¬¬ä¸€å¤§é˜»ç¢**ï¼šç”¨æˆ·ä¿¡ä»»ä¸€æ—¦è¢«å¹»è§‰ç ´åï¼Œäº§å“å°±å¤±å»ä»·å€¼ã€‚ä»»ä½•ä¸¥è‚ƒçš„ LLM äº§å“éƒ½å¿…é¡»æœ‰å¹»è§‰é˜²æŠ¤æ–¹æ¡ˆ
- **"è®©æ¨¡å‹çŸ¥é“è‡ªå·±ä¸çŸ¥é“ä»€ä¹ˆ"æ¯”"æ¶ˆé™¤å¹»è§‰"æ›´åŠ¡å®**ï¼šå®Œå…¨æ¶ˆé™¤å¹»è§‰ç­‰ä»·äºå®Œç¾çš„ä¸–ç•ŒçŸ¥è¯†è¡¨ç¤ºï¼ˆçŸ­æœŸä¸å¯èƒ½ï¼‰ï¼Œä½†æ ¡å‡†æ¨¡å‹çš„ä¸ç¡®å®šæ€§è¡¨è¾¾æ˜¯å¯å®ç°çš„

### æœªè§£é—®é¢˜ä¸å±€é™
- **å¤§æ¨¡å‹ vs å¹»è§‰çš„ Scaling æ‚–è®º**ï¼šæ›´å¤§çš„æ¨¡å‹åœ¨äº‹å®æ€§ä¸Šé€šå¸¸æ›´å¥½ï¼Œä½†åœ¨ TruthfulQA ä¸Šå¯èƒ½å› æ›´å¥½åœ°å­¦ä¹ äº†"æµè¡Œé”™è¯¯"ï¼ˆimitative falsehoodsï¼‰è€Œè¡¨ç°æ›´å·®ã€‚RLHF åå¤§æ¨¡å‹åœ¨æ‰€æœ‰ç»´åº¦ä¸Šéƒ½æ”¹å–„
- **çŸ¥è¯†å†²çªçš„æ ¹æœ¬è§£æ³•**ï¼šå½“å‚æ•°åŒ–çŸ¥è¯†ä¸æ£€ç´¢ä¸Šä¸‹æ–‡å†²çªæ—¶ï¼Œæ›´å¤§çš„æ¨¡å‹åè€Œæ›´å€¾å‘äºä¿¡ä»»è‡ªå·±çš„å‚æ•°åŒ–çŸ¥è¯†â€”â€”è¿™ä¸ RAG çš„è®¾è®¡åˆè¡·ç›¸çŸ›ç›¾
- **å¹»è§‰æ£€æµ‹çš„ Ground Truth é—®é¢˜**ï¼šè°æ¥éªŒè¯æ£€æµ‹å™¨æœ¬èº«æ²¡æœ‰å¹»è§‰ï¼ŸLLM-as-Judge æ–¹æ³•å­˜åœ¨å…ƒå±‚é¢çš„å¯é æ€§å›°å¢ƒ

### è„‘æš´ï¼šå¦‚æœå¾€ä¸‹å»¶ä¼¸
- SelfCheckGPT + SAE ç‰¹å¾æ£€æµ‹ï¼šåœ¨æ¨¡å‹å†…éƒ¨æ˜¯å¦å­˜åœ¨"å¹»è§‰æ¿€æ´»æ¨¡å¼"çš„ç‰¹å¾ï¼Ÿå¦‚æœèƒ½æ‰¾åˆ°å¹¶å®‰è£… Circuit Breakerï¼Œå°±èƒ½å®ç° real-time å¹»è§‰é˜»æ–­
- RAG + [[AI/2-Agent/Fundamentals/ReAct ä¸ CoT|ReAct æ¨ç†æ¨¡å¼]]ï¼šè®© Agent åœ¨æ¯æ­¥æ¨ç†åè‡ªåŠ¨æ£€ç´¢éªŒè¯ â†’ "æ¨ç†-éªŒè¯äº¤æ›¿"æ¨¡å¼å¯èƒ½æ¯” Self-RAG æ›´å¯é 
- [[AI/5-AI å®‰å…¨/å¯¹é½æŠ€æœ¯æ€»ç»“|DPO]] çš„ anti-hallucination åº”ç”¨ï¼šè‡ªåŠ¨æ„å»º (äº‹å®å›ç­”, å¹»è§‰å›ç­”) åå¥½å¯¹ â†’ æ— éœ€äººå·¥æ ‡æ³¨çš„åå¹»è§‰ DPO è®­ç»ƒ
- 6 ä¸ªæœˆé¢„åˆ¤ï¼šå¹»è§‰æ£€æµ‹å°†ä»"åå¤„ç†"èµ°å‘"æ¨¡å‹åŸç”Ÿ"â€”â€”o3 ç­‰æ¨¡å‹å¯èƒ½å†…ç½® self-verification æœºåˆ¶

```mermaid
flowchart TD
    subgraph å¹»è§‰ç¼“è§£æŠ€æœ¯æ ˆ
        A[è®­ç»ƒé˜¶æ®µ] --> A1[æ•°æ®æ¸…æ´—]
        A --> A2[RLHF/DPO<br/>å¯¹é½è®­ç»ƒ]
        B[æ¨ç†é˜¶æ®µ] --> B1[RAG<br/>æ£€ç´¢å¢å¼º]
        B --> B2[CoT/Self-Consistency<br/>æ¨ç†å¢å¼º]
        B --> B3[å—é™è§£ç <br/>æ ¼å¼çº¦æŸ]
        C[åå¤„ç†é˜¶æ®µ] --> C1[SelfCheckGPT<br/>é»‘ç›’æ£€æµ‹]
        C --> C2[äº‹å®æ ¸æŸ¥Pipeline<br/>è¯æ®éªŒè¯]
        C --> C3[å¼•ç”¨æ ‡æ³¨<br/>å¯æº¯æº]
        D[äº§å“å±‚] --> D1[äººå·¥å®¡æ ¸]
        D --> D2[ä¸ç¡®å®šæ€§è¡¨è¾¾]
    end
```

---

## See Also

- [[AI/3-LLM/Evaluation/LLM è¯„æµ‹ä½“ç³»|LLM è¯„æµ‹ä½“ç³»]] â€” å¹»è§‰çš„è¯„æµ‹æ–¹æ³•ï¼šTruthfulQA/FactScore
- [[AI/3-LLM/RL/Theory/RLRR-Reference-Guided-Alignment-Non-Verifiable|RLRR]] â€” reference-guided å¯¹é½å‡å°‘å¹»è§‰çš„æ–¹æ³•
- [[AI/3-LLM/Application/RAG/Advanced RAG|Advanced RAG]] â€” RAG æ˜¯å‡è½»å¹»è§‰çš„ä¸»è¦å·¥ç¨‹æ‰‹æ®µ
-  â€” å¤§è¯­è¨€æ¨¡å‹çŸ¥è¯†å…¨å›¾è°±
