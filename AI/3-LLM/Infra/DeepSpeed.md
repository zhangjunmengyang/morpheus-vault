---
title: DeepSpeed
brief: Microsoft å¼€æºçš„æ·±åº¦å­¦ä¹ ä¼˜åŒ–åº“ï¼Œæ ¸å¿ƒæ˜¯ ZeRO ç³»åˆ—æŠ€æœ¯â€”â€”é€šè¿‡åˆ†é˜¶æ®µæ¶ˆé™¤æ•°æ®å¹¶è¡Œä¸­çš„å†—ä½™å­˜å‚¨ï¼ˆä¼˜åŒ–å™¨/æ¢¯åº¦/å‚æ•°ï¼‰ï¼Œä½¿æœ‰é™ GPU è®­ç»ƒæ›´å¤§æ¨¡å‹ï¼›ZeRO-2 æ˜¯æ€§ä»·æ¯”æœ€é«˜çš„å¹³è¡¡ç‚¹ã€‚
type: concept
domain: ai/llm/infra
created: 2026-02-13
updated: 2026-02-22
tags:
  - ai/llm/infra
  - type/concept
  - interview/hot
status: complete
sources:
  - "ZeRO: Memory Optimizations Toward Training Trillion Parameter Models â€” arXiv:1910.02054"
  - "DeepSpeed Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale â€” arXiv:2207.00032"
  - "ZeRO-Offload: Democratizing Billion-Scale Model Training â€” arXiv:2101.06840"
  - https://github.com/microsoft/DeepSpeed
related:
  - "[[AI/3-LLM/Infra/FSDP|FSDP]]"
  - "[[AI/3-LLM/Infra/Megatron-LM|Megatron-LM]]"
  - "[[AI/3-LLM/Infra/æ¨¡å‹å¹¶è¡Œç­–ç•¥|æ¨¡å‹å¹¶è¡Œç­–ç•¥]]"
---
# DeepSpeed

## æ¦‚è¿°

DeepSpeed æ˜¯ Microsoft å¼€æºçš„æ·±åº¦å­¦ä¹ ä¼˜åŒ–åº“ï¼Œæ ¸å¿ƒæ˜¯ **ZeROï¼ˆZero Redundancy Optimizerï¼‰** ç³»åˆ—æŠ€æœ¯ã€‚å®ƒè§£å†³çš„é—®é¢˜å¾ˆç›´æ¥ï¼š**æ€ä¹ˆç”¨æœ‰é™çš„ GPU è®­ç»ƒæ›´å¤§çš„æ¨¡å‹**ã€‚

ZeRO çš„æ€è·¯æ˜¯æ¶ˆé™¤æ•°æ®å¹¶è¡Œä¸­çš„å†—ä½™â€”â€”æ ‡å‡† DDP åœ¨æ¯ä¸ª GPU ä¸Šéƒ½å­˜ä¸€ä»½å®Œæ•´çš„å‚æ•°ã€æ¢¯åº¦ã€ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œè¿™åœ¨å¤§æ¨¡å‹æ—¶ä»£æ˜¯å·¨å¤§çš„æµªè´¹ã€‚

> æ¥æºï¼šRajbhandari et al., "ZeRO: Memory Optimizations Toward Training Trillion Parameter Models" arXiv:1910.02054

## ZeRO ä¸‰ä¸ªé˜¶æ®µ

ZeRO çš„æ ¸å¿ƒæ˜¯åˆ†é˜¶æ®µæ¶ˆé™¤å†—ä½™ï¼Œæ¯ä¸ªé˜¶æ®µåˆ†ç‰‡æ›´å¤šçš„å†…å®¹ï¼š

### æ˜¾å­˜å ç”¨åˆ†æï¼ˆä»¥ 7B FP16 æ¨¡å‹ + Adam ä¸ºä¾‹ï¼Œ4 GPUï¼‰

æ¯ä¸ª GPU ä¸Šçš„æ˜¾å­˜ï¼ˆä¸å«æ¿€æ´»å€¼ï¼‰ï¼š

| ç»„ä»¶ | DDP | ZeRO-1 | ZeRO-2 | ZeRO-3 |
|------|-----|--------|--------|--------|
| å‚æ•° (FP16) | 14 GB | 14 GB | 14 GB | **3.5 GB** |
| æ¢¯åº¦ (FP16) | 14 GB | 14 GB | **3.5 GB** | **3.5 GB** |
| ä¼˜åŒ–å™¨çŠ¶æ€ (FP32) | 56 GB | **14 GB** | **14 GB** | **14 GB** |
| **æ€»è®¡** | **84 GB** | **42 GB** | **31.5 GB** | **21 GB** |

### ZeRO Stage 1: ä¼˜åŒ–å™¨çŠ¶æ€åˆ†ç‰‡

åªåˆ†ç‰‡ optimizer statesï¼ˆAdam çš„ momentum å’Œ varianceï¼‰ã€‚é€šä¿¡é‡ä¸ DDP ç›¸åŒï¼ˆä¸€æ¬¡ All-Reduceï¼‰ï¼Œä½†æ˜¾å­˜å‡åŠã€‚

### ZeRO Stage 2: + æ¢¯åº¦åˆ†ç‰‡

åœ¨ Stage 1 åŸºç¡€ä¸Šåˆ†ç‰‡æ¢¯åº¦ã€‚åå‘ä¼ æ’­æ—¶ç”¨ Reduce-Scatter æ›¿ä»£ All-Reduceï¼Œæ¯ä¸ª GPU åªä¿ç•™è‡ªå·±éœ€è¦çš„æ¢¯åº¦åˆ†ç‰‡ã€‚é€šä¿¡é‡ä¸å˜ï¼Œä½†æ˜¾å­˜è¿›ä¸€æ­¥å‡å°‘ã€‚

### ZeRO Stage 3: + å‚æ•°åˆ†ç‰‡

æ‰€æœ‰ä¸œè¥¿éƒ½åˆ†ç‰‡ã€‚å‰å‘å’Œåå‘ä¼ æ’­æ—¶éœ€è¦ All-Gather æ”¶é›†å®Œæ•´å‚æ•°ï¼Œè®¡ç®—å®Œå†ä¸¢å¼ƒã€‚é€šä¿¡é‡å¢åŠ  50%ï¼Œä½†æ˜¾å­˜é™åˆ°æè‡´ã€‚

**ç­‰ä»·äº [[AI/3-LLM/Infra/FSDP]] çš„ FULL_SHARDã€‚**

> æ¥æºï¼šarXiv:1910.02054, Sec. 3.2 â€” ZeRO Stage 3 çš„é€šä¿¡é‡åˆ†æï¼šç›¸æ¯” DDP å¢åŠ çº¦ 50%

## é…ç½®æ–¹å¼

DeepSpeed é€šè¿‡ JSON é…ç½®æ–‡ä»¶æ§åˆ¶ï¼š

### ZeRO Stage 2ï¼ˆæœ€å¸¸ç”¨çš„å¹³è¡¡ç‚¹ï¼‰

```json
{
    "bf16": {"enabled": true},
    "zero_optimization": {
        "stage": 2,
        "allgather_partitions": true,
        "allgather_bucket_size": 2e8,
        "overlap_comm": true,
        "reduce_scatter": true,
        "reduce_bucket_size": 2e8,
        "contiguous_gradients": true
    },
    "gradient_accumulation_steps": 4,
    "gradient_clipping": 1.0,
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto"
}
```

### ZeRO Stage 3 + Offload

```json
{
    "bf16": {"enabled": true},
    "zero_optimization": {
        "stage": 3,
        "offload_param": {
            "device": "cpu",
            "pin_memory": true
        },
        "offload_optimizer": {
            "device": "cpu",
            "pin_memory": true
        },
        "overlap_comm": true,
        "contiguous_gradients": true,
        "sub_group_size": 1e9,
        "reduce_bucket_size": "auto",
        "stage3_prefetch_bucket_size": "auto",
        "stage3_param_persistence_threshold": "auto",
        "stage3_max_live_parameters": 1e9,
        "stage3_max_reuse_distance": 1e9
    }
}
```

## ZeRO-Offload å’Œ ZeRO-Infinity

### ZeRO-Offload

> æ¥æºï¼šRen et al., "ZeRO-Offload: Democratizing Billion-Scale Model Training" arXiv:2101.06840

æŠŠä¼˜åŒ–å™¨çŠ¶æ€å’Œæ¢¯åº¦å¸è½½åˆ° CPU å†…å­˜ï¼š
- GPU åšå‰å‘å’Œåå‘è®¡ç®—
- CPU åšä¼˜åŒ–å™¨æ›´æ–°ï¼ˆAdam stepï¼‰
- é€šè¿‡ PCIe ä¼ è¾“æ•°æ®

ä»£ä»·ï¼šè®­ç»ƒé€Ÿåº¦é™ä½ 20-40%ï¼ˆå–å†³äº PCIe å¸¦å®½ï¼‰ï¼Œä½†èƒ½åœ¨å•å¡ä¸Šè®­ç»ƒæ›´å¤§çš„æ¨¡å‹ã€‚

### ZeRO-Infinity

åœ¨ Offload åŸºç¡€ä¸Šè¿›ä¸€æ­¥å¸è½½åˆ° **NVMe SSD**ï¼š
- CPU å†…å­˜æœ‰é™ï¼Ÿç”¨ SSD æ‰©å±•
- ç†è®ºä¸Šå¯ä»¥åœ¨å• GPU ä¸Šè®­ç»ƒä»»æ„å¤§çš„æ¨¡å‹ï¼ˆåªè¦ SSD å¤Ÿå¤§ï¼‰
- é€Ÿåº¦ä¼šæ›´æ…¢ï¼Œä½†å¯¹äºæç«¯èµ„æºé™åˆ¶ä¸‹çš„è®­ç»ƒæ˜¯å”¯ä¸€é€‰æ‹©

## DeepSpeed çš„å…¶ä»–åŠŸèƒ½

### 1. Mixture of Experts (MoE) æ”¯æŒ

DeepSpeed æä¾›äº† MoE è®­ç»ƒçš„åŸºç¡€è®¾æ–½ï¼š
- Expert Parallelismï¼šä¸åŒ GPU ä¸Šæ”¾ä¸åŒçš„ expert
- ä¸ ZeRO ç»“åˆä½¿ç”¨

### 2. é€šä¿¡ä¼˜åŒ–

- **Gradient Compression**ï¼šæ¢¯åº¦é‡åŒ–åå†é€šä¿¡
- **1-bit Adam**ï¼šç”¨ 1-bit é‡åŒ–çš„æ¢¯åº¦åšé€šä¿¡ï¼Œæå¤§å‡å°‘å¸¦å®½éœ€æ±‚ï¼ˆæ¥æºï¼šTang et al., "1-bit Adam" arXiv:2102.02888ï¼‰

### 3. Activation Checkpointing

```json
{
    "activation_checkpointing": {
        "partition_activations": true,
        "contiguous_memory_optimization": true,
        "cpu_checkpointing": true
    }
}
```

ç”¨æ—¶é—´æ¢ç©ºé—´ï¼šä¸ä¿å­˜ä¸­é—´æ¿€æ´»å€¼ï¼Œåå‘ä¼ æ’­æ—¶é‡ç®—ã€‚æ˜¾å­˜èŠ‚çœæ˜¾è‘—ï¼Œè®¡ç®—é‡å¢åŠ çº¦ 33%ã€‚

### 4. DeepSpeed-Chat

é’ˆå¯¹ RLHF è®­ç»ƒçš„å®Œæ•´ pipelineï¼ˆSFT â†’ Reward Modeling â†’ PPOï¼‰ï¼Œä½†ç¤¾åŒºä½¿ç”¨ç‡ä¸å¦‚ TRL/verlã€‚

## ä¸ HuggingFace çš„é›†æˆ

é€šè¿‡ Accelerate æˆ–ç›´æ¥åœ¨ Trainer ä¸­ä½¿ç”¨ï¼š

```python
from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir="./output",
    deepspeed="ds_config.json",  # æŒ‡å®šé…ç½®æ–‡ä»¶
    bf16=True,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
)
```

```bash
# å¯åŠ¨
deepspeed --num_gpus=8 train.py --deepspeed ds_config.json
# æˆ–
accelerate launch --config_file accelerate_ds.yaml train.py
```

## é€‰æ‹©å»ºè®®

| åœºæ™¯ | æ¨èæ–¹æ¡ˆ | ç†ç”± |
|------|---------|------|
| å•å¡è®­ç»ƒ | ä¸éœ€è¦ DeepSpeed | æ— å†—ä½™é—®é¢˜ |
| å¤šå¡ã€æ¨¡å‹ < 13B | ZeRO Stage 2 | æ€§ä»·æ¯”æœ€é«˜ï¼Œé€šä¿¡é‡=DDP |
| å¤šå¡ã€æ¨¡å‹ 13B-70B | ZeRO Stage 3 | å‚æ•°åˆ†ç‰‡è§£å†³æ˜¾å­˜ç“¶é¢ˆ |
| æ˜¾å­˜æåº¦ç´§å¼  | ZeRO-3 + CPU Offload | é€Ÿåº¦é™ 20-40%ï¼Œæ¢æ˜¾å­˜ |
| åªæœ‰ 1-2 å¼ å¡è®­å¤§æ¨¡å‹ | ZeRO-3 + CPU/NVMe Offload | å”¯ä¸€å¯è¡Œæ–¹æ¡ˆ |

## ğŸ“š æ¨èé˜…è¯»

### åŸå§‹è®ºæ–‡
- [ZeRO: Memory Optimizations Toward Training Trillion Parameter Models](https://arxiv.org/abs/1910.02054) â€” ZeRO ä¸‰é˜¶æ®µçš„å®Œæ•´ç†è®ºå’Œå®éªŒ
- [DeepSpeed Inference: Enabling Efficient Inference of Transformer Models at Unprecedented Scale](https://arxiv.org/abs/2207.00032) â€” æ¨ç†ä¾§çš„ä¼˜åŒ–ï¼ˆå¤š GPU inference, kernel fusionï¼‰
- [ZeRO-Offload: Democratizing Billion-Scale Model Training](https://arxiv.org/abs/2101.06840) â€” CPU/NVMe offload çš„è®¾è®¡

### æ·±åº¦è§£è¯»
- [DeepSpeed æ·±åº¦è§£æï¼ˆçŸ¥ä¹ï¼‰](https://zhuanlan.zhihu.com/p/630734624) â€” ä¸­æ–‡ç¤¾åŒºè¯¦ç»†è§£è¯» ZeRO å„é˜¶æ®µ â­â­â­â­
- [HuggingFace DeepSpeed é›†æˆæ–‡æ¡£](https://huggingface.co/docs/transformers/deepspeed) â€” æœ€å¸¸ç”¨çš„å®æˆ˜æŒ‡å—

### å®è·µèµ„æº
- [microsoft/DeepSpeed GitHub](https://github.com/microsoft/DeepSpeed) â€” å®˜æ–¹ä»“åº“
- [DeepSpeed Examples](https://github.com/microsoft/DeepSpeedExamples) â€” åŒ…å« RLHFã€MoE ç­‰è®­ç»ƒç¤ºä¾‹

## ğŸ”§ è½åœ°åº”ç”¨

### ç›´æ¥å¯ç”¨åœºæ™¯
- **SFT/é¢„è®­ç»ƒåŠ é€Ÿ**ï¼šZeRO-2 + HuggingFace Trainer ä¸€è¡Œé…ç½®å³å¯å¯ç”¨
- **RLHF è®­ç»ƒ**ï¼š[[AI/3-LLM/Frameworks/OpenRLHF/OpenRLHF|OpenRLHF]] å’Œ [[AI/3-LLM/Frameworks/TRL/TRL æ¦‚è¿°|TRL]] å‡æ·±åº¦é›†æˆ DeepSpeed
- **å•å¡è®­å¤§æ¨¡å‹**ï¼šZeRO-3 + CPU Offload è®© 24GB æ¶ˆè´¹çº§ GPU ä¹Ÿèƒ½å¾®è°ƒ 7B æ¨¡å‹

### å·¥ç¨‹å®ç°è¦ç‚¹
- **ZeRO Stage é€‰æ‹©å…¬å¼**ï¼šæ¯ GPU æ˜¾å­˜éœ€æ±‚ â‰ˆ $\frac{18 \times P}{N \times \text{stage\_factor}}$ï¼ˆ$P$ å‚æ•°é‡ bytesï¼Œ$N$ GPU æ•°ï¼‰
- **`overlap_comm: true`** æ˜¯æ€§èƒ½å…³é”®â€”â€”å…è®¸é€šä¿¡ä¸è®¡ç®—é‡å 
- **å¸¸è§å‘**ï¼šZeRO-3 ä¸‹ `model.parameters()` è¿”å›çš„æ˜¯åˆ†ç‰‡å‚æ•°ï¼Œç›´æ¥è®¿é—®ä¼šæŠ¥é”™ï¼›éœ€ç”¨ `deepspeed.zero.GatheredParameters` ä¸Šä¸‹æ–‡

### é¢è¯•é«˜é¢‘é—®æ³•
- Q: ZeRO ä¸‰ä¸ª Stage åˆ†åˆ«åˆ†ç‰‡äº†ä»€ä¹ˆï¼Ÿé€šä¿¡é‡å˜åŒ–å¦‚ä½•ï¼Ÿ
  A: Stage 1 åˆ†ç‰‡ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆé€šä¿¡é‡=DDPï¼‰ï¼›Stage 2 åŠ åˆ†ç‰‡æ¢¯åº¦ï¼ˆé€šä¿¡é‡=DDPï¼Œä½†ç”¨ Reduce-Scatter æ›¿ä»£ AllReduceï¼‰ï¼›Stage 3 åŠ åˆ†ç‰‡å‚æ•°ï¼ˆé€šä¿¡é‡=1.5Ã—DDPï¼Œå› ä¸ºå¤šäº† forward/backward çš„ AllGatherï¼‰ã€‚

## ğŸ’¡ å¯å‘ä¸æ€è€ƒ

### So Whatï¼Ÿå¯¹è€æ¿æ„å‘³ç€ä»€ä¹ˆ
- DeepSpeed æ˜¯"ç”¨æœ€å°‘èµ„æºè®­æœ€å¤§æ¨¡å‹"çš„é¦–é€‰å·¥å…·â€”â€”ZeRO-2 å‡ ä¹é›¶ä»£ç ä¾µå…¥ï¼Œæ˜¯ SFT çš„é»˜è®¤é€‰æ‹©
- ç†è§£ ZeRO çš„æ˜¾å­˜æ¨¡å‹ï¼ˆå‚æ•° + æ¢¯åº¦ + ä¼˜åŒ–å™¨ = $2P + 2P + 12P = 16P$ bytes for Adam FP16ï¼‰æ˜¯ä¼°ç®—è®­ç»ƒèµ„æºçš„åŸºç¡€

### æœªè§£é—®é¢˜ä¸å±€é™
- ZeRO-3 çš„é€šä¿¡é¢‘ç‡ï¼ˆæ¯å±‚ä¸¤æ¬¡ AllGatherï¼‰åœ¨è¶…å¤§è§„æ¨¡é›†ç¾¤ä¸Šä¸å¦‚ [[AI/3-LLM/Infra/Megatron-LM]] çš„æ‰‹åŠ¨ TP é«˜æ•ˆ
- CPU Offload çš„ PCIe å¸¦å®½ç“¶é¢ˆï¼ˆ~32 GB/sï¼‰åœ¨ NVMe SSD åœºæ™¯æ›´ä¸¥é‡

### è„‘æš´ï¼šå¦‚æœå¾€ä¸‹å»¶ä¼¸
- ZeRO++ çš„ hierarchical partitioning + quantized communication èƒ½å¦è®© ZeRO-3 åœ¨ä¸‡å¡é›†ç¾¤ä¸Šè¿½å¹³ Megatronï¼Ÿ
- å¦‚æœæŠŠ [[AI/3-LLM/Infra/FSDP|FSDP2]] çš„ DTensor + torch.compile ä¸ DeepSpeed çš„ offload ç»“åˆï¼Œæ˜¯å¦æ˜¯æœ€ä½³æ–¹æ¡ˆï¼Ÿ

## ç›¸å…³

> ğŸ”— See also: [[AI/3-LLM/Infra/FSDP]] â€” PyTorch åŸç”Ÿçš„ ZeRO-3 å®ç°ï¼Œä¸ DeepSpeed ç›´æ¥å¯¹æ ‡
> ğŸ”— See also: [[AI/3-LLM/Infra/Megatron-LM]] â€” TP/PP å¹¶è¡Œï¼Œä¸ ZeRO äº’è¡¥ï¼ˆå¤§è§„æ¨¡é›†ç¾¤å¸¸æ··ç”¨ï¼‰
> ğŸ”— See also: [[AI/3-LLM/Infra/æ¨¡å‹å¹¶è¡Œç­–ç•¥|æ¨¡å‹å¹¶è¡Œç­–ç•¥]] â€” ä» DP åˆ° 5D å¹¶è¡Œçš„å…¨æ™¯å¯¹æ¯”

- [[AI/3-LLM/Infra/åˆ†å¸ƒå¼è®­ç»ƒ]] â€” åˆ†å¸ƒå¼è®­ç»ƒæ¦‚è§ˆ
- [[AI/3-LLM/Infra/Ray]] â€” åˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶
- [[AI/3-LLM/Frameworks/TRL/TRL æ¦‚è¿°|TRL æ¦‚è¿°]] â€” é›†æˆ DeepSpeed çš„è®­ç»ƒæ¡†æ¶
- [[AI/3-LLM/Frameworks/verl/verl æ¦‚è¿°|verl æ¦‚è¿°]] â€” verl å¯¹åˆ†å¸ƒå¼è®­ç»ƒçš„æ”¯æŒ
- [[AI/3-LLM/Frameworks/OpenRLHF/OpenRLHF|OpenRLHF]]
