---
brief: "Unsloth 数据合成——训练数据生成的 Unsloth 工具链；用现有模型合成 SFT/偏好数据、数据质量过滤、格式转换；从零数据到可训练数据集的完整流水线。"
title: "数据合成"
type: concept
domain: ai/llm/frameworks/unsloth
created: "2026-02-13"
updated: "2026-02-13"
tags:
  - ai/llm/frameworks/unsloth
  - type/concept
---
# Unsloth 数据合成

> 文档：https://docs.unsloth.ai/get-started/fine-tuning-llms-guide/datasets-guide

Unsloth 微调的核心痛点不是代码——几行代码就能跑起来。真正的难点是**数据**。这篇笔记记录 Unsloth 生态下的数据准备最佳实践。

## 数据格式

Unsloth 支持两种主要格式：

### 1. 对话格式（推荐）

```json
{
  "conversations": [
    {"role": "system", "content": "你是一位数据工程师助手。"},
    {"role": "user", "content": "Spark 和 Flink 哪个更适合实时处理？"},
    {"role": "assistant", "content": "Flink 更适合真正的实时处理..."}
  ]
}
```

### 2. Instruction 格式

```json
{
  "instruction": "解释 Spark 的 lazy evaluation",
  "input": "",
  "output": "Spark 采用惰性求值策略..."
}
```

## 数据合成实践

### 从领域文档生成 QA 对

这是最常用的场景——把内部文档变成训练数据：

```python
import openai

def doc_to_qa(doc_chunk: str, num_pairs: int = 3) -> list:
    prompt = f"""基于以下技术文档，生成 {num_pairs} 个高质量的问答对。
    
要求：
1. 问题要具体，不要太宽泛
2. 答案要准确且有深度
3. 涵盖不同层次：概念解释、实践操作、故障排查

文档：
{doc_chunk}

输出 JSON 格式：
[{{"question": "...", "answer": "..."}}]
"""
    response = openai.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"},
    )
    return json.loads(response.choices[0].message.content)
```

### 多样性增强

```python
# 用不同 persona 生成，增加多样性
personas = [
    "你是一个刚入行的初级工程师",
    "你是一个有 5 年经验的数据工程师",
    "你是一个正在面试的候选人",
    "你是一个需要排查生产问题的 SRE",
]

for persona in personas:
    qa_pairs = doc_to_qa(doc, persona=persona)
```

### 质量过滤

```python
def filter_qa(qa_pair: dict) -> bool:
    q, a = qa_pair["question"], qa_pair["answer"]
    
    # 基础检查
    if len(a) < 50 or len(a) > 3000:
        return False
    if len(q) < 10:
        return False
    
    # 去掉"是/否"类简单问题
    if a.strip() in ["是", "否", "对", "不对"]:
        return False
    
    # LLM 打分
    score = judge_quality(q, a)
    return score >= 4
```

## 推荐数据集来源

| 来源 | 用途 | 备注 |
|------|------|------|
| 内部文档 | 领域知识 | 需要脱敏 |
| Stack Overflow | 技术 QA | 公开可用 |
| GitHub Issues | 故障排查 | 实战性强 |
| 技术博客 | 概念解释 | 需要筛选质量 |

## 数据量经验值

| 任务 | 最少数据量 | 推荐数据量 |
|------|-----------|-----------|
| 风格对齐 | 50-100 | 200-500 |
| 领域 QA | 500-1000 | 2000-5000 |
| 代码生成 | 1000-2000 | 5000-10000 |
| 通用助手 | 5000+ | 20000+ |

**核心原则：质量 > 数量。500 条精标数据 > 5000 条低质数据。**

## 相关

- [[AI/3-LLM/Application/Synthetic-Data/Synthetic Data|Synthetic Data 综述]]
- [[AI/3-LLM/Application/Synthetic-Data/DataFlow|DataFlow 框架]]
- [[AI/3-LLM/Application/Synthetic-Data/数据合成|数据合成（Prompt 视角）]]
- [[AI/3-LLM/Frameworks/Unsloth/Chat Templates|Chat Templates]]
- [[AI/3-LLM/Frameworks/Unsloth/训练示例概述|训练示例概述]]
