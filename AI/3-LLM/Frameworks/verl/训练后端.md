---
brief: "verl 训练后端——底层计算后端选择：vLLM（推理采样）+ Megatron/FSDP（模型训练）的混合架构；不同后端的性能特性和切换方案；vLLM rollout + PyTorch FSDP 训练的推荐配置。"
title: "训练后端"
type: project
domain: ai/llm/frameworks/verl
created: "2026-02-13"
updated: "2026-02-13"
tags:
  - ai/llm/frameworks/verl
  - type/project
---
# 训练后端

> Megatron-LM 后端：https://verl.readthedocs.io/en/latest/workers/megatron_workers.html
> SGLang 后端：https://verl.readthedocs.io/en/latest/workers/sglang_worker.html

## 两个维度的后端

verl 在两个层面有"后端"选择：

1. **训练后端**：Actor/Critic 做梯度更新用什么框架 → FSDP / Megatron-LM
2. **推理后端**：Rollout 生成用什么引擎 → SGLang / vLLM

```
┌──────────────────────────────────────────┐
│                 verl                       │
│                                            │
│  Training Backend    Inference Backend     │
│  ┌───────────────┐  ┌──────────────────┐  │
│  │ FSDP (默认)    │  │ SGLang (推荐)    │  │
│  │ Megatron-LM   │  │ vLLM             │  │
│  └───────────────┘  └──────────────────┘  │
└──────────────────────────────────────────┘
```

## 训练后端对比

### FSDP (Fully Sharded Data Parallel)

PyTorch 原生的分布式训练方案，等同于 DeepSpeed ZeRO-3。

```python
# FSDP 配置
fsdp_config:
  sharding_strategy: "FULL_SHARD"  # ZeRO-3
  # SHARD_GRAD_OP = ZeRO-2
  # NO_SHARD = DDP
  
  cpu_offload: false
  mixed_precision: "bf16"
  
  # 自动 wrap 策略
  auto_wrap_policy: "transformer_layer"
  min_num_params: 1e6
```

**优点**：
- PyTorch 原生，不需要额外依赖
- 配置简单，开箱即用
- 支持 HuggingFace 模型无缝接入
- 社区维护好，bug 少

**缺点**：
- 不支持 Tensor Parallel（只有 Data Parallel）
- 超大模型（70B+）性能不如 Megatron
- 通信效率在大规模集群上有瓶颈

### Megatron-LM

NVIDIA 的分布式训练框架，支持 3D 并行（DP + TP + PP）。

```python
# Megatron 配置
megatron_config:
  tensor_parallel_size: 4     # TP: 模型张量切分到 4 张卡
  pipeline_parallel_size: 2   # PP: 模型层切分到 2 组
  # Data Parallel 自动计算: total_gpus / (TP * PP)
  
  sequence_parallel: true     # 序列并行，省激活显存
  use_flash_attn: true
```

**优点**：
- 3D 并行，大模型训练必备
- 通信效率高（TP 用 NVLink，PP 用 IB）
- 72B 以上模型几乎是唯一选择

**缺点**：
- 需要将 HuggingFace 模型转为 Megatron 格式
- 配置复杂，调试困难
- 模型兼容性有限（不是所有架构都支持）

### 选择建议

| 模型规模 | 推荐后端 | 理由 |
|----------|---------|------|
| ≤ 7B | FSDP | 简单够用 |
| 7B-14B | FSDP 或 Megatron | 看团队熟悉度 |
| 14B-72B | Megatron | 需要 TP |
| > 72B | Megatron | 必须 3D 并行 |

## 推理后端对比

### SGLang

```yaml
rollout:
  name: "sglang"
  tensor_parallel_size: 1
  gpu_memory_utilization: 0.85
  
  # SGLang 特色
  enable_prefix_caching: true  # 多轮场景性能翻倍
  chunked_prefill: true
```

**核心优势**：
- **RadixAttention**：自动 prefix caching，多轮/共享前缀场景效果拔群
- **Chunked Prefill**：prefill 和 decode 可以 overlap
- 吞吐量通常比 vLLM 高 20-30%

### vLLM

```yaml
rollout:
  name: "vllm"
  tensor_parallel_size: 1
  gpu_memory_utilization: 0.85
  
  # vLLM 参数
  enable_prefix_caching: false  # vLLM 也支持但默认关
  max_num_seqs: 256
```

**核心优势**：
- 生态成熟，模型支持最广
- PagedAttention 内存管理高效
- 文档和社区更完善

### 推理引擎选择

```python
# 性能测试经验 (Qwen2.5-7B, 8×A100):
#
# SGLang:
#   - 单轮 throughput: ~2500 tokens/s
#   - 多轮 throughput: ~3200 tokens/s (prefix cache 命中)
#   - 首 token 延迟: ~45ms
#
# vLLM:
#   - 单轮 throughput: ~2100 tokens/s
#   - 多轮 throughput: ~2300 tokens/s
#   - 首 token 延迟: ~55ms
#
# 结论: SGLang 在 verl 场景下更优
#       (GRPO group 内 prompt 相同，prefix cache 天然命中率高)
```

## Megatron 模型格式转换

用 Megatron 后端需要先做格式转换：

```bash
# HuggingFace → Megatron
python tools/convert_hf_to_megatron.py \
  --hf-model-path /path/to/qwen2.5-7b \
  --megatron-path /path/to/megatron_ckpt \
  --tp-size 4 \
  --pp-size 2

# 训练完后 Megatron → HuggingFace (用于推理部署)
python tools/convert_megatron_to_hf.py \
  --megatron-path /path/to/megatron_ckpt \
  --hf-model-path /path/to/output_hf \
  --tp-size 4 \
  --pp-size 2
```

## 混合使用

verl 的一个巧妙设计：训练和推理可以用不同后端。

```yaml
# 训练用 FSDP (简单)，推理用 SGLang (快)
actor_rollout_ref:
  actor:
    backend: "fsdp"
  rollout:
    name: "sglang"
```

这样既能享受 FSDP 的简单配置，又能用上 SGLang 的高性能推理。权重在阶段切换时自动同步。

## See Also

**verl 框架内部（同目录）**
- [[AI/3-LLM/Frameworks/verl/verl 概述|verl 概述]] — 框架总览，含训练后端章节
- [[AI/3-LLM/Frameworks/verl/HybridFlow|HybridFlow]] — 单控制器架构，训练/推理后端协同原理
- [[AI/3-LLM/Frameworks/verl/性能调优|性能调优]] — 后端性能调优实战
- [[AI/3-LLM/Frameworks/verl/硬件资源预估|硬件资源预估]] — 不同后端显存需求

**外部依赖（后端工具）**
- [[AI/3-LLM/Infra/FSDP|FSDP]] — 训练后端：PyTorch 全参数分片，verl 默认训练选项
- [[AI/3-LLM/Infra/Megatron-LM|Megatron-LM]] — 训练后端：Megatron 大规模分布式（3D并行）
- [[Projects/MA-RLHF/xtrain/xtrain-03b-ZeRO-手撕实操|ZeRO-手撕实操]] — FSDP 底层原理的手撕实现
- [[Projects/MA-RLHF/lc10/lc10-04-vLLM-V0-手撕实操|vLLM-手撕实操]] — 推理后端 vLLM 的手撕实现

## 推荐阅读

1. **verl 官方文档**：[verl.readthedocs.io](https://verl.readthedocs.io/) — 训练后端配置章节
2. **HybridFlow 论文**：[[AI/3-LLM/Frameworks/verl/HybridFlow|HybridFlow]] — 理解 verl 单控制器模型的根本原因
