---
brief: "模型蒸馏——Knowledge Distillation 从 Teacher 向 Student 传递知识的三种方式（Soft Label/Feature/Contrastive）；LLM 场景的蒸馏特殊挑战；DeepSeek-R1 蒸馏路线（Reasoning trace 直接 SFT）的工程验证。"
title: "模型蒸馏：从知识蒸馏到 LLM 蒸馏实践"
date: 2026-02-13
tags:
  - ai/llm/training
  - ai/distillation
  - ai/model-compression
  - type/concept
  - interview/hot
status: active
---

# 模型蒸馏：从知识蒸馏到 LLM 蒸馏实践

> 让小模型学到大模型的"暗知识"——部署成本降 10 倍，效果只损失 5%

## 1. 知识蒸馏基础

### Hinton 的经典框架（2015）

核心思想：**教师模型（Teacher）的 soft label 比 hard label 包含更多信息**。

```
Hard label: [0, 0, 1, 0, 0]  → 只知道正确类别
Soft label: [0.01, 0.05, 0.80, 0.10, 0.04]  → 知道类间相似度

"猫" 的 soft label 中 "狗" 的概率比 "飞机" 高
→ 隐含了 "猫和狗更相似" 的暗知识 (dark knowledge)
```

### 蒸馏损失函数

```python
import torch
import torch.nn.functional as F

def distillation_loss(student_logits, teacher_logits, labels, 
                      temperature=2.0, alpha=0.5):
    """
    经典知识蒸馏 loss
    
    L = α · L_soft + (1-α) · L_hard
    
    L_soft: 学生和教师的 soft distribution 的 KL 散度
    L_hard: 学生预测和真实标签的交叉熵
    """
    # Soft loss: KL(student_soft || teacher_soft)
    student_soft = F.log_softmax(student_logits / temperature, dim=-1)
    teacher_soft = F.softmax(teacher_logits / temperature, dim=-1)
    soft_loss = F.kl_div(student_soft, teacher_soft, reduction='batchmean')
    soft_loss = soft_loss * (temperature ** 2)  # 梯度补偿
    
    # Hard loss: CrossEntropy(student, labels)
    hard_loss = F.cross_entropy(student_logits, labels)
    
    return alpha * soft_loss + (1 - alpha) * hard_loss
```

### Temperature 的作用

```
T=1 (标准 softmax):  [0.01, 0.05, 0.90, 0.03, 0.01]  → 尖锐分布
T=2:                  [0.05, 0.12, 0.55, 0.18, 0.10]  → 平滑分布
T=5:                  [0.10, 0.15, 0.30, 0.25, 0.20]  → 更平滑

高温度 → 分布更平滑 → 暴露更多类间关系
         但温度太高 → 信息被稀释，噪声增大

推荐: T ∈ [2, 5]，通常 T=2 或 T=4
```

## 2. 蒸馏方法分类

### 2.1 输出层蒸馏（Logit-based / Soft Label）

```
最经典的方法: 学生模仿教师的输出分布

Teacher: input → [logit_1, logit_2, ..., logit_V] → softmax/T → soft targets
Student: input → [logit_1, logit_2, ..., logit_V] → softmax/T → 对齐 soft targets

优点: 实现简单，只需要教师的输出
缺点: 对 LLM 来说，vocab_size 巨大 (100K+)，存储 logits 成本高
```

### 2.2 特征蒸馏（Feature Distillation）

```
让学生模仿教师的中间层表示

Teacher: input → hidden_0 → hidden_1 → ... → hidden_N → output
                    ↓           ↓                 ↓
Student: input → hidden_0 → hidden_1 → ... → hidden_M → output
                    ↑           ↑                 ↑
              投影对齐      投影对齐          投影对齐

需要投影层: 因为 teacher 和 student 的 hidden_dim 通常不同
L_feature = MSE(W · student_hidden, teacher_hidden)
```

### 2.3 关系蒸馏（Relational KD）

```
不对齐绝对表示，而是对齐样本间的关系

教师空间中: dist(sample_i, sample_j) ≈ 学生空间中: dist(sample_i, sample_j)

方法:
  - PKT: 对齐概率分布间的互信息
  - RKD: 对齐样本对的距离和角度关系
  - CRD: 对比学习框架下的关系蒸馏
```

## 3. LLM 蒸馏的特殊挑战

```
挑战                          原因                          应对
─────────────────────────────────────────────────────────────────
1. 词表巨大                   100K+ token，存储 logits 成本高   只蒸馏 top-k logits
2. 序列生成                   auto-regressive, 错误会累积       on-policy 蒸馏
3. 教师太大无法部署            671B 参数的教师根本跑不动          离线生成 + SFT
4. 能力涌现不可分解            推理/创造力不在某一层              多任务混合蒸馏
5. 白盒 vs 黑盒               闭源模型拿不到 logits             只能用输出文本蒸馏
6. 灾难性遗忘                 蒸馏特定能力时通用能力退化          数据混合策略
```

### 白盒 vs 黑盒蒸馏

```
白盒蒸馏 (教师可访问内部):
  → 可以用 logits 对齐、特征对齐
  → 效果最好，但要求教师和学生同时在线
  → 代表: Megatron 蒸馏、TinyLLaMA

黑盒蒸馏 (只有教师的文本输出):
  → 用教师生成的 (prompt, response) 对做 SFT
  → 本质上是"数据蒸馏"
  → 代表: Alpaca (GPT-3.5→LLaMA), Vicuna, DeepSeek-R1-Distill
```

## 4. DeepSeek 蒸馏实践

### DeepSeek-R1 → DeepSeek-R1-Distill

DeepSeek-R1 (2025) 的蒸馏是 LLM 蒸馏的经典案例：

```
教师: DeepSeek-R1 (671B MoE, 37B 激活)
学生: Qwen2.5-7B / 14B / 32B, LLaMA-3.1-8B / 70B

蒸馏方法: 黑盒 SFT 蒸馏
  1. 用 DeepSeek-R1 生成大量高质量 CoT 推理数据
  2. 包含 <think>...</think> 思维链标记
  3. 直接在学生模型上做 SFT

结果 (令人惊讶):
  DeepSeek-R1-Distill-Qwen-32B > OpenAI o1-mini (数学/代码)
  DeepSeek-R1-Distill-Qwen-7B  > QwQ-32B-Preview
  → 蒸馏的 7B 模型超过了专门训练的 32B 推理模型！
```

### 蒸馏数据的关键

```python
# DeepSeek-R1 蒸馏数据格式示例
{
    "instruction": "证明 √2 是无理数",
    "output": """<think>
我需要证明√2是无理数。最经典的方法是反证法。

假设√2是有理数，则可以表示为 p/q，其中 p,q 互质...

如果 p² = 2q²，那么 p² 是偶数，因此 p 是偶数...
设 p = 2k，则 4k² = 2q²，即 q² = 2k²...
因此 q 也是偶数，与 p,q 互质矛盾。

所以√2是无理数。
</think>

**证明**：采用反证法。

假设 √2 是有理数，则存在互质的正整数 p, q 使得 √2 = p/q...
"""
}
```

### DeepSeek-V3 的自蒸馏

```
DeepSeek-V3 使用了"自蒸馏" (self-distillation):
  1. 先训练 DeepSeek-R1 (强推理模型)
  2. 从 R1 蒸馏推理 CoT 数据
  3. 将这些数据融入 V3 的 SFT 阶段
  4. 让 V3 在保持通用能力的同时获得推理增强

关键创新: 验证+反思 pattern 的蒸馏
  → 不只是蒸馏答案，而是蒸馏"思考过程"
  → V3 学会了何时验证、何时反思
```

## 5. 实用蒸馏 Pipeline

```python
# 使用 TRL 做 LLM 黑盒蒸馏
from transformers import AutoModelForCausalLM, AutoTokenizer
from trl import SFTTrainer, SFTConfig

# Step 1: 用教师模型生成蒸馏数据
teacher = AutoModelForCausalLM.from_pretrained("deepseek-ai/DeepSeek-R1")
teacher_tok = AutoTokenizer.from_pretrained("deepseek-ai/DeepSeek-R1")

def generate_distill_data(prompts, teacher, tokenizer):
    """用教师模型生成蒸馏数据"""
    distill_data = []
    for prompt in prompts:
        inputs = tokenizer(prompt, return_tensors="pt").to(teacher.device)
        output = teacher.generate(
            **inputs,
            max_new_tokens=4096,
            temperature=0.7,    # 适度随机性
            top_p=0.95,
            do_sample=True,
        )
        response = tokenizer.decode(output[0], skip_special_tokens=True)
        distill_data.append({"instruction": prompt, "output": response})
    return distill_data

# Step 2: 在学生模型上 SFT
student = AutoModelForCausalLM.from_pretrained("Qwen/Qwen2.5-7B")
student_tok = AutoTokenizer.from_pretrained("Qwen/Qwen2.5-7B")

trainer = SFTTrainer(
    model=student,
    tokenizer=student_tok,
    train_dataset=distill_dataset,
    args=SFTConfig(
        num_train_epochs=3,
        learning_rate=2e-5,
        per_device_train_batch_size=4,
        gradient_accumulation_steps=8,
        bf16=True,
        max_seq_length=4096,
    ),
)
trainer.train()
```

### 白盒蒸馏示例

```python
# 白盒蒸馏: 对齐 teacher 和 student 的 logits
def white_box_distill_step(student, teacher, batch, temperature=2.0, alpha=0.5):
    """白盒蒸馏训练步骤"""
    with torch.no_grad():
        teacher_outputs = teacher(**batch)
        teacher_logits = teacher_outputs.logits
    
    student_outputs = student(**batch)
    student_logits = student_outputs.logits
    
    # 只对 response token 计算蒸馏 loss
    mask = batch["labels"] != -100
    
    # KL divergence on soft targets
    T = temperature
    student_log_probs = F.log_softmax(student_logits[mask] / T, dim=-1)
    teacher_probs = F.softmax(teacher_logits[mask] / T, dim=-1)
    
    # Top-K 优化: 只对教师 top-k token 计算 KL
    top_k = 50
    top_k_indices = teacher_probs.topk(top_k, dim=-1).indices
    teacher_probs_k = teacher_probs.gather(-1, top_k_indices)
    student_log_probs_k = student_log_probs.gather(-1, top_k_indices)
    
    soft_loss = F.kl_div(student_log_probs_k, teacher_probs_k, 
                          reduction='batchmean') * (T ** 2)
    
    # Hard loss
    hard_loss = F.cross_entropy(student_logits[mask], batch["labels"][mask])
    
    return alpha * soft_loss + (1 - alpha) * hard_loss
```

## 6. 蒸馏效果评估

```
评估维度:
  1. 基准测试保持率 = student_score / teacher_score × 100%
     → 目标: >90% (7B蒸馏32B) / >80% (1.5B蒸馏7B)
  
  2. 推理效率提升 = teacher_latency / student_latency
     → 目标: 3-10x speedup
  
  3. 任务维度分析
     → 不同能力的蒸馏效率不同:
        知识问答: 蒸馏效果好 (知识可以通过数据传递)
        数学推理: 蒸馏效果中等 (需要大量 CoT 数据)
        创造力:   蒸馏效果差 (难以量化和传递)
```

## 7. 面试高频题

### Q1: 知识蒸馏中 temperature 的作用是什么？为什么要乘以 T²？
**答**：Temperature 控制 softmax 的平滑程度。T>1 时分布变平滑，暴露更多教师对各类别的细微偏好（暗知识）。T=1 时 softmax 过于尖锐，非正确类别的概率接近 0，学生学不到类间关系。乘以 T² 是梯度补偿——softmax(z/T) 对 z 的梯度被 T 缩小了，T² 将梯度 scale 恢复到与标准 CE loss 相同的量级，确保 soft loss 和 hard loss 的梯度贡献平衡。

### Q2: LLM 的黑盒蒸馏和白盒蒸馏有什么区别？各自适用场景？
**答**：黑盒蒸馏只使用教师的**文本输出**做 SFT，不需要教师的 logits 或中间表示。优点是简单、可蒸馏闭源模型；缺点是信息量少，只有 hard label。白盒蒸馏使用教师的 **logits**（甚至中间层特征）做对齐，信息量大，效果更好；缺点是需要同时加载教师和学生模型，显存要求高。实践中，对开源模型优先白盒；对闭源 API（如 GPT-4）只能黑盒。

### Q3: DeepSeek-R1 蒸馏的 7B 模型为什么能超过 32B 的 QwQ？
**答**：三个关键因素：(1) 教师极强——DeepSeek-R1 是 671B MoE 模型，其推理能力远超 QwQ-32B，蒸馏数据质量极高；(2) 蒸馏了"思维过程"——不只是最终答案，而是包含 `<think>` 标记的完整 CoT，学生学会了**如何推理**；(3) 模型容量够用——7B 模型的参数足以存储推理 pattern，瓶颈不在模型大小而在训练数据质量。

### Q4: 蒸馏和直接用小模型训练相比，优势在哪里？
**答**：(1) 教师的 soft label 提供了比 hard label 更丰富的监督信号（类间相似度、置信度分布）；(2) 教师可以"纠正"训练数据中的噪声——即使标签有误，教师的输出通常是合理的；(3) 对于 LLM，教师可以生成比人工标注更多、更一致的高质量数据（数据增强效应）；(4) 蒸馏可以传递教师的隐性能力（如推理链、格式控制），这些在原始数据中可能不存在。

### Q5: 蒸馏时如何避免学生模型的灾难性遗忘？
**答**：(1) **数据混合**——蒸馏数据中混入通用任务数据，比例通常 1:1 到 1:3；(2) **渐进蒸馏**——先蒸馏通用能力，再逐步加入专项能力；(3) **正则化**——用原始模型作为锚点，添加 KL(student_current || student_original) 惩罚项；(4) **LoRA 蒸馏**——只训练 adapter，冻结大部分参数，天然防遗忘；(5) **评估全面**——监控目标任务和通用任务的指标，发现退化及时调整数据配比。

---

## See Also

- [[AI/4-模型/DeepSeek/DeepSeek-R1|DeepSeek-R1]] — 蒸馏最佳案例：671B MoE 蒸馏到 7B 超越 QwQ-32B，教师强度 + CoT 思维过程蒸馏是关键
- [[AI/3-LLM/SFT/SFT 原理|SFT 原理]] — 蒸馏的实现基础：黑盒蒸馏本质是 SFT，白盒蒸馏在 SFT 上加 soft label KD loss
- [[AI/3-LLM/SFT/LoRA|LoRA]] — 蒸馏效率方案：LoRA 蒸馏冻结大部分参数，天然防灾难性遗忘
- [[AI/6-应用/Synthetic-Data/DataFlow|Synthetic Data]] — 蒸馏数据工程：大模型生成合成数据是黑盒蒸馏的核心数据管道
