---
brief: "SFT 训练数据构建全链路——从 seed data 到高质量 instruction dataset 的数据工程；Alpaca/ShareGPT/ChatML 格式规范；数据质量过滤/去重/多样性保证；Self-Instruct 自动扩充方法的工程实现。"
title: "训练数据构建：SFT 数据工程全链路"
date: 2026-02-14
domain: AI/LLM/SFT
tags: [SFT, 训练数据, 指令微调, 数据工程, Alpaca, ShareGPT, ChatML, Self-Instruct, 数据质量]
rating: 4
status: active
---

> [!info] 另有面试版
> Foundations 精简版：[[AI/3-LLM/Pretraining/LLM数据工程2026技术全景]]

# 训练数据构建

高质量的训练数据是 [[AI/3-LLM/SFT/SFT 原理]] (Supervised Fine-Tuning) 成功的关键。LIMA 论文证明了"Less is More"的重要性：1000 条高质量数据胜过 10 万条低质量数据。

## 指令数据格式

### Alpaca 格式

最经典的指令-输入-输出三元组格式，适合单轮任务。

```json
{
  "instruction": "解释什么是机器学习",
  "input": "",
  "output": "机器学习是人工智能的一个分支，它使计算机系统能够通过经验自动改进性能，而无需被明确编程。"
}
```

**转换为训练格式：**
```python
def format_alpaca_prompt(instruction, input_text="", output=""):
    """Alpaca 格式转换"""
    if input_text:
        prompt = f"Below is an instruction that describes a task, paired with an input that provides further context.\n\n### Instruction:\n{instruction}\n\n### Input:\n{input_text}\n\n### Response:\n"
    else:
        prompt = f"Below is an instruction that describes a task.\n\n### Instruction:\n{instruction}\n\n### Response:\n"
    
    if output:
        return prompt + output
    return prompt

# 示例用法
training_text = format_alpaca_prompt(
    instruction="将以下句子翻译成英文",
    input_text="机器学习是人工智能的重要分支",
    output="Machine learning is an important branch of artificial intelligence."
)
```

### ShareGPT 格式

多轮对话格式，更符合 ChatGPT 的交互方式。

```json
{
  "conversations": [
    {"from": "human", "value": "请解释深度学习的基本概念"},
    {"from": "gpt", "value": "深度学习是机器学习的一个子领域，使用具有多个隐藏层的神经网络来学习数据的复杂模式。"},
    {"from": "human", "value": "它与传统机器学习有什么区别？"},
    {"from": "gpt", "value": "主要区别在于：1) 特征提取自动化；2) 模型复杂度更高；3) 需要更多数据..."}
  ]
}
```

**训练时处理：**
```python
def process_sharegpt_conversation(conversation):
    """处理 ShareGPT 格式的对话"""
    messages = []
    for turn in conversation['conversations']:
        if turn['from'] == 'human':
            messages.append({"role": "user", "content": turn['value']})
        elif turn['from'] == 'gpt':
            messages.append({"role": "assistant", "content": turn['value']})
    
    return messages

def format_conversation_for_training(messages):
    """转换为训练格式"""
    formatted = ""
    for i, msg in enumerate(messages):
        if msg['role'] == 'user':
            formatted += f"<|user|>\n{msg['content']}\n"
        elif msg['role'] == 'assistant':
            formatted += f"<|assistant|>\n{msg['content']}\n"
    
    return formatted + "<|endoftext|>"
```

### ChatML 格式

OpenAI 提出的标准化对话格式，支持系统消息。

```json
{
  "messages": [
    {"role": "system", "content": "你是一个专业的AI助手，善于解释技术概念。"},
    {"role": "user", "content": "什么是 Transformer 架构？"},
    {"role": "assistant", "content": "Transformer 是一种基于自注意力机制的神经网络架构..."}
  ]
}
```

**特点：**
- 明确区分系统、用户、助手角色
- 支持复杂的多轮对话
- 易于扩展（可添加工具调用等角色）

## 数据质量 > 数据数量

### LIMA 论文启示

Meta 的 LIMA (Less Is More for Alignment) 论文证明：
- **1000 条精心策划的数据 > 100K 条一般质量数据**
- 质量维度：指令多样性、回复质量、格式一致性
- 关键在于覆盖核心能力，而非数据规模

### 高质量数据特征

```python
class DataQualityChecker:
    """数据质量检查器"""
    
    def check_instruction_quality(self, instruction, response):
        """检查指令-回复质量"""
        quality_score = 0
        issues = []
        
        # 1. 指令清晰度
        if len(instruction.split()) < 5:
            issues.append("指令过短，缺乏具体性")
        elif len(instruction.split()) > 100:
            issues.append("指令过长，可能包含无关信息")
        else:
            quality_score += 1
        
        # 2. 回复完整性
        if len(response) < 50:
            issues.append("回复过短，信息不足")
        elif self._is_complete_response(response):
            quality_score += 1
        
        # 3. 格式一致性
        if self._has_consistent_format(instruction, response):
            quality_score += 1
        
        # 4. 内容相关性
        if self._is_relevant(instruction, response):
            quality_score += 1
        
        return {
            'score': quality_score / 4,
            'issues': issues
        }
    
    def _is_complete_response(self, response):
        """检查回复完整性"""
        # 检查是否有未完成的句子
        return not response.strip().endswith(('...', '，', '、'))
    
    def _is_relevant(self, instruction, response):
        """检查内容相关性"""
        # 简化的相关性检查
        instruction_words = set(instruction.lower().split())
        response_words = set(response.lower().split())
        
        # 计算词汇重叠度
        overlap = len(instruction_words & response_words)
        return overlap / len(instruction_words) > 0.1
```

## 数据配比策略

### 多任务平衡

```python
TASK_DISTRIBUTION = {
    'qa': 0.25,           # 问答任务
    'summarization': 0.15, # 摘要任务  
    'translation': 0.10,   # 翻译任务
    'code': 0.20,         # 代码任务
    'creative': 0.15,     # 创意写作
    'reasoning': 0.15     # 推理任务
}

def balance_dataset(raw_datasets):
    """平衡多任务数据集"""
    balanced_data = []
    total_size = 10000  # 目标总数据量
    
    for task, ratio in TASK_DISTRIBUTION.items():
        task_data = raw_datasets[task]
        target_size = int(total_size * ratio)
        
        if len(task_data) > target_size:
            # 随机采样
            sampled = random.sample(task_data, target_size)
        else:
            # 重复采样或合成数据补充
            sampled = task_data * (target_size // len(task_data) + 1)
            sampled = sampled[:target_size]
        
        balanced_data.extend(sampled)
    
    # 随机打乱
    random.shuffle(balanced_data)
    return balanced_data
```

### 多语言策略

```python
LANGUAGE_DISTRIBUTION = {
    'zh': 0.4,    # 中文
    'en': 0.4,    # 英文
    'code': 0.2   # 代码（语言无关）
}

def create_multilingual_dataset(zh_data, en_data, code_data):
    """构建多语言数据集"""
    dataset = []
    
    # 中文数据
    zh_samples = random.sample(zh_data, int(10000 * 0.4))
    dataset.extend(zh_samples)
    
    # 英文数据
    en_samples = random.sample(en_data, int(10000 * 0.4))
    dataset.extend(en_samples)
    
    # 代码数据
    code_samples = random.sample(code_data, int(10000 * 0.2))
    dataset.extend(code_samples)
    
    return dataset
```

### 难度梯度

```python
class DifficultyBalancer:
    """难度平衡器"""
    
    def __init__(self):
        self.difficulty_levels = {
            'easy': {'ratio': 0.4, 'criteria': self._is_easy},
            'medium': {'ratio': 0.4, 'criteria': self._is_medium}, 
            'hard': {'ratio': 0.2, 'criteria': self._is_hard}
        }
    
    def _is_easy(self, sample):
        """简单任务：单步推理，直接回忆"""
        instruction = sample['instruction'].lower()
        easy_patterns = ['什么是', 'define', '解释', 'explain']
        return any(pattern in instruction for pattern in easy_patterns)
    
    def _is_medium(self, sample):
        """中等任务：多步推理，需要分析"""
        instruction = sample['instruction'].lower()
        medium_patterns = ['分析', 'analyze', '比较', 'compare', '如何']
        return any(pattern in instruction for pattern in medium_patterns)
    
    def _is_hard(self, sample):
        """困难任务：复杂推理，创造性任务"""
        instruction = sample['instruction'].lower()
        hard_patterns = ['设计', 'design', '创造', 'create', '优化', 'optimize']
        return any(pattern in instruction for pattern in hard_patterns)
    
    def balance_by_difficulty(self, dataset):
        """按难度平衡数据"""
        categorized = {level: [] for level in self.difficulty_levels}
        
        for sample in dataset:
            for level, config in self.difficulty_levels.items():
                if config['criteria'](sample):
                    categorized[level].append(sample)
                    break
        
        balanced = []
        total_size = len(dataset)
        
        for level, config in self.difficulty_levels.items():
            target_size = int(total_size * config['ratio'])
            level_data = categorized[level]
            
            if len(level_data) >= target_size:
                balanced.extend(random.sample(level_data, target_size))
            else:
                balanced.extend(level_data)
        
        return balanced
```

## 数据清洗与去污染

### 重复数据检测

```python
import hashlib
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

class DataDeduplicator:
    """数据去重器"""
    
    def __init__(self, similarity_threshold=0.9):
        self.threshold = similarity_threshold
        self.vectorizer = TfidfVectorizer()
    
    def exact_deduplication(self, dataset):
        """精确去重"""
        seen_hashes = set()
        deduplicated = []
        
        for sample in dataset:
            # 组合指令和回复计算哈希
            content = sample['instruction'] + sample['output']
            content_hash = hashlib.md5(content.encode()).hexdigest()
            
            if content_hash not in seen_hashes:
                seen_hashes.add(content_hash)
                deduplicated.append(sample)
        
        return deduplicated
    
    def semantic_deduplication(self, dataset):
        """语义去重"""
        if len(dataset) == 0:
            return dataset
            
        # 提取文本特征
        texts = [s['instruction'] + ' ' + s['output'] for s in dataset]
        tfidf_matrix = self.vectorizer.fit_transform(texts)
        
        # 计算相似度矩阵
        similarity_matrix = cosine_similarity(tfidf_matrix)
        
        # 标记重复项
        to_remove = set()
        for i in range(len(similarity_matrix)):
            for j in range(i+1, len(similarity_matrix)):
                if similarity_matrix[i][j] > self.threshold:
                    to_remove.add(j)  # 保留较早的样本
        
        # 过滤重复项
        deduplicated = [
            dataset[i] for i in range(len(dataset)) 
            if i not in to_remove
        ]
        
        return deduplicated
```

### 内容过滤

```python
class ContentFilter:
    """内容过滤器"""
    
    def __init__(self):
        self.toxic_keywords = [
            # 有害内容关键词
            '暴力', '仇恨', '歧视', '违法'
        ]
        
        self.low_quality_patterns = [
            r'^\w{1,3}$',  # 过短回复
            r'^(好|是|对|不是)的?[。！？]*$',  # 无意义回复
            r'^[。！？\s]*$'  # 只有标点
        ]
    
    def filter_dataset(self, dataset):
        """过滤数据集"""
        filtered = []
        stats = {'total': len(dataset), 'filtered_toxic': 0, 
                'filtered_quality': 0, 'kept': 0}
        
        for sample in dataset:
            # 检查有害内容
            if self._is_toxic(sample):
                stats['filtered_toxic'] += 1
                continue
            
            # 检查质量
            if self._is_low_quality(sample):
                stats['filtered_quality'] += 1
                continue
                
            filtered.append(sample)
            stats['kept'] += 1
        
        print(f"过滤统计: {stats}")
        return filtered
    
    def _is_toxic(self, sample):
        """检查是否包含有害内容"""
        text = sample['instruction'] + ' ' + sample['output']
        return any(keyword in text.lower() for keyword in self.toxic_keywords)
    
    def _is_low_quality(self, sample):
        """检查是否低质量"""
        import re
        response = sample['output'].strip()
        
        return any(re.match(pattern, response) 
                  for pattern in self.low_quality_patterns)
```

## 合成数据方法

### Self-Instruct

通过 LLM 自动生成指令-回复对。

```python
class SelfInstructGenerator:
    """Self-Instruct 生成器"""
    
    def __init__(self, llm_client):
        self.llm = llm_client
        self.seed_instructions = [
            "解释一个科学概念",
            "写一首关于自然的诗",
            "设计一个算法解决问题",
            "分析一个历史事件"
        ]
    
    def generate_instruction(self, seed_instruction):
        """生成新指令"""
        prompt = f"""
基于以下种子指令，生成一个相关但不同的新指令：

种子指令：{seed_instruction}

要求：
1. 新指令应该与种子指令相关但不相同
2. 指令要明确、具体
3. 难度适中，可以被合理回答

新指令：
"""
        return self.llm.generate(prompt).strip()
    
    def generate_response(self, instruction):
        """为指令生成回复"""
        prompt = f"""
请为以下指令提供一个高质量、详细的回复：

指令：{instruction}

回复：
"""
        return self.llm.generate(prompt).strip()
    
    def generate_dataset(self, num_samples=1000):
        """生成合成数据集"""
        dataset = []
        
        for _ in range(num_samples):
            # 随机选择种子指令
            seed = random.choice(self.seed_instructions)
            
            # 生成新指令
            instruction = self.generate_instruction(seed)
            
            # 生成回复
            response = self.generate_response(instruction)
            
            dataset.append({
                'instruction': instruction,
                'input': '',
                'output': response,
                'source': 'self_instruct'
            })
        
        return dataset
```

### Evol-Instruct

通过进化策略逐步增强指令复杂度。

```python
class EvolInstructGenerator:
    """Evol-Instruct 生成器"""
    
    def __init__(self, llm_client):
        self.llm = llm_client
        self.evolution_methods = [
            self._add_constraints,
            self._increase_reasoning,
            self._add_breadth,
            self._deepen_complexity
        ]
    
    def _add_constraints(self, instruction):
        """添加约束条件"""
        prompt = f"""
为以下指令添加合理的约束条件，使其更具挑战性：

原指令：{instruction}

进化后的指令：
"""
        return self.llm.generate(prompt).strip()
    
    def _increase_reasoning(self, instruction):
        """增加推理要求"""
        prompt = f"""
修改以下指令，使其需要更多的推理和分析：

原指令：{instruction}

进化后的指令：
"""
        return self.llm.generate(prompt).strip()
    
    def evolve_instruction(self, base_instruction, generations=3):
        """进化指令"""
        current = base_instruction
        
        for _ in range(generations):
            method = random.choice(self.evolution_methods)
            current = method(current)
        
        return current
```

### Magpie

使用查询生成和自过滤生成高质量数据。

```python
class MagpieGenerator:
    """Magpie 生成器"""
    
    def __init__(self, llm_client):
        self.llm = llm_client
        
    def generate_query(self, domain="通用"):
        """生成查询"""
        prompt = f"""
生成一个关于{domain}领域的高质量问题或指令。要求：
1. 问题要有深度，需要专业知识回答
2. 问题要实用，有实际价值
3. 问题要清晰明确

问题：
"""
        return self.llm.generate(prompt).strip()
    
    def self_filter(self, query, response):
        """自过滤机制"""
        prompt = f"""
评估以下问答对的质量（1-5分）：

问题：{query}
回答：{response}

评估标准：
1. 回答的准确性和完整性
2. 语言的流畅性和专业性  
3. 是否直接回应了问题

评分（1-5）：
"""
        
        score_text = self.llm.generate(prompt).strip()
        try:
            score = int(score_text.split('：')[-1])
            return score >= 4
        except:
            return False
    
    def generate_high_quality_pairs(self, num_pairs=1000, domain="通用"):
        """生成高质量问答对"""
        high_quality_pairs = []
        attempts = 0
        
        while len(high_quality_pairs) < num_pairs and attempts < num_pairs * 3:
            attempts += 1
            
            # 生成查询
            query = self.generate_query(domain)
            
            # 生成回复
            response = self.llm.generate(f"请详细回答：{query}")
            
            # 自过滤
            if self.self_filter(query, response):
                high_quality_pairs.append({
                    'instruction': query,
                    'input': '',
                    'output': response,
                    'source': 'magpie'
                })
        
        return high_quality_pairs
```

## 面试常见问题

### 1. Alpaca 格式和 ShareGPT 格式的适用场景有什么区别？

**答案：**

**Alpaca 格式：**
- **适用场景：** 单轮任务，指令遵循训练
- **优势：** 格式简单，易于处理和分析
- **典型任务：** 翻译、摘要、问答、代码生成

**ShareGPT 格式：**
- **适用场景：** 多轮对话，聊天机器人训练
- **优势：** 保持对话上下文，支持复杂交互
- **典型任务：** 客服对话、教学助手、复杂推理

**技术差异：**
```python
# Alpaca: 简单的输入输出映射
"instruction" → "output"

# ShareGPT: 维护对话状态
[user_msg1, assistant_msg1, user_msg2, assistant_msg2, ...]
```

**选择原则：** 如果任务主要是单步完成的指令，选择 Alpaca；如果需要多轮交互和上下文记忆，选择 ShareGPT。

### 2. 如何量化评估训练数据的质量？

**答案：**

**多维度评估体系：**

1. **多样性指标：**
```python
def calculate_diversity_metrics(dataset):
    # 词汇多样性
    vocab_diversity = len(unique_words) / total_words
    
    # 句法多样性（句子长度分布）
    length_variance = np.var([len(s['output'].split()) for s in dataset])
    
    # 语义多样性（embedding 聚类）
    semantic_clusters = cluster_embeddings(dataset)
    semantic_diversity = len(semantic_clusters) / len(dataset)
    
    return {
        'vocab_diversity': vocab_diversity,
        'length_variance': length_variance, 
        'semantic_diversity': semantic_diversity
    }
```

2. **质量指标：**
```python
def calculate_quality_metrics(dataset):
    # 语法正确性（使用语法检查器）
    grammar_scores = [check_grammar(s['output']) for s in dataset]
    
    # 指令遵循度（指令与回复相关性）
    relevance_scores = [
        calculate_relevance(s['instruction'], s['output']) 
        for s in dataset
    ]
    
    # 完整性（回复是否完整）
    completeness_scores = [
        check_completeness(s['output']) for s in dataset
    ]
    
    return {
        'grammar_avg': np.mean(grammar_scores),
        'relevance_avg': np.mean(relevance_scores),
        'completeness_avg': np.mean(completeness_scores)
    }
```

3. **平衡性指标：**
```python
def calculate_balance_metrics(dataset):
    # 任务类型分布
    task_distribution = Counter([s['task_type'] for s in dataset])
    
    # 长度分布
    length_distribution = [len(s['output'].split()) for s in dataset]
    
    # 难度分布
    difficulty_distribution = Counter([s['difficulty'] for s in dataset])
    
    return {
        'task_entropy': calculate_entropy(task_distribution),
        'length_cv': np.std(length_distribution) / np.mean(length_distribution),
        'difficulty_balance': min(difficulty_distribution.values()) / max(difficulty_distribution.values())
    }
```

### 3. Self-Instruct 和 Evol-Instruct 的核心差异是什么？

**答案：**

**Self-Instruct：**
- **核心思想：** 从种子指令出发，生成相关但不同的新指令
- **生成方式：** 一步生成，水平扩展
- **优势：** 快速扩充数据，保持一定多样性
- **劣势：** 质量参差不齐，缺乏系统性提升

**Evol-Instruct：**
- **核心思想：** 通过多轮进化逐步提升指令复杂度
- **生成方式：** 迭代进化，垂直提升
- **进化策略：** 
  - 增加约束条件
  - 加深推理要求
  - 扩展问题范围
  - 提高复杂度

**代码对比：**
```python
# Self-Instruct: 横向扩展
def self_instruct(seed):
    return generate_similar_instruction(seed)

# Evol-Instruct: 纵向进化  
def evol_instruct(base_instruction, depth=3):
    current = base_instruction
    for _ in range(depth):
        current = evolve_instruction(current)
    return current
```

**应用场景：**
- **Self-Instruct：** 需要快速扩充特定类型数据
- **Evol-Instruct：** 需要提升模型处理复杂任务的能力

### 4. 如何处理多语言训练数据的配比问题？

**答案：**

**关键考虑因素：**

1. **目标用户分布：**
```python
# 根据实际用户分布调整
USER_DISTRIBUTION = {
    'zh': 0.6,  # 中文用户占 60%
    'en': 0.3,  # 英文用户占 30%  
    'other': 0.1  # 其他语言 10%
}

# 数据配比略高于用户分布，考虑学习难度
DATA_DISTRIBUTION = {
    'zh': 0.5,
    'en': 0.4, 
    'code': 0.1  # 代码作为通用语言
}
```

2. **语言学习难度：**
```python
# 不同语言需要不同的数据量
LANGUAGE_WEIGHTS = {
    'zh': 1.2,  # 中文语法复杂，需要更多数据
    'en': 1.0,  # 英文作为基准
    'code': 0.8  # 代码语法规则明确，需要较少数据
}

def adjust_language_ratio(base_distribution, weights):
    adjusted = {}
    for lang, ratio in base_distribution.items():
        adjusted[lang] = ratio * weights.get(lang, 1.0)
    
    # 重新归一化
    total = sum(adjusted.values())
    return {lang: ratio/total for lang, ratio in adjusted.items()}
```

3. **跨语言任务处理：**
```python
def create_cross_lingual_dataset(zh_data, en_data):
    """创建跨语言数据集"""
    cross_lingual = []
    
    # 翻译任务
    for zh_sample in zh_data[:1000]:
        cross_lingual.append({
            'instruction': 'Translate to English',
            'input': zh_sample['content'],
            'output': translate_to_english(zh_sample['content'])
        })
    
    # 语言理解任务
    for sample in random.sample(zh_data + en_data, 500):
        cross_lingual.append({
            'instruction': 'Answer in the same language as the question',
            'input': sample['question'],
            'output': sample['answer']  # 保持原语言回答
        })
    
    return cross_lingual
```

### 5. 如何设计训练数据的增量更新策略？

**答案：**

**增量更新挑战：**
- **灾难性遗忘：** 新数据覆盖旧知识
- **数据漂移：** 新旧数据分布不一致
- **质量控制：** 确保增量数据质量

**解决方案：**

1. **数据版本管理：**
```python
class DataVersionManager:
    def __init__(self):
        self.versions = {}
        
    def add_version(self, version_id, new_data, base_version=None):
        """添加数据版本"""
        if base_version:
            # 增量添加
            base_data = self.versions[base_version]['data']
            merged_data = self.merge_datasets(base_data, new_data)
        else:
            merged_data = new_data
            
        self.versions[version_id] = {
            'data': merged_data,
            'timestamp': datetime.now(),
            'base_version': base_version,
            'stats': self.calculate_stats(merged_data)
        }
    
    def merge_datasets(self, old_data, new_data):
        """合并数据集"""
        # 1. 去重
        merged = self.deduplicate(old_data + new_data)
        
        # 2. 重新平衡
        merged = self.rebalance_tasks(merged)
        
        # 3. 质量过滤
        merged = self.quality_filter(merged)
        
        return merged
```

2. **渐进训练策略：**
```python
class IncrementalTrainingStrategy:
    def __init__(self, model, old_dataset, new_dataset):
        self.model = model
        self.old_dataset = old_dataset
        self.new_dataset = new_dataset
    
    def progressive_training(self):
        """渐进式训练"""
        # 阶段1：用少量新数据预热
        warmup_data = random.sample(self.new_dataset, 100)
        self.model.train(warmup_data, learning_rate=1e-5)
        
        # 阶段2：混合训练（新数据 + 采样的旧数据）
        mixed_data = (
            self.new_dataset + 
            random.sample(self.old_dataset, len(self.new_dataset) // 2)
        )
        self.model.train(mixed_data, learning_rate=5e-6)
        
        # 阶段3：全量微调
        if self.validate_performance():
            full_data = self.old_dataset + self.new_dataset
            self.model.train(full_data, learning_rate=1e-6)
```

3. **质量监控体系：**
```python
def monitor_incremental_quality(old_stats, new_stats, thresholds):
    """监控增量数据质量"""
    alerts = []
    
    # 检查分布漂移
    kl_divergence = calculate_kl_divergence(
        old_stats['task_distribution'], 
        new_stats['task_distribution']
    )
    
    if kl_divergence > thresholds['distribution_drift']:
        alerts.append(f"任务分布漂移过大: {kl_divergence:.3f}")
    
    # 检查质量指标
    quality_drop = old_stats['quality_score'] - new_stats['quality_score']
    if quality_drop > thresholds['quality_drop']:
        alerts.append(f"质量下降: {quality_drop:.3f}")
    
    return alerts
```

**关键原则：**
- 保持核心数据不变，增量添加新场景
- 定期重新平衡整个数据集
- 建立质量监控和回滚机制
- 采用渐进式训练避免灾难性遗忘

---

---

## See Also

- [[AI/3-LLM/SFT/SFT 原理|SFT 原理]] — 数据构建的理论基础：LIMA"Less is More"原则说明数据质量>数量，与本文的质量控制体系形成配套
- [[AI/3-LLM/Pretraining/预训练数据工程|预训练数据工程]] — 上游知识：预训练阶段的 web-scale Dedup/质量过滤/配比优化（Llama-3/FineWeb/DoReMi）；对比：预训练 = 数量×质量双驱动，SFT = 质量>数量（LIMA原则）
- 合成数据与数据飞轮2026全景 ⭐ — 当人工标注数据达到上限时，Self-Instruct/RLAIF/数据飞轮是训练数据的合成扩展路径；本文实战，全景版提供方法论
- [[AI/3-LLM/Pretraining/预训练数据工程|LLM数据工程2026全景]] — 3778行：预训练数据管线全覆盖；与SFT数据构建形成预训练→微调的完整数据工程体系
- RLHF DPO 2026技术全景 — 偏好数据构建是RLHF pipeline的上游输入；本文SFT数据构建 + RLHF偏好数据构建 = post-training完整数据路径
- LLM微调实战2026全景 ⭐ — 数据构建的工程落地；ChatML格式/数据清洗/质量过滤的具体代码实现