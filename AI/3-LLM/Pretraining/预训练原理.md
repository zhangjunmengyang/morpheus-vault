---
brief: "预训练原理——LLM 预训练的完整技术体系：目标函数（Next Token Prediction/MLM）/Scaling Laws/数据并行/模型并行/流水线并行；从基础原理到工程实现的完整参考，面试被问预训练 vs 微调区别的标准框架。"
tags: [LLM, Pretraining, Training, Language-Model, Scaling-Laws]
created: 2026-02-14
status: draft
---

# 预训练原理

预训练（Pretraining）是大语言模型训练的第一阶段，模型在大规模无标注文本数据上学习语言的基本规律和知识。本文详细介绍预训练的核心原理、技术细节和工程实践。

## 预训练目标函数

### Causal Language Modeling (CLM)
最主流的预训练目标，模型学习预测下一个 token：

```python
# GPT 风格的因果语言建模
def causal_lm_loss(logits, targets):
    """
    logits: [batch_size, seq_len, vocab_size]
    targets: [batch_size, seq_len]
    """
    # 只计算预测位置的损失
    shift_logits = logits[..., :-1, :].contiguous()
    shift_labels = targets[..., 1:].contiguous()
    
    loss_fct = CrossEntropyLoss()
    loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), 
                   shift_labels.view(-1))
    return loss
```

数学表达式：
$$\mathcal{L}_{CLM} = -\sum_{i=1}^{T} \log P(x_i | x_{<i}; \theta)$$

### Masked Language Modeling (MLM)
BERT 风格，随机 mask 部分 token 并预测：

```python
def create_masked_input(input_ids, mask_prob=0.15):
    """创建带 mask 的输入"""
    labels = input_ids.clone()
    masked_indices = torch.rand(input_ids.shape) < mask_prob
    
    # 80% 替换为 [MASK]，10% 随机替换，10% 保持不变
    indices_replaced = torch.rand(input_ids.shape) < 0.8
    input_ids[masked_indices & indices_replaced] = MASK_TOKEN_ID
    
    indices_random = torch.rand(input_ids.shape) < 0.5
    random_words = torch.randint(vocab_size, input_ids.shape)
    input_ids[masked_indices & ~indices_replaced & indices_random] = random_words[masked_indices & ~indices_replaced & indices_random]
    
    # 只计算被 mask 位置的损失
    labels[~masked_indices] = -100
    return input_ids, labels
```

### Prefix Language Modeling
PaLM、GLM 等使用的混合方式，结合了 CLM 和 MLM 的优点：

```python
def prefix_lm_loss(logits, targets, prefix_length):
    """
    前缀部分使用双向注意力，生成部分使用因果注意力
    """
    # 前缀部分不计算损失，只有生成部分计算
    mask = torch.zeros_like(targets, dtype=torch.bool)
    mask[:, prefix_length:] = True
    
    masked_targets = targets.clone()
    masked_targets[~mask] = -100
    
    return cross_entropy(logits.view(-1, logits.size(-1)), 
                        masked_targets.view(-1))
```

## 数据清洗 Pipeline

### 去重策略

```python
# 基于 MinHash 的近似去重
from datasketch import MinHashLSH, MinHash

def dedup_documents(documents, threshold=0.8):
    """文档级去重"""
    lsh = MinHashLSH(threshold=threshold, num_perm=128)
    deduplicated = []
    
    for i, doc in enumerate(documents):
        minhash = MinHash(num_perm=128)
        for token in doc.split():
            minhash.update(token.encode('utf8'))
        
        # 检查是否存在相似文档
        similar_docs = lsh.query(minhash)
        if not similar_docs:
            lsh.insert(f"doc_{i}", minhash)
            deduplicated.append(doc)
    
    return deduplicated

# 序列级去重（处理重复的段落/句子）
def sequence_dedup(text, min_length=50):
    """移除重复的长序列"""
    from collections import defaultdict
    
    sentences = text.split('.')
    seen_sequences = defaultdict(int)
    filtered_sentences = []
    
    for sent in sentences:
        if len(sent.strip()) < min_length:
            filtered_sentences.append(sent)
            continue
            
        # 使用滑动窗口检查重复
        normalized = ' '.join(sent.strip().split())
        seen_sequences[normalized] += 1
        
        if seen_sequences[normalized] <= 2:  # 允许最多出现2次
            filtered_sentences.append(sent)
    
    return '.'.join(filtered_sentences)
```

### 质量过滤
多维度质量评估：

```python
class QualityFilter:
    def __init__(self):
        self.min_words = 10
        self.max_words = 10000
        self.min_chars_per_word = 3
        self.max_chars_per_word = 15
    
    def filter_document(self, text):
        """综合质量评估"""
        # 基础统计特征
        words = text.split()
        word_count = len(words)
        
        if not (self.min_words <= word_count <= self.max_words):
            return False, "word_count_filter"
        
        # 字符长度分布
        avg_word_length = sum(len(w) for w in words) / word_count
        if not (self.min_chars_per_word <= avg_word_length <= self.max_chars_per_word):
            return False, "word_length_filter"
        
        # 特殊字符比例
        special_chars = sum(1 for c in text if not c.isalnum() and not c.isspace())
        special_ratio = special_chars / len(text)
        if special_ratio > 0.3:
            return False, "special_char_filter"
        
        # 语言检测
        if not self._is_target_language(text):
            return False, "language_filter"
        
        # 内容质量（困惑度）
        perplexity = self._compute_perplexity(text)
        if perplexity > 1000:  # 困惑度过高说明质量较差
            return False, "perplexity_filter"
        
        return True, "passed"
```

### 有害内容过滤

```python
# 基于分类器的有害内容检测
class ToxicityFilter:
    def __init__(self, model_path):
        self.classifier = load_model(model_path)  # 预训练的毒性分类器
        self.toxic_keywords = self._load_keywords()
    
    def is_harmful(self, text, threshold=0.7):
        """多层次有害内容检测"""
        # 关键词匹配（快速过滤）
        if any(keyword in text.lower() for keyword in self.toxic_keywords):
            return True, "keyword_match"
        
        # 分类器预测
        toxicity_score = self.classifier.predict_proba([text])[0][1]
        if toxicity_score > threshold:
            return True, f"classifier_score_{toxicity_score:.3f}"
        
        return False, "clean"
```

## 数据配比策略

### 多领域数据混合
基于 [[AI/1-Foundations/Scaling Laws]] 的最优配比：

```python
# PaLM 风格的数据配比
DATA_MIXTURE = {
    "web": 0.60,           # 网页数据（主体）
    "books": 0.16,         # 书籍（高质量长文本）
    "code": 0.12,          # 代码（逻辑推理能力）
    "news": 0.05,          # 新闻（时效性信息）
    "academic": 0.04,      # 学术论文（专业知识）
    "conversational": 0.03 # 对话数据（交互能力）
}

# 动态配比调整策略
class DataMixtureScheduler:
    def __init__(self, total_tokens, mixture_config):
        self.total_tokens = total_tokens
        self.mixture_config = mixture_config
        self.current_step = 0
    
    def get_current_mixture(self, step):
        """训练过程中动态调整数据配比"""
        progress = step / self.total_tokens
        
        # 早期阶段增加代码和学术数据比例（提升推理能力）
        if progress < 0.3:
            adjusted = self.mixture_config.copy()
            adjusted["code"] *= 1.5
            adjusted["academic"] *= 1.2
            # 重新归一化
            total = sum(adjusted.values())
            adjusted = {k: v/total for k, v in adjusted.items()}
            return adjusted
        
        return self.mixture_config
```

## 训练稳定性技巧

### Gradient Clipping
```python
def clip_gradient_norm(model, max_norm=1.0):
    """梯度裁剪防止梯度爆炸"""
    total_norm = 0
    for p in model.parameters():
        if p.grad is not None:
            param_norm = p.grad.data.norm(2)
            total_norm += param_norm.item() ** 2
    total_norm = total_norm ** (1. / 2)
    
    clip_coef = max_norm / (total_norm + 1e-6)
    if clip_coef < 1:
        for p in model.parameters():
            if p.grad is not None:
                p.grad.data.mul_(clip_coef)
    
    return total_norm
```

### Learning Rate Schedule
```python
class WarmupCosineScheduler:
    def __init__(self, optimizer, warmup_steps, total_steps, base_lr, min_lr=0):
        self.optimizer = optimizer
        self.warmup_steps = warmup_steps
        self.total_steps = total_steps
        self.base_lr = base_lr
        self.min_lr = min_lr
    
    def step(self, current_step):
        if current_step < self.warmup_steps:
            # 线性预热
            lr = self.base_lr * current_step / self.warmup_steps
        else:
            # 余弦衰减
            progress = (current_step - self.warmup_steps) / (self.total_steps - self.warmup_steps)
            lr = self.min_lr + (self.base_lr - self.min_lr) * 0.5 * (1 + math.cos(math.pi * progress))
        
        for param_group in self.optimizer.param_groups:
            param_group['lr'] = lr
```

### Loss Spike 处理
```python
class LossSpikeDetector:
    def __init__(self, spike_threshold=2.0, window_size=100):
        self.spike_threshold = spike_threshold
        self.window_size = window_size
        self.loss_history = deque(maxlen=window_size)
    
    def detect_spike(self, current_loss):
        """检测损失尖峰"""
        if len(self.loss_history) < 10:
            self.loss_history.append(current_loss)
            return False
        
        recent_avg = sum(list(self.loss_history)[-10:]) / 10
        
        if current_loss > recent_avg * self.spike_threshold:
            logger.warning(f"Loss spike detected: {current_loss:.4f} vs avg {recent_avg:.4f}")
            return True
        
        self.loss_history.append(current_loss)
        return False
    
    def handle_spike(self, model, optimizer):
        """处理损失尖峰：回滚到之前的检查点"""
        logger.info("Rolling back to previous checkpoint...")
        # 加载最近的稳定检查点
        checkpoint = torch.load("last_stable_checkpoint.pt")
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        # 降低学习率
        for param_group in optimizer.param_groups:
            param_group['lr'] *= 0.5
```

## Scaling Laws

### Chinchilla Law
计算最优的模型大小和数据量关系：

$$N_{\text{optimal}} = G \cdot D^{a}$$
$$D_{\text{optimal}} = G \cdot N^{b}$$

其中 $a \approx b \approx 1$ (Chinchilla 发现)

```python
def chinchilla_optimal_allocation(compute_budget_flops):
    """
    根据 Chinchilla Law 计算最优的模型参数量和训练数据量
    """
    # Chinchilla 常数（基于经验拟合）
    A, B, alpha, beta = 406.4, 410.7, 0.34, 0.28
    
    # 计算最优参数量（十亿参数）
    N_optimal = ((A * compute_budget_flops) / (6 * B)) ** (1 / (alpha + beta))
    
    # 计算最优 token 数量（十亿 token）
    D_optimal = (B * compute_budget_flops) / (6 * A) ** (1 / (alpha + beta))
    
    return N_optimal, D_optimal

# 示例：1e21 FLOPs 的计算预算
N_opt, D_opt = chinchilla_optimal_allocation(1e21)
print(f"最优配置: {N_opt:.1f}B 参数, {D_opt:.1f}B tokens")
```

### Compute-Optimal Training
```python
class ComputeOptimalTrainer:
    def __init__(self, model_params, compute_budget):
        self.model_params = model_params  # 模型参数量
        self.compute_budget = compute_budget  # FLOPs 预算
        
        # 根据 scaling law 确定最优训练 tokens
        self.optimal_tokens = self._compute_optimal_tokens()
    
    def _compute_optimal_tokens(self):
        """根据模型大小计算最优训练数据量"""
        # Chinchilla 比例：20 tokens per parameter
        return self.model_params * 20
    
    def get_training_schedule(self):
        """生成训练计划"""
        tokens_per_step = self.batch_size * self.seq_length
        total_steps = self.optimal_tokens // tokens_per_step
        
        return {
            "total_steps": total_steps,
            "tokens_per_step": tokens_per_step,
            "total_tokens": self.optimal_tokens,
            "compute_utilization": self._estimate_mfu()
        }
```

## 面试常见问题

### Q1: 为什么大多数现代 LLM 选择 Causal LM 而不是 Masked LM？

**答案：**
1. **生成能力**：Causal LM 天然适合文本生成任务，而 MLM 需要额外的解码策略
2. **训练效率**：每个位置都有监督信号，相比 MLM 只有 15% 的位置有损失
3. **工程实现**：因果注意力避免了未来信息泄露，实现更简洁
4. **下游任务适配**：大多数应用场景（对话、写作）都是生成式的

### Q2: 数据去重为什么如此重要？

**答案：**
1. **避免记忆化**：重复数据导致模型过拟合，降低泛化能力
2. **训练效率**：相同样本的重复学习浪费计算资源
3. **数据泄露**：测试集污染问题，影响评估可信度
4. **质量提升**：去重过程中发现和移除低质量内容

### Q3: Scaling Laws 在实践中如何指导模型设计？

**答案：**
1. **资源分配**：确定给定计算预算下的最优模型大小
2. **训练计划**：决定需要多少数据才能充分训练模型
3. **性能预测**：在训练前估计最终模型性能
4. **比较基准**：评估训练是否达到了理论最优

### Q4: 混合精度训练中为什么需要 master weights？

**答案：**
1. **精度保持**：FP16 参数更新可能因精度不足导致无效更新
2. **累积误差**：小的梯度在 FP16 下可能被截断，需要 FP32 累积
3. **训练稳定性**：避免因精度问题导致的训练发散
4. **性能平衡**：FP16 前向传播提速，FP32 参数更新保精度

### Q5: 如何判断预训练数据的质量？

**答案：**
1. **统计特征**：词长分布、句长分布、字符熵等基础指标
2. **语言模型困惑度**：使用训练好的模型评估文本流畅性
3. **内容分类**：毒性检测、主题分类、文体分析
4. **人工评估**：抽样进行人工质量标注，建立质量标准
5. **下游效果**：在代表性任务上测试训练效果

---

相关笔记：[[AI/3-LLM/Architecture/FlashAttention|Transformer Architecture]]、[[AI/3-LLM/SFT/训练数据构建|SFT 训练流程]]、[[AI/3-LLM/Infra/模型并行策略]]、[[AI/3-LLM/RL/GRPO/GRPO 深度理解|RLHF/GRPO]]、[[AI/3-LLM/Pretraining/预训练数据工程|预训练数据工程]] — 本文讲原理，数据工程讲 Dedup/过滤/配比工程实现