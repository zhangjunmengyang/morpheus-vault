---
brief: "ICLR 2026 è¶‹åŠ¿åˆ†æâ€”â€”ä» ICLR 2026 å½•ç”¨è®ºæ–‡çœ‹ 2026 å¹´ AI ç ”ç©¶ä¸»æµæ–¹å‘ï¼›RL for Reasoning/å¤šæ¨¡æ€å¯¹é½/Agent RL/é•¿ä¸Šä¸‹æ–‡/æ¨ç†æ•ˆç‡äº”å¤§çƒ­ç‚¹çš„è®ºæ–‡åˆ†å¸ƒï¼›å¯¹è€æ¿ç ”ç©¶æ–¹å‘é€‰é¢˜çš„æˆ˜ç•¥å‚è€ƒã€‚"
title: "ICLR 2026 è¶‹åŠ¿åˆ†æ"
type: analysis
domain: ai/llm/evaluation
tags:
  - ai/llm/evaluation
  - type/analysis
  - conference/iclr
created: 2026-02-16
---

# ICLR 2026 è¶‹åŠ¿åˆ†æ

> æ¥æºï¼š5357 ç¯‡ accepted papers å…³é”®è¯ç»Ÿè®¡ (Reddit r/LocalLLaMA åˆ†æ)
> æ—¶é—´ï¼š2026 å¹´ 1 æœˆåº• decisions released

## æ ¸å¿ƒæ•°æ®

| æ–¹å‘ | è®ºæ–‡æ•° | è¶‹åŠ¿åˆ¤æ–­ |
|------|--------|----------|
| **Test-time compute** (TTC) | 257 | ğŸ”¥ æœ€å¤§çƒ­ç‚¹ï¼Œå·²ä»å®éªŒèµ°å‘ä¸»æµ |
| **Mamba / SSM** | 202 | æ´»è·ƒï¼Œattention æ›¿ä»£æ–¹æ¡ˆæœªæ­» |
| **GRPO** | 157 | å‹å€’æ€§é¢†å…ˆ DPO |
| **RLVR** | 125 | è¶…è¿‡ RLHFï¼Œverifiable rewards è·¯çº¿èƒœå‡º |
| **Hallucination** | 123 | ä»æœªè§£å†³ï¼Œretrieval grounding æ–¹å‘æ´»è·ƒ |
| **Factuality** | 125 | ä¸ hallucination å¹¶åˆ— |
| **DPO** | 55 | é€€æ½®æ˜æ˜¾ |
| **RLHF** | 54 | è¢« RLVR è¶…è¶Š |

## å…³é”®ä¿¡å·è§£è¯»

### 1. GRPO 157 vs DPO 55 â€” Alignment æ–¹æ³•æ¢ä»£

å­¦æœ¯ç•Œå·²ç»å®Œæˆä» DPO åˆ° GRPO çš„è¿ç§»ï¼ˆ3:1 æ¯”ä¾‹ï¼‰ã€‚åŸå› ï¼š
- GRPO ä¸éœ€è¦ paired preference data
- ä¸ verifiable rewards å¤©ç„¶å…¼å®¹
- DeepSeek-R1 çš„æˆåŠŸæ˜¯å‚¬åŒ–å‰‚

**é¢è¯•æ³¨æ„ï¼š** DPO ä¸å†æ˜¯ SOTA alignment æ–¹æ³•ã€‚è¦èƒ½è®²æ¸…æ¥š GRPO ä¸ºä»€ä¹ˆæ›´å¥½ã€‚

### 2. RLVR 125 vs RLHF 54 â€” Reward èŒƒå¼è½¬ç§»

å¯éªŒè¯ rewardï¼ˆmath/code/logic correctnessï¼‰çš„è·¯çº¿å®Œå…¨å‹è¿‡äº† human preference annotationã€‚æ ¸å¿ƒä¼˜åŠ¿ï¼š
- ä¸éœ€è¦æ˜‚è´µçš„äººå·¥æ ‡æ³¨
- Reward signal æ›´ cleanã€less noisy
- å¯¹ reasoning ä»»åŠ¡æ›´ aligned
- å¯ä»¥åšåˆ° on-policyã€å¤§è§„æ¨¡

### 3. TTC 257 ç¯‡ â€” Test-Time Compute æˆä¸ºæœ€å¤§çƒ­ç‚¹

ä» o1 â†’ R1 â†’ Gemini 3 Deep Thinkï¼Œè¿™æ¡è·¯çº¿åœ¨å·¥ä¸šç•Œå’Œå­¦æœ¯ç•ŒåŒæ—¶ validatedã€‚ç ”ç©¶æ–¹å‘åŒ…æ‹¬ï¼š
- Inference-time scaling laws
- Self-correction / self-verification
- Budget allocation strategies
- ä¸ training-time compute çš„ trade-off

### 4. Mamba/SSM 202 ç¯‡ â€” æ²¡æ­»

å°½ç®¡ Transformer ä»å ä¸»å¯¼ï¼ŒSSM æ–¹å‘ä»æœ‰å¤§é‡ç ”ç©¶ã€‚å¯¹ consumer hardware ä¸Šçš„æ¨ç†æ•ˆç‡æœ‰å®é™…æ„ä¹‰ã€‚

### 5. å€¼å¾—å…³æ³¨çš„å•ç¯‡

**Nait (Neuron-Aware Instruction Tuning):**
- ç”¨ neuron activation patterns é€‰æ‹© 10% Alpaca-GPT4 æ•°æ®
- æ•ˆæœ > 100% å…¨é‡è®­ç»ƒ
- Insight: å¤§éƒ¨åˆ† instruction tuning æ•°æ®æ˜¯å†—ä½™çš„ï¼Œsmart selection >> more data

**MCP Security Bench:**
- Instruction-following èƒ½åŠ›è¶Šå¼ºçš„æ¨¡å‹ï¼Œè¶Šå®¹æ˜“è¢« prompt injection via tool outputs
- "Capability-vulnerability paradox" â€” agent è¶Šå¼ºè¶Šå±é™©

## å¯¹æˆ‘ä»¬çš„å¯ç¤º

1. **RL æ–¹å‘è¦å…¨åŠ›æŠ¼ GRPO + RLVR** â€” è¿™æ˜¯å­¦æœ¯å…±è¯†
2. **TTC æ˜¯å¿…é¡»æŒæ¡çš„æ–¹å‘** â€” é¢è¯•å¿…è€ƒ
3. **æ•°æ®æ•ˆç‡** > æ•°æ®è§„æ¨¡ â€” Nait çš„ insight å€¼å¾—æ·±æŒ–
4. **Agent å®‰å…¨æ˜¯å¼€æ”¾é—®é¢˜** â€” èƒ½åŠ›æ‚–è®ºå€¼å¾—å…³æ³¨

## å…³è”ç¬”è®°

- [[GRPO æ·±åº¦ç†è§£]]
- [[å¯¹é½æŠ€æœ¯ç»¼è¿°]]
- [[RLHF å…¨é“¾è·¯]]
- [[AI/3-LLM/Evaluation/LLM è¯„æµ‹ä½“ç³»]]

---
*Created: 2026-02-16 by Scholar heartbeat*
