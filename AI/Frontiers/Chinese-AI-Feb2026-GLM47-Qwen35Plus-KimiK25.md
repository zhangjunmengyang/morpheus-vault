# 中国 AI 模型全景：2026 年 2 月三巨头评测

**来源**：AI Crucible 双评委评测 + 公开规格
**评级**：★★★★☆
**标签**：#中国AI #GLM-4.7 #Qwen #KimiK2 #MoE #竞品分析
**日期**：2026-02-26

---

## 一、格局判断

**12 个月前**：中国模型 = 「省钱替代品」
**2026 年 2 月**：全三家旗舰在严格双评委基准下追平西方前沿，framing 已死。

这不是某一家的突破，是整个中国 AI 层次的集体跃迁。

---

## 二、三巨头规格对比

| 指标 | GLM-4.7 (Z.AI) | Qwen 3.5 Plus (Alibaba) | Kimi K2.5 (Moonshot AI) |
|------|---------------|------------------------|------------------------|
| Context | 200K tokens | **1M tokens**（最大） | 262K tokens |
| 输入价格 | $0.54/M | **$0.48/M**（最低） | $0.72/M |
| 输出价格 | $2.40/M | $2.88/M | $3.60/M |
| Vision | ✅ | ✅ | ✅ |
| 架构 | MoE（744B/40B） | **MoE（397B/17B）** | 未公开 |
| 优势 | 完整性+结构 | 1M上下文+超低价格 | 创意+工具+可执行性 |

**Qwen 3.5 Plus 亮点**：
- 397B total / 17B active MoE — 效率极高
- 1M context — 业界最长上下文之一
- $0.48/M input — 前沿质量里最便宜的选项

**Kimi K2.5 亮点**：
- Agentic 专家定位（工具调用、多步推理）
- Moonshot AI 在 K2 时代确立的 agentic niche 延续

---

## 三、评测结果（双评委：Gemini 3.1 Pro + Claude Sonnet 4.6）

**任务**：复杂金融规划教育框架（8个维度，竞争精炼策略，2轮）

| 模型 | 综合分 | Gemini 评分 | Claude 评分 |
|------|--------|------------|------------|
| 🥇 GLM-4.7 | **9.0/10** | 9.4 | 8.7 |
| 🥈 Kimi K2.5 | 8.8/10 | 8.9 | 8.74 |
| 🥉 Qwen 3.5 Plus | 8.6/10 | 8.4 | 8.7 |

**关键**：三者差距仅 0.4 分，全部超过 8.5 ——一年前这是 GPT-4 级别的分数。

### 分项表现

| 维度 | GLM-4.7 | Qwen 3.5 Plus | Kimi K2.5 |
|------|---------|--------------|-----------|
| 准确性 | 9.5/8.5 | 8.5/8.5 | 9.0/8.5 |
| 清晰度 | **9.5/9.5** | 9.0/9.0 | 9.0/8.0 |
| 完整性 | **10/9.0**（最高） | 7.0/8.5 | 7.5/9.0 |
| 创意性 | 8.5/7.5 | 9.0/8.5 | **9.5/9.2**（最高）|
| 实用性 | 9.5/9.0 | 8.5/9.0 | **9.5/9.0**（最高）|

（格式：Gemini评分/Claude评分）

---

## 四、各模型能力定位

### GLM-4.7（Z.AI，原智谱）— "最被低估的模型"
- **优势**：完整性和结构化（Completeness 拿了最高分 10/10 from Gemini）
- 典型场景：合规文档、研究报告、教育内容
- GLM-4.7 生成了 2800+ 词的「创始人财务操作系统」框架，一个字没漏
- 设计哲学：**不跳过任何东西**（设计层面的完整性保证）
- Z.AI 更名前 = 智谱 AI，GLM 系列延续

### Kimi K2.5（Moonshot AI）— Agentic 专家
- **优势**：创意框架 + 可执行性（Creativity 9.5/9.2，Usefulness 最高）
- 发明用户没要求的框架（「Operational Load per Dollar / OLD」指标）
- 典型场景：危机剧本、实施日历、税务策略
- 定位明确：产出可以**直接行动**的 output

### Qwen 3.5 Plus（Alibaba）— 1M Token 时代的赌注
- **优势**：超长上下文 + 极低价格 + 创意场景（新 persona 框架）
- Completeness 较低（7.0/8.5）——对完整性要求高的场景需注意
- 战略定位：用 1M context + 超低价格打企业级长文档处理市场

---

## 五、代际对比（2025 Dec → 2026 Feb）

| 指标 | 2025 Dec | 2026 Feb | 变化 |
|------|---------|---------|------|
| 最长 Context | 262K（Qwen3-Max） | **1M**（Qwen 3.5 Plus） | 4× |
| 最高分 | 9.4（Kimi K2 Thinking） | 9.0（GLM-4.7，双评委） | 评测标准提高 |
| 最低输入价 | $0.14/M（DeepSeek） | $0.48/M（Qwen 3.5 Plus） | 旗舰级质量降价 |
| Vision | 2/3 支持 | **3/3** 全覆盖 | 多模态标配 |

**解读**：中国 AI 从「推理 benchmark 导向」转向「通用生产模型」——工具调用、视觉、超长 context 全面铺开，竞争企业工作负载。

---

## 六、技术含义（对 LLM 研究的启示）

1. **MoE 成为主流**：Qwen 3.5 Plus（397B/17B）和 GLM-4.7（744B/40B）都是大 MoE，稀疏激活是效率-质量 Pareto 的关键
2. **Price-Quality Frontier 重组**：$0.48/M 达到接近 frontier 的质量，OpenAI/Anthropic 的溢价空间被压缩
3. **1M Context 竞赛**：RAG 的必要性被进一步质疑——当 context 够大时，直接塞进 prompt 是合理替代
4. **Agentic 分化**：Kimi 主打 Agentic 工具专家，GLM 主打完整性专家，Qwen 主打成本效率专家——三者定位分化

---

## 七、与 Vault 已有内容的关联

- GLM-5 技术报告（arXiv: 2602.15763）→ `AI/Frontiers/GLM-5-技术报告精读.md`（已写）
- GLM-4.7 是 GLM-5 下游的 post-training 产品（744B → 针对特定场景的精炼版）
- Qwen 3.5 Plus MoE 架构与 DeepSeek-V3 的 MoE 设计（Group Expert + Expert-level Load Balance）对比值得深研

---

## 八、我的判断

**GLM-4.7 被低估**的核心原因：Z.AI 营销力弱，不如 Alibaba/ByteDance 声量大，但实际质量 Completeness 全局最高。对需要"不漏一个要点"的 enterprise 任务，GLM-4.7 是最优选择。

**Qwen 3.5 Plus 的 1M ctx** 是战略卡位而非炫技——长 document QA / 代码库理解 / 多轮 agent session 都受益。但当前 Completeness 分数偏低，说明模型在长 prompt 下可能存在注意力分散问题（典型的长 context 困境：窗口长但使用效率不高）。

**Kimi K2.5** 的 Agentic 路线正确，但 262K context 是三者最短——随着 context 竞争升温，这是一个要补的短板。
