---
title: 分布式系统模式
tags: [design-pattern, distributed-systems, microservices, resilience]
date: 2026-02-28
---

# 分布式系统模式

> GoF 是单机代码的设计语言，分布式系统模式是网络时代的设计语言。
> 核心挑战变了：网络会断、机器会挂、延迟不可预测、数据需要一致性。

---

## 一、弹性模式（Resilience Patterns）

### 1. 熔断器（Circuit Breaker）⭐

**问题**：下游服务挂了，你还在不断发请求 → 资源耗尽 → 级联崩溃（雪崩效应）。

````mermaid
flowchart TD
  n1["┌─────────────────────────────┐"]
  n2["│        Circuit Breaker       │"]
  n3["请求  →  [熔断器]  → │  Closed（正常，放行）         │  →  下游服务"]
  n4["│  Open（熔断，直接拒绝）        │"]
  n5["│  Half-Open（探测，少量放行）   │"]
  n6["└─────────────────────────────┘"]
  n7["状态转移："]
  n8["Closed  →（失败率超阈值）→  Open"]
  n9["Open    →（冷却时间到）→  Half-Open"]
  n10["Half-Open →（探测成功）→  Closed"]
  n11["Half-Open →（探测失败）→  Open"]
  n1 --> n2
  n2 --> n3
  n3 --> n4
  n4 --> n5
  n5 --> n6
  n6 --> n7
  n7 --> n8
  n8 --> n9
  n9 --> n10
  n10 --> n11
````

**本质**：主动放弃，保护自己，给下游恢复时间。
**现实类比**：家里保险丝——过载时自动断开，不让整个电路烧掉。

**AI 映射**：
- 模型 API 超时 / 限速 → 熔断，切换到 fallback 模型
- 工具调用失败率过高 → 熔断，返回降级响应
- Agent 下游数据库不可用 → 熔断，用缓存数据临时应对

---

### 2. 重试模式（Retry）

**问题**：网络抖动导致请求偶发失败，但其实重试一下就好了。

````mermaid
flowchart TD
  n1["请求失败"]
  n2["↓"]
  n3["等待 1s  →  重试"]
  n4["↓"]
  n5["等待 2s  →  重试"]
  n6["↓"]
  n7["等待 4s  →  重试（指数退避）"]
  n8["↓"]
  n9["放弃，返回错误"]
  n1 --> n2
  n2 --> n3
  n3 --> n4
  n4 --> n5
  n5 --> n6
  n6 --> n7
  n7 --> n8
  n8 --> n9
````

**关键设计**：
- **固定间隔**：简单，但可能造成惊群（所有客户端同时重试）
- **指数退避（Exponential Backoff）**：每次等待时间翻倍
- **加抖动（Jitter）**：在退避时间上加随机量，避免惊群

**注意**：重试只适合**幂等操作**（重复执行结果相同）。非幂等操作（支付、发消息）不能无脑重试。

**AI 映射**：
- LLM API 调用（限速 429 / 超时）→ 指数退避重试
- 工具调用失败 → 重试 + 错误信息反馈给 Agent 调整策略

---

### 3. 舱壁模式（Bulkhead）

**问题**：一个慢请求占满所有线程/连接，导致其他请求也被饿死。

````mermaid
flowchart TD
  n1["没有舱壁："]
  n2["[服务A请求] × 100  →  占满所有100个线程  →  服务B请求全部等待超时"]
  n3["有舱壁："]
  n4["[线程池A: 60个] → 服务A独享"]
  n5["[线程池B: 40个] → 服务B独享"]
  n6["服务A挂了，服务B不受影响"]
  n1 --> n2
  n2 --> n3
  n3 --> n4
  n4 --> n5
  n5 --> n6
````

**本质**：隔离资源，一个部分的故障不蔓延到其他部分。
**现实类比**：船舱隔板——一个舱进水，不沉整艘船。

**AI 映射**：
- 不同 Agent 使用独立的模型推理资源池
- 高优先级任务（实时响应）和低优先级任务（批处理）用不同线程池隔离

---

### 4. 超时模式（Timeout）

**问题**：下游一直不返回，请求永远挂着——不如主动放弃。

````mermaid
flowchart TD
  n1["请求发出  →  等待  →  [超时阈值]  →  放弃，返回错误"]
  n2["↑"]
  n3["比 P99 延迟稍大（不太短，不太长）"]
  n1 --> n2
  n2 --> n3
````

**关键**：超时值怎么设？太短误判，太长资源浪费。通常设为 P99 延迟的 1.5-2 倍。

**AI 映射**：
- 工具调用��时（搜索、代码执行）
- LLM 推理超时 → 触发 fallback
- 心跳检测（超时视为 Agent 挂掉）

---

## 二、数据模式（Data Patterns）

### 5. 事件溯源（Event Sourcing）⭐

**问题**：传统数据库只存"当前状态"，丢失了所有历史——出了问题无法审计，也无法回滚。

````mermaid
flowchart TD
  n1["传统方式（存状态）："]
  n2["用户余额 = 100"]
  n3["事件溯源（存事件）："]
  n4["事件1：充值 +200"]
  n5["事件2：消费 -50"]
  n6["事件3：消费 -50"]
  n7["当前状态 = 从头重放所有事件 = 100"]
  n8["需要\"3天前的余额\"？从事件1重放到那个时间点即可"]
  n1 --> n2
  n2 --> n3
  n3 --> n4
  n4 --> n5
  n5 --> n6
  n6 --> n7
  n7 --> n8
````

**本质**：存变化（事件），不存结果（状态）；状态 = 事件序列的投影。

**三大好处**：
- **完整审计日志**：每一步都有记录
- **时间旅行**：重放到任意历史时刻
- **事件驱动集成**：其他系统订阅事件，松耦合

**AI 映射**：
- Agent 操作日志（每个 tool call、每个决策都作为事件存储）
- 对话历史 = 事件序列（不只存最终状态，存每一轮交互）
- 可回放对话轨迹，Debug Agent 行为

---

### 6. CQRS（命令查询职责分离）

**问题**：读和写的需求完全不同——写需要强一致，读需要高性能——为什么要用同一个模型？

````mermaid
flowchart TD
  n1["传统：一个模型处理所有读写"]
  n2["┌──────────────┐"]
  n3["│   数据库      │  ←→  所有操作"]
  n4["└──────────────┘"]
  n5["CQRS：读写分离"]
  n6["Command（写） → 写模型（强一致，范式化）"]
  n7["Query（读）   → 读模型（高性能，非范式化，可多个视图）"]
  n8["两个模型通过事件同步（通常结合 Event Sourcing）"]
  n1 --> n2
  n2 --> n3
  n3 --> n4
  n4 --> n5
  n5 --> n6
  n6 --> n7
  n7 --> n8
````

**本质**：读和写用不同的数据模型，各自优化。

**AI 映射**：
- Agent 的写操作（更新记忆、写日志）和读操作（检索上下文）用不同存储
- 向量库（读优化）+ 关系数据库（写优化），CQRS 视角看 RAG 架构

---

### 7. Saga 模式⭐

**问题**：跨多个服务的分布式事务——传统 2PC 太重，微服务不支持。

````mermaid
flowchart TD
  n1["订单流程（跨4个服务）："]
  n2["Step1: 扣库存  → Step2: 扣余额  → Step3: 创建物流  → Step4: 发通知"]
  n3["如果 Step3 失败："]
  n4["补偿事务（逆序）："]
  n5["取消通知 ← 取消物流 ← 退余额 ← 恢复库存"]
  n1 --> n2
  n2 --> n3
  n3 --> n4
  n4 --> n5
````

**两种实现**：
- **编排式（Choreography）**：每个服务完成后发事件，下一个服��订阅事件自行触发（去中心化）
- **指挥式（Orchestration）**：一个 Saga Orchestrator 依次调用各服务（中心化，更好控制）

**AI 映射**：
- 多步骤 Agent 任务的事务管理（任一步失败 → 触发补偿动作回滚）
- 复杂业务流程（订票：选座→锁座→支付→出票，任何步骤失败都要补偿）

---

## 三、服务治理模式（Service Governance）

### 8. API 网关（API Gateway）

**问题**：客户端需要和 N 个微服务打交道——每个服务的地址不同，鉴权各管各的。

````mermaid
flowchart TD
  n1["客户端  →  API 网关  →  服务A"]
  n2["→  服务B"]
  n3["→  服务C"]
  n4["网关统一处理：鉴权、限速、路由、负载均衡、日志、SSL卸载"]
  n1 --> n2
  n2 --> n3
  n3 --> n4
````

**本质**：外观模式（Facade）在网络层的应用。

**AI 映射**：
- LLM API 网关（统一鉴权、限速、模型路由、计费）
- Agent 系统的统一入口（LiteLLM、OpenRouter 的本质就是 API Gateway）

---

### 9. Sidecar 模式

**问题**：每个服务都需要日志收集、健康检测、配置管理……能不能不让业务代码关心这些？

````mermaid
flowchart TD
  n1["[业务容器]  +  [Sidecar 容器]"]
  n2["├─ 日志收集"]
  n3["├─ 健康检测"]
  n4["├─ 服务发现"]
  n5["└─ 流量监控"]
  n6["两者运行在同一个 Pod/主机，共享网络和存储"]
  n7["业务代码零感知"]
  n1 --> n2
  n2 --> n3
  n3 --> n4
  n4 --> n5
  n5 --> n6
  n6 --> n7
````

**本质**：把横切关注点（cross-cutting concerns）移到独立的伴生进程。

**AI 映射**：
- Agent 的 Sidecar：安全过滤器（内容审核）、使用量监控、缓存层
- Memory 模块作为 Agent 的 Sidecar（不改主 Agent 逻辑，独立附加记忆能力）

---

### 10. 服务网格（Service Mesh）

**问题**：微服务多了，服务间通信的治理（重试、熔断、追踪、加密）散落在各业务代码里，维护噩梦。

````mermaid
flowchart TD
  n1["没有服务网格："]
  n2["每个服务自己实现重试/熔断/追踪（重复造轮子）"]
  n3["有服务网格（Istio/Linkerd）："]
  n4["每个服务旁有 Sidecar Proxy（Envoy）"]
  n5["所有流量经过 Proxy"]
  n6["治理逻辑统一在控制平面配置（业务代码完全不感知）"]
  n1 --> n2
  n2 --> n3
  n3 --> n4
  n4 --> n5
  n5 --> n6
````

**本质**：Sidecar 模式的集群化应用——把整个网络治理层抽象出来。

**AI 映射**：
- Multi-Agent 系统的通信治理层（统一配置 Agent 间通信的限速、重试、追踪）
- 未来 Agent 基础设施的演进方向：Agent Mesh

---

### 11. 幂等消费者（Idempotent Consumer）

**问题**：消息队列可能重复投递（at-least-once 语义），消费者收到重复消息可能导致重复操作。

````mermaid
flowchart TD
  n1["消息 ID=\"abc123\""]
  n2["消费者收到消息 → 检查 ID 是否已处理过"]
  n3["├─ 是：直接丢弃（幂等）"]
  n4["└─ 否：处理 + 记录 ID"]
  n5["无论消息投递几次，结果都一样"]
  n1 --> n2
  n2 --> n3
  n3 --> n4
  n4 --> n5
````

**AI 映射**：
- Agent 的工具调用去重（同一个 tool call 不重复执行）
- 事件驱动的 Agent 任务（消息重投 → 不重复触发动作）

---

## 四、消息模式（EIP，企业集成模式 65 种的精华）

### 12. 消息路由器（Message Router）

````mermaid
flowchart TD
  n1["消息  →  路由器  →  根据内容/规则  →  目标A"]
  n2["→  目标B"]
  n3["→  目标C"]
  n1 --> n2
  n2 --> n3
````

**AI 映射**：意图识别后路由到不同 Agent（搜索意图→搜索Agent，写作意图→写作Agent）

---

### 13. 消息过滤器（Message Filter）

````mermaid
flowchart TD
  n1["消息流  →  [过滤器：只通过符合条件的]  →  下游"]
````

**AI 映射**：内容安全过滤（只有通过审核的消息才发给 Agent）

---

### 14. 聚合器（Aggregator）

````mermaid
flowchart TD
  n1["并行请求A结果 ─→"]
  n2["并行请求B结果 ─→  [聚合器：等齐后合并]  →  完整结果"]
  n3["并行请求C结果 ─→"]
  n1 --> n2
  n2 --> n3
````

**AI 映射**：
- 并行多路检索结果聚合
- Fan-out 多个 Agent 并行处理，最后汇总答案（Mixture-of-Agents）

---

### 15. 散播-聚集（Scatter-Gather）

````mermaid
flowchart TD
  n1["请求  →  广播给 N 个候选  →  [聚合器：取最好的]  →  最终结果"]
  n2["（并行执行）"]
  n1 --> n2
````

**AI 映射**：
- 多模型并行采样，取最高置信度的答案（Self-Consistency 的本质）
- 多个搜索引擎并行查询，聚合结果去重

---

## 分布式模式速查

| 类别 | 模式 | 核心问题 |
|---|---|---|
| 弹性 | 熔断器 | 下游故障不级联 |
| 弹性 | 重试+退避 | 瞬时失败自动恢复 |
| 弹性 | 舱壁 | 故障隔离不蔓延 |
| 弹性 | 超时 | 防止无限等待 |
| 数据 | 事件溯源 | 完整历史可回放 |
| 数据 | CQRS | 读写分离各自优化 |
| 数据 | Saga | 分布式事务补偿 |
| 治理 | API 网关 | 统一入口 |
| 治理 | Sidecar | 横切关注点剥离 |
| 治理 | 服务网格 | 集群级通信治理 |
| 消息 | 路由器 | 按规则分发 |
| 消息 | 聚合器 | 并行结果汇聚 |
| 消息 | 散播-聚集 | 并行采样取最优 |
