---
title: 并发与消息模式
tags: [design-pattern, concurrency, messaging, synchronization, stability]
date: 2026-02-28
brief: GoF之外的四类模式：同步原语（互斥锁/读写锁/信号量）/ 并发模式（生产者消费者/扇入扇出/Reactor）/ 消息模式（发布订阅/推拉）/ 稳定性模式（熔断器/重试/舱壁/限流），工程生产环境必备。
---

# 并发与消息模式

> GoF 23 种模式解决的是单机代码的对象协作问题。
> 这一层解决的是：**多线程、网络、分布式场景下的协调与稳定性**。
> 工程师进阶必须掌握——面试考的不少，生产环境用得更多。

---

## 一、同步原语（Synchronization Primitives）

并发的基础积木。多个执行流（线程/协程）访问共享资源时，需要协调。

### 1. 互斥锁（Mutex / Lock）

**问题**：多个线程同时写共享变量，导致数据竞争。

```mermaid
sequenceDiagram
    participant T1 as 线程1
    participant L as 互斥锁
    participant R as 共享资源
    participant T2 as 线程2

    T1->>L: Lock()
    L-->>T1: 获得锁
    T1->>R: 读写操作
    T2->>L: Lock()
    Note over T2,L: 阻塞等待
    T1->>L: Unlock()
    L-->>T2: 获得锁
    T2->>R: 读写操作
    T2->>L: Unlock()
```

**本质**：同一时刻只有一个执行流能进入临界区。
**注意**：锁的粒度要小（只保护必要的代码段），否则并发退化为串行。

---

### 2. 读写锁（Read-Write Lock）

**问题**：读操作远多于写操作，互斥锁让读也串行化——性能浪费。

```mermaid
flowchart TD
    subgraph 读写锁规则
        R1[读锁：多个读者可以同时持有]
        R2[写锁：写者独占，排斥所有读者和写者]
        R3[读写互斥：有写者时不允许读]
    end
    subgraph 场景
        S1[适合：读多写少\n如缓存/配置中心]
        S2[不适合：写频繁\n锁升级开销大]
    end
```

**本质**：读可以并发，写必须独占。大幅提升读密集型场景的吞吐量。
**AI 映射**：Agent 知识库（高频读取/低频更新）用读写锁，避免读操作串行化。

---

### 3. 信号量（Semaphore）

**问题**：需要限制同时访问某资源的并发数量（不是互斥，是限额）。

```mermaid
flowchart LR
    subgraph 信号量 S=3
        S[计数=3]
    end
    T1[线程1] -->|acquire S=2| S
    T2[线程2] -->|acquire S=1| S
    T3[线程3] -->|acquire S=0| S
    T4[线程4] -->|acquire 阻塞等待| S
    T1 -->|release S=1| S
    T4 -->|获得许可| S
```

**本质**：计数器控制并发数，acquire 减 1，release 加 1，为 0 时阻塞。
**vs 互斥锁**：互斥锁是信号量=1的特例；信号量可以允许 N 个并发。
**AI 映射**：
- 限制同时调用 LLM API 的并发数（防止超出速率限制）
- 工具调用的并发控制（如同时最多 5 个搜索请求）

---

### 4. 条件变量（Condition Variable）

**问题**：线程需要等待某个条件满足才能继续，而不是无脑自旋检查（浪费 CPU）。

```mermaid
sequenceDiagram
    participant Consumer as 消费者线程
    participant CV as 条件变量
    participant Producer as 生产者线程

    Consumer->>CV: wait(条件: 队列非空)
    Note over Consumer: 释放锁，挂起等待
    Producer->>CV: 生产数据
    Producer->>CV: notify()
    CV-->>Consumer: 唤醒
    Consumer->>Consumer: 检查条件，继续执行
```

**本质**：等待某个条件成立，被通知时再醒来检查。通常和互斥锁配合使用。
**AI 映射**：等待工具调用返回结果（阻塞等待条件：结果已就绪）。

---

## 二、并发模式（Concurrency Patterns）

### 5. 生产者-消费者（Producer-Consumer）⭐

**问题**：生产速度和消费速度不匹配，需要一个缓冲区解耦。

```mermaid
flowchart LR
    subgraph 生产者
        P1[Producer 1]
        P2[Producer 2]
    end
    subgraph 缓冲队列
        Q[Buffer Queue\n有界/无界]
    end
    subgraph 消费者
        C1[Consumer 1]
        C2[Consumer 2]
        C3[Consumer 3]
    end

    P1 & P2 -->|put| Q
    Q -->|take| C1 & C2 & C3
```

**本质**：队列作为缓冲，解耦生产和消费的速率差异。
**两个关键参数**：
- 队列容量（有界队列避免内存耗尽，无界队列避免生产者阻塞）
- 消费者数量（决定吞吐上限）

**AI 映射**：
- Agent 任务队列（用户请求 → 队列 → Worker Pool 消费）
- LLM 批处理（批量攒请求再一起推理，提升 GPU 利用率）

---

### 6. 扇出-扇入（Fan-Out / Fan-In）

**问题**：一个任务可以拆成多个子任务并行执行，最后汇总结果。

```mermaid
flowchart TD
    Master[主任务] -->|分发| W1[Worker 1]
    Master -->|分发| W2[Worker 2]
    Master -->|分发| W3[Worker 3]
    W1 -->|结果| Agg[聚合器]
    W2 -->|结果| Agg
    W3 -->|结果| Agg
    Agg --> Final[最终结果]
```

**Fan-Out**：一个任务拆成多个并行执行。
**Fan-In**：多个结果汇总成一个。
**AI 映射**：
- 并行检索多个数据源（同时查 3 个向量库），结果合并重排序（Fan-Out + Fan-In）
- Mixture of Agents（MoA）：多个 LLM 并行生成 → 聚合器选最优

---

### 7. Reactor 模式

**问题**：服务器需要同时处理大量并发连接，每个连接一个线程的方式代价太高。

```mermaid
flowchart TD
    subgraph Reactor 核心
        EM[Event Loop\n事件循环] -->|监听| MUX[I/O 多路复用\nselect/epoll]
        MUX -->|事件就绪| EM
    end
    subgraph 事件处理
        EM -->|可读| H1[Handler: 读取数据]
        EM -->|可写| H2[Handler: 发送响应]
        EM -->|连接| H3[Handler: Accept连接]
    end
    C1[客户端1] & C2[客户端2] & C3[客户端N] -->|网络连接| MUX
```

**本质**：单线程 + 事件循环 + 非阻塞 I/O = 支撑数万并发连接。
**现实映射**：Node.js / Nginx / Redis 底层都是 Reactor 模式。
**AI 映射**：高并发推理服务（vLLM/TGI 的并发请求处理）的核心架构。

---

### 8. 有界并行（Bounded Parallelism）

**问题**：并行执行 N 个任务，但不能无限制并发（防止资源耗尽）。

```mermaid
flowchart LR
    Tasks[100个任务] --> Pool[工作池\n固定大小=5]
    Pool -->|最多5个同时| W1[Worker]
    Pool -->|最多5个同时| W2[Worker]
    Pool -->|最多5个同时| W3[Worker]
    Pool -->|最多5个同时| W4[Worker]
    Pool -->|最多5个同时| W5[Worker]
    W1 & W2 & W3 & W4 & W5 -->|完成后取下一个| Pool
```

**本质**：Goroutine/Thread Pool + Semaphore 的组合，控制并发上限。
**AI 映射**：并行工具调用的并发控制（同时最多 5 个外部 API 请求）。

---

## 三、消息传递模式（Messaging Patterns）

### 9. 发布-订阅（Pub/Sub）⭐

**问题**：消息发送方不想知道谁在接收，接收方不想知道谁在发送——完全解耦。

```mermaid
flowchart LR
    P1[Publisher A] -->|publish| MB[消息总线\nEvent Bus]
    P2[Publisher B] -->|publish| MB
    MB -->|subscribe| S1[Subscriber 1]
    MB -->|subscribe| S2[Subscriber 2]
    MB -->|subscribe| S3[Subscriber 3]
```

**vs 观察者**：
- 观察者：Subject 直接持有 Observer 列表，仍有耦合
- 发布订阅：中间有消息总线，Publisher 和 Subscriber 完全不知道对方存在

**AI 映射**：
- 军团公告板（bulletin.md）本质是 Pub/Sub：贾维斯发布任务，任何 Agent 订阅并认领
- 事件驱动 AI 系统（工具调用完成 → 发布事件 → 多个下游 Agent 响应）

---

### 10. 推-拉模式（Push / Pull）

**问题**：数据更新通知的两种基本策略。

```mermaid
flowchart TD
    subgraph Push 推模式
        S1[Server] -->|主动推送数据| C1[Client]
        note1[优点：实时性高\n缺点：客户端可能来不及消费]
    end
    subgraph Pull 拉模式
        C2[Client] -->|定期轮询请求| S2[Server]
        S2 -->|返回数据| C2
        note2[优点：客户端控制消费节奏\n缺点：有延迟，浪费请求]
    end
```

**组合策略（Long Poll / WebSocket）**：
- Long Poll：客户端发请求，服务器有数据时才返回（介于推拉之间）
- WebSocket：建立双向通道，真正实时双向推送

**AI 映射**：
- LLM 流式输出（SSE）= Push 模式——服务器逐 token 推给客户端
- 心跳检查（馆长心跳）= Pull 模式——定期轮询触发

---

### 11. 扇入（Fan-In）消息聚合

**问题**：多个来源的消息需要合并到一个通道处理。

```mermaid
flowchart LR
    CH1[Channel 1] --> FI[Fan-In\n聚合器]
    CH2[Channel 2] --> FI
    CH3[Channel 3] --> FI
    FI --> OUT[统一输出通道]
```

**AI 映射**：多个 Agent 并行产出结果 → 汇总到 Orchestrator 统一处理（与 Fan-Out 搭配形成 Scatter-Gather 模式）。

---

## 四、稳定性模式（Stability Patterns）

生产环境存活的保障。下游不可靠时，自己不能跟着挂掉。

### 12. 熔断器（Circuit Breaker）⭐

```mermaid
stateDiagram-v2
    [*] --> Closed
    Closed --> Open: 失败率超阈值
    Open --> HalfOpen: 冷却时间到
    HalfOpen --> Closed: 探测请求成功
    HalfOpen --> Open: 探测请求失败

    Closed: Closed 正常放行
    Open: Open 直接拒绝\n不打下游
    HalfOpen: Half-Open 少量探测
```

**本质**：主动放弃，保护自己，给下游恢复时间。现实类比：保险丝。
**AI 映射**：
- LLM API 限速/超时 → 熔断，切换 fallback 模型
- 工具调用失败率过高 → 熔断，返回降级响应

---

### 13. 重试（Retry）

```mermaid
flowchart TD
    REQ[发请求] -->|成功| OK[✅]
    REQ -->|失败| W1[等待 1s]
    W1 --> R1[重试1]
    R1 -->|成功| OK
    R1 -->|失败| W2[等待 2s\n指数退避]
    W2 --> R2[重试2]
    R2 -->|失败| W3[等待 4s + 随机抖动]
    W3 --> R3[重试3]
    R3 -->|失败| FAIL[❌ 放弃]
```

**三个关键设计**：
- **指数退避**：每次等待时间翻倍，避免持续冲击
- **抖动（Jitter）**：加随机偏移，避免所有客户端同时重试（惊群效应）
- **幂等前提**：只有幂等操作才能重试（查询✅ / 支付❌）

**AI 映射**：LLM API 调用的 429 / 超时 → 指数退避重试。

---

### 14. 舱壁（Bulkhead）

```mermaid
flowchart LR
    subgraph 没有舱壁
        A100[服务A 100并发] -->|占满| P1[线程池 100]
        B[服务B请求] -->|全部阻塞| P1
    end
    subgraph 有舱壁
        A50[服务A 50并发] --> PA[线程池A 50]
        B50[服务B 50并发] --> PB[线程池B 50]
        Note[A挂了不影响B]
    end
```

**本质**：像船舱隔板，一个舱漏水不影响其他舱。通过资源隔离防止级联故障。
**AI 映射**：
- 高优先级请求（付费用户）和低优先级请求（免费用户）用不同线程池
- 不同工具的调用使用独立连接池，一个工具挂了不影响其他工具

---

### 15. 限流（Rate Limiting）

```mermaid
flowchart LR
    subgraph 令牌桶算法
        TB[令牌桶\n固定速率填充]
        R1[请求1] -->|取令牌| TB
        R2[请求2] -->|取令牌| TB
        R3[请求3] -->|桶空，拒绝| TB
    end
    subgraph 滑动窗口算法
        SW[时间窗口\n统计请求数]
        note[超过阈值的请求排队或拒绝]
    end
```

**两种主流算法**：
- **令牌桶**：固定速率生成令牌，请求消耗令牌，允许突发（桶满时可存），长期平均速率受限
- **滑动窗口**：统计最近 N 秒的请求数，超过阈值拒绝，更精确

**AI 映射**：
- LLM API 调用限速（每分钟最多 60 次请求）
- 多租户系统的用户级限流（每个用户每天 1000 次调用）

---

### 16. 快速失败（Fail Fast）

**问题**：与其让错误的请求慢慢超时消耗资源，不如早发现早拒绝。

```mermaid
flowchart LR
    REQ[请求] --> V{前置验证}
    V -->|参数非法| E1[❌ 立即返回错误\n不进入处理流程]
    V -->|资源不可用| E2[❌ 立即返回错误\n不排队等待]
    V -->|验证通过| PROC[正常处理]
```

**本质**：尽早发现问题，比在系统深处发现要好得多。
**AI 映射**：
- 工具调用参数校验（LLM 生成的参数格式错误 → 立即返回错误 + 错误信息反馈给 LLM 修正）
- Context 长度超限 → 立即截断而非等到推理失败

---

## 四类模式关系图

```mermaid
flowchart TD
    subgraph 同步原语 基础层
        M[互斥锁] & RW[读写锁] & SEM[信号量] & CV[条件变量]
    end
    subgraph 并发模式 构建于同步原语之上
        PC[生产者消费者] & FO[扇出扇入] & BP[有界并行] & RC[Reactor]
    end
    subgraph 消息模式 解耦与通信
        PS[发布订阅] & PP[推拉模式] & FI[扇入聚合]
    end
    subgraph 稳定性模式 生产环境保障
        CB[熔断器] & RT[重试] & BH[舱壁] & RL[限流] & FF[快速失败]
    end
    同步原语 --> 并发模式
    并发模式 --> 消息模式
    消息模式 & 并发模式 --> 稳定性模式
```

---

## 生产环境最低配置

> 任何对外的 LLM/Tool 调用，至少需要：

```mermaid
flowchart LR
    REQ[请求] --> FF[快速失败\n前置校验]
    FF --> RL[限流\n令牌桶]
    RL --> CB[熔断器\n保护下游]
    CB -->|Closed| CALL[实际调用]
    CALL -->|成功| OK[✅]
    CALL -->|失败| RT[重试\n指数退避]
    RT -->|超次数| FALLBACK[降级响应]
    CB -->|Open| FALLBACK
```

**缺了哪个都是生产事故的根源。**

## See Also
- [[05-分布式系统模式]] — 更高层的分布式模式（Saga/CQRS/事件溯源）
- [[03-行为型模式-GoF]] — 观察者 vs 发布订阅的深度对比
- [[04-架构模式与AI协作]] — AI 系统的架构级模式
- [[00-设计模式总览MOC]] — 全局导览
