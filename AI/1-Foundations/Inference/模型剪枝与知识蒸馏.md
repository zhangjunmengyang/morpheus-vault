---
brief: "模型剪枝与知识蒸馏——结构化剪枝（注意力头/FFN层）vs 非结构化剪枝；知识蒸馏的 Soft Label/Feature-Level/Contrastive 三种方式；LLM 场景的蒸馏特殊挑战（生成式 vs 判别式）；模型压缩的工程选型矩阵。"
title: "模型剪枝与知识蒸馏"
date: 2026-02-14
tags: [inference, pruning, distillation, compression, interview]
type: note
---

> [!info] 📖 版本说明
> 本篇为**面试速查版**（简洁直接）。深度工程版：[[知识蒸馏与模型压缩-2026技术全景|知识蒸馏与模型压缩 2026 全景]]

# 模型剪枝与知识蒸馏

## 1. 模型压缩全景

大模型推理成本高、延迟大，模型压缩是将大模型"瘦身"的关键技术族。四大主流方法：

```
                    模型压缩
           ┌──────┬──────┬──────┐
           │      │      │      │
         量化   剪枝   蒸馏  低秩分解
     (Quant) (Prune) (Distill) (LoRA等)

方法对比：
┌──────────┬────────────────┬──────────┬──────────┐
│ 方法     │ 核心思想       │ 压缩比   │ 精度损失 │
├──────────┼────────────────┼──────────┼──────────┤
│ 量化     │ 降低权重精度   │ 2-4x     │ 小       │
│ 剪枝     │ 移除不重要的权重│ 2-10x    │ 中       │
│ 蒸馏     │ 用大模型教小模型│ 10-100x  │ 中-大    │
│ 低秩分解 │ 矩阵近似分解   │ 2-4x     │ 小       │
└──────────┴────────────────┴──────────┴──────────┘
```

**关系与组合：**
- 量化和剪枝**直接作用于同一个模型**，可以叠加使用
- 蒸馏**产出一个新的小模型**，与原模型架构可以不同
- 实际生产中常见组合：先蒸馏得到小模型，再对小模型做量化
- 低秩分解常用于训练阶段（LoRA），推理阶段用于压缩全连接层

---

## 2. 结构化剪枝 vs 非结构化剪枝

### 2.1 非结构化剪枝（Unstructured Pruning）

**原理：** 将模型权重矩阵中"不重要"的单个权重置零。

```
原始权重矩阵：          剪枝后（50% 稀疏度）：
[0.3  0.01 0.5]         [0.3  0    0.5]
[0.02 0.8  0.1]    →    [0    0.8  0.1]
[0.7  0.03 0.04]        [0.7  0    0   ]
```

**判断"不重要"的标准：**
- **Magnitude Pruning**：绝对值最小的权重最不重要（最经典）
- **Movement Pruning**：训练过程中变化最小的权重最不重要
- **基于梯度的方法**：梯度小的权重对 loss 影响小

**优点：**
- 理论压缩比高（可达 90%+ 稀疏度）
- 精度保持较好（大量研究表明 50-80% 的权重可以被剪掉而不显著影响精度）

**缺点：**
- **硬件不友好**：产生的稀疏矩阵不规则，标准 GPU 无法加速，需要专用稀疏计算库（如 NVIDIA 的 2:4 稀疏格式）
- 实际推理加速有限，除非硬件原生支持稀疏计算

### 2.2 结构化剪枝（Structured Pruning）

**原理：** 移除整个结构单元（整个 attention head、整个 FFN 神经元、整个 layer）。

```
原始 Transformer：              结构化剪枝后：
┌─────────────────┐            ┌─────────────────┐
│ Attention (12头) │            │ Attention (8头)  │  ← 移除 4 个 head
├─────────────────┤            ├─────────────────┤
│ FFN (3072维)     │            │ FFN (2048维)     │  ← 移除 1024 个神经元
├─────────────────┤            ├─────────────────┤
│ Layer 1-12       │            │ Layer 1-10       │  ← 移除 2 个 layer
└─────────────────┘            └─────────────────┘
```

**优点：**
- **硬件友好**：剪枝后模型仍是稠密的，标准 GPU 直接加速
- 实际推理速度提升与压缩比成正比
- 无需特殊硬件或软件支持

**缺点：**
- 压缩比受限（移除整个结构单元的粒度太粗）
- 相同压缩比下精度损失比非结构化剪枝大
- 需要微调（fine-tune）恢复精度

### 2.3 半结构化剪枝（Semi-structured / N:M Sparsity）

NVIDIA Ampere 架构引入的 **2:4 稀疏格式**：每 4 个连续权重中最多保留 2 个非零值。

```
原始：[0.3  0.01  0.5  0.02]  →  2:4 稀疏：[0.3  0  0.5  0]
```

- 硬件原生支持，Tensor Core 可加速 ~2x
- 50% 固定稀疏度，精度损失可控
- 是目前实际部署中最实用的稀疏方案

---

## 3. LLM 剪枝方法

### 3.1 SparseGPT（2023）

**核心思想：** 将剪枝问题转化为逐层的最优权重更新问题。

```
目标：min ||WX - W'X||²  （剪枝后输出尽量接近原输出）
W: 原始权重, W': 剪枝后权重, X: 该层输入

方法：
1. 逐列处理权重矩阵
2. 对每列，选择要剪掉的权重
3. 用 Hessian 逆矩阵的近似来更新剩余权重，补偿被剪掉权重的影响
```

**关键特点：**
- **单次剪枝（One-shot）**：不需要重训练/微调，只需少量校准数据（~128 样本）
- 基于二阶信息（Hessian）做补偿更新，精度保持优秀
- 可将 GPT-175B 剪到 50-60% 稀疏度，perplexity 几乎无损
- 计算效率高，175B 模型在单台 A100 上几小时内完成

### 3.2 Wanda（2024）

**核心思想：** 用权重幅度 × 输入激活幅度作为重要性指标，比 SparseGPT 更简单高效。

```
重要性分数 = |W_ij| × ||X_j||₂

W_ij: 权重值
X_j: 对应输入特征的 L2 范数
```

**关键特点：**
- **极简方法**：不需要 Hessian 计算，不需要权重更新
- 核心洞察：仅看权重大小不够，还要看该权重连接的输入特征有多"活跃"
- 效果接近 SparseGPT，但速度快一个数量级
- 特别适合 N:M 半结构化稀疏

### 3.3 LLM-Pruner（2023）

**核心思想：** 针对 LLM 的结构化剪枝框架。

```
流程：
1. 依赖分析：找出 LLM 中的耦合结构（哪些参数必须一起保留/移除）
2. 重要性估计：用一阶（梯度）+ 二阶（Hessian）信息评估每组结构的重要性
3. 结构移除：移除最不重要的结构组
4. 快速恢复：用 LoRA 做少量微调恢复精度（比全参微调便宜得多）
```

**关键特点：**
- 任务无关（task-agnostic），剪枝后的模型保持通用能力
- 20% 参数移除后，配合 LoRA 微调可以恢复大部分性能
- 真正实现推理加速（结构化剪枝的优势）

---

## 4. 知识蒸馏基础

### 4.1 Teacher-Student 框架

```
                  ┌─────────────┐
  输入 ──────────→│ Teacher 模型 │──→ Soft Labels (概率分布)
       │          │ (大模型)     │         │
       │          └─────────────┘         │
       │                                   │ KL 散度损失
       │                                   ↓
       │          ┌─────────────┐    ┌──────────┐
       └─────────→│ Student 模型 │──→│ 训练损失  │
                  │ (小模型)     │    │ L = αL_CE │
                  └─────────────┘    │  + βL_KD  │
                                     └──────────┘
```

**核心直觉：** Teacher 的 soft label（概率分布）比 hard label（one-hot）包含更多信息。

例如，图片分类中：
- Hard label: [猫=1, 狗=0, 鸟=0]
- Soft label: [猫=0.7, 狗=0.25, 鸟=0.05]

Soft label 告诉 Student："这张图主要像猫，但也有点像狗"——这种"暗知识"（dark knowledge）是蒸馏的精髓。

### 4.2 Temperature Scaling

```python
# 标准 softmax
softmax(z_i) = exp(z_i) / Σ exp(z_j)

# 带温度的 softmax
softmax(z_i / T) = exp(z_i / T) / Σ exp(z_j / T)

# T=1: 正常分布
# T>1: 分布更平滑，暴露更多类间关系（蒸馏常用 T=2~20）
# T→∞: 均匀分布
```

温度越高，soft label 越"软"，Student 能学到更多类间的相对关系。

### 4.3 KL 散度损失

```
L_KD = KL(P_teacher(T) || P_student(T))
     = Σ P_teacher * log(P_teacher / P_student)

总损失：
L = α * L_CE(y_true, P_student(T=1)) + β * L_KD(P_teacher(T), P_student(T))

α + β = 1, 通常 β 较大（如 0.7-0.9），因为 teacher 的知识是主要学习信号
```

---

## 5. LLM 蒸馏实践

### 5.1 输出蒸馏（最常见）

**原理：** 用 Teacher（大模型）的输出作为训练数据，微调 Student（小模型）。

```
典型流程：
1. 准备 instruction 数据集（如 52K 条指令）
2. 用 GPT-4 / Claude 生成高质量回答
3. 用这些 (instruction, response) 对微调小模型（如 LLaMA-7B）
4. 得到能力接近 Teacher 的小模型

代表工作：
- Alpaca：52K 条 GPT-3.5 生成的数据 → 微调 LLaMA-7B
- Vicuna：70K 条 ShareGPT 对话数据 → 微调 LLaMA-13B
- Orca：用 GPT-4 的 CoT 推理过程作为训练数据，显著提升小模型推理能力
```

**关键技巧：**
- **数据质量 > 数据数量**：1K 条高质量数据可能比 100K 条低质量数据效果好
- **蒸馏推理过程（CoT）**，不仅蒸馏最终答案——Orca 的核心贡献
- **多样性**：覆盖足够多的任务类型和难度级别

### 5.2 特征蒸馏

**原理：** 不仅学输出分布，还对齐 Teacher 和 Student 的中间层表示。

```
Teacher:  Layer1 → Layer2 → ... → Layer12 → Output
             ↓        ↓              ↓
          [映射层]  [映射层]      [映射层]    ← 维度对齐
             ↓        ↓              ↓
Student:  Layer1 → Layer2 → ... → Layer6  → Output

损失 = L_output + λ * Σ ||f_teacher(i) - g(f_student(j))||²

g(): 映射层（因为 Teacher 和 Student 的隐藏维度通常不同）
```

**优点：** 比纯输出蒸馏学到更丰富的中间表示
**缺点：** 需要 Teacher 和 Student 同时加载，显存要求高；层对齐策略需要调参

### 5.3 在线蒸馏 vs 离线蒸馏

```
离线蒸馏（Offline Distillation）：
1. 先用 Teacher 生成所有样本的 soft label 并保存
2. 再用保存的 soft label 训练 Student
✅ Teacher 只需跑一次，计算效率高
✅ 可以用闭源 API（GPT-4）作为 Teacher
❌ 无法根据 Student 的学习状态动态调整教学

在线蒸馏（Online Distillation）：
1. Teacher 和 Student 同时运行
2. 每个 batch，实时计算 Teacher 的输出作为 Student 的学习目标
✅ Teacher 可以根据 Student 的弱点动态调整
✅ 还可以做自蒸馏（Self-Distillation）：模型蒸馏自身
❌ 计算开销大，需要同时加载两个模型
```

对于 LLM 场景，**离线蒸馏是主流**（因为 Teacher 通常是闭源 API，无法同时加载）。

---

## 6. DeepSeek-R1 的蒸馏启示

DeepSeek-R1 展示了一个重要范式：**从大推理模型蒸馏到小模型，可以保留推理能力。**

### 6.1 背景

```
DeepSeek-R1（671B MoE）
  │
  │ 蒸馏
  ↓
DeepSeek-R1-Distill-Qwen-32B   ← 效果接近 GPT-4o
DeepSeek-R1-Distill-Qwen-14B   ← 效果接近原版 R1 在部分任务
DeepSeek-R1-Distill-Qwen-7B    ← 手机可跑，仍具备较强推理能力
DeepSeek-R1-Distill-Qwen-1.5B  ← 极致压缩
```

### 6.2 关键发现

1. **推理过程可蒸馏**：大模型的 Chain-of-Thought 推理模式可以被小模型学会，这超出了很多人的预期
2. **蒸馏 > 直接 RL**：直接对小模型做 RL 训练推理能力，效果不如从大模型蒸馏。说明大模型在 RL 过程中学到的"推理模式"是有结构的、可传递的
3. **蒸馏数据的关键**：使用 R1 生成的包含完整推理链的数据（而非仅最终答案）进行 SFT
4. **模型底座很重要**：Qwen2.5 系列作为底座，本身有较好的语言能力，蒸馏效果好于较弱的底座

### 6.3 启示

```
实践指导：
1. 蒸馏推理链（CoT），不仅仅蒸馏答案
2. 选择好的 Student 底座（预训练质量很重要）
3. 蒸馏 + SFT 结合，先蒸馏再做任务特定微调
4. 蒸馏可以跨模型族（R1 是 MoE，Student 是 Dense）
```

---

## 7. 与量化的组合使用

### 7.1 剪枝 + 量化

```
组合流程（推荐顺序）：
原始模型 → 剪枝（移除冗余参数）→ 微调恢复 → 量化（降低精度）→ 部署

为什么这个顺序：
- 先剪枝减少参数量，再量化降低每个参数的 bit 数
- 压缩比可以叠加：剪枝 2x × 量化 4x = 8x
- 先量化再剪枝也可以，但剪枝时的重要性评估会受量化噪声干扰
```

### 7.2 蒸馏 + 量化

```
组合流程：
Teacher (大模型) → 蒸馏 → Student (小模型) → 量化 → 部署

更进阶：量化感知蒸馏（Quantization-Aware Distillation）
- 训练时 Student 就模拟量化噪声
- 蒸馏和量化同时优化，最终效果更好
```

### 7.3 实际部署组合示例

```
场景：将 LLaMA-70B 部署到单卡 A100（80GB）

方案 A：纯量化
  LLaMA-70B + GPTQ-4bit = ~35GB ✅ 单卡可放

方案 B：蒸馏 + 量化
  LLaMA-70B → 蒸馏到 LLaMA-8B → AWQ-4bit = ~4GB
  效果损失更多，但推理速度快 5-8x，可在消费级 GPU 运行

方案 C：结构化剪枝 + 量化
  LLaMA-70B → LLM-Pruner 移除 30% 结构 → LoRA 恢复 → GPTQ-4bit = ~20GB
  保留了原模型架构的大部分能力，单卡轻松放下
```

---

## 8. 面试常见问题及回答要点

### Q1: 结构化剪枝和非结构化剪枝的核心区别是什么？实际部署选哪个？

**回答要点：**
非结构化剪枝移除单个权重，产生不规则稀疏矩阵，理论压缩比高但标准硬件无法加速；结构化剪枝移除整个计算单元（head/neuron/layer），剪枝后仍是稠密模型，GPU 直接加速。

实际部署推荐：
- 如果目标硬件支持 N:M 稀疏（如 NVIDIA A100+），用 **2:4 半结构化剪枝**，是目前最佳平衡点
- 如果目标是标准 GPU 不做特殊适配，用 **结构化剪枝 + LoRA 微调恢复**
- 非结构化剪枝主要用于研究和特殊硬件场景

### Q2: SparseGPT 和 Wanda 的区别？

**回答要点：**
两者都是 LLM 的 one-shot 剪枝方法（不需重训练），核心区别：
- **SparseGPT** 用二阶信息（Hessian 逆）做补偿更新，剪掉一个权重后更新剩余权重来最小化输出偏差。精度好但计算量较大
- **Wanda** 只用一阶信息（权重大小 × 输入激活大小）做重要性评估，不做补偿更新。简单快速，效果接近 SparseGPT

选择：如果对精度要求极高选 SparseGPT，如果要快速迭代选 Wanda。

### Q3: 知识蒸馏中 temperature 的作用？怎么选？

**回答要点：**
Temperature 控制 softmax 输出分布的"软硬程度"。T 越高分布越平滑，暴露更多类间关系（dark knowledge）。

选择策略：
- T=1 时 soft label 退化为 hard label，没有蒸馏效果
- T=2~5 适合大多数任务
- T=10~20 适合类别很多、类间关系复杂的场景
- 实践中通常做超参搜索，T 和损失权重 α/β 一起调

注意：Teacher 和 Student 在计算 KD loss 时必须使用**相同的 T**，但 Student 最终推理时用 T=1。

### Q4: LLM 蒸馏和传统蒸馏有什么不同？

**回答要点：**
传统蒸馏（如 BERT 时代）通常是白盒蒸馏——Teacher 和 Student 同时加载，对齐 logits 和中间层。

LLM 蒸馏的特殊性：
1. **Teacher 通常是黑盒**（GPT-4 API），只能拿到输出文本，拿不到 logits 和中间层表示
2. 因此 LLM 蒸馏主要是**输出蒸馏**：用 Teacher 生成高质量数据，对 Student 做 SFT
3. 蒸馏推理链（CoT）比蒸馏最终答案重要得多（Orca、DeepSeek-R1 的启示）
4. 数据质量和多样性是 LLM 蒸馏成功的关键，而非损失函数设计

### Q5: DeepSeek-R1 蒸馏到小模型的核心经验是什么？对实践有什么指导？

**回答要点：**
核心发现：推理能力是可蒸馏的，且蒸馏效果优于直接对小模型做 RL。

三个关键经验：
1. **蒸馏完整推理链**：不只是 (问题, 答案)，而是 (问题, 思考过程, 答案)。小模型通过模仿大模型的思考模式习得推理能力
2. **底座选择很重要**：同样蒸馏 R1 的数据，Qwen2.5-32B 作底座效果远好于较弱的底座。Student 需要有足够的"学习能力"
3. **蒸馏可跨架构**：R1 是 671B MoE，Student 是 Dense 架构，说明推理模式的知识是架构无关的

实践指导：如果你需要部署一个有推理能力的小模型，与其从零 RL 训练，不如找最好的大推理模型生成蒸馏数据，然后 SFT 到好的小模型底座上。

---

## See Also

- [[知识蒸馏与模型压缩-2026技术全景|知识蒸馏 2026 全景]] — 深度版：ICLR 2026 最新蒸馏方法全景
- [[模型量化综述|模型量化综述]] — 与剪枝/蒸馏并列的压缩方法
- [[AI/1-Foundations/Training/Scaling Laws|Scaling Laws]] — 为什么大模型蒸馏到小模型有效
- [[AI/1-Foundations/目录|Foundations MOC]] — 推理优化基础全图谱
