---
brief: "PEFT æ–¹æ³•å¯¹æ¯”â€”â€”LoRA/Prefix Tuning/Prompt Tuning/Adapter å››å¤§æµæ´¾çš„åŸç†ã€æ˜¾å­˜å ç”¨ã€æ€§èƒ½å’Œé€‚ç”¨åœºæ™¯å®Œæ•´å¯¹æ¯”è¡¨ï¼›é¢è¯•è¢«é—®å‚æ•°é«˜æ•ˆå¾®è°ƒé€‰å‹æ—¶çš„æ ‡å‡†å‚è€ƒï¼Œç›´æ¥ç»™å‡ºå†³ç­–çŸ©é˜µã€‚"
title: "PEFT æ–¹æ³•å¯¹æ¯”ï¼šLoRA / Prefix / Prompt / Adapter"
date: 2026-02-14
domain: AI/LLM/SFT
tags: [LLM, PEFT, LoRA, Fine-tuning, Efficiency, Parameter-Efficient]
rating: 4
status: active
---

# PEFT æ–¹æ³•å¯¹æ¯”

å‚æ•°é«˜æ•ˆå¾®è°ƒï¼ˆParameter-Efficient Fine-Tuning, PEFTï¼‰æ˜¯åœ¨ä¸ä¿®æ”¹å¤§éƒ¨åˆ†é¢„è®­ç»ƒå‚æ•°çš„æƒ…å†µä¸‹ï¼Œé€šè¿‡å°‘é‡å¯è®­ç»ƒå‚æ•°å®ç°æ¨¡å‹é€‚é…çš„æŠ€æœ¯ã€‚æœ¬æ–‡å¯¹æ¯”ä¸»æµ PEFT æ–¹æ³•çš„åŸç†ã€å®ç°å’Œåº”ç”¨åœºæ™¯ã€‚

## LoRA åŸç†ä¸å®ç°

### æ ¸å¿ƒæ€æƒ³
LoRAï¼ˆLow-Rank Adaptationï¼‰åŸºäºä½ç§©åˆ†è§£çš„æ€æƒ³ï¼Œè®¤ä¸ºå¾®è°ƒè¿‡ç¨‹ä¸­çš„æƒé‡å˜åŒ–çŸ©é˜µå…·æœ‰ä½ç§©ç‰¹æ€§ï¼š

$$W = W_0 + \Delta W = W_0 + BA$$

å…¶ä¸­ $B \in \mathbb{R}^{d \times r}$ï¼Œ$A \in \mathbb{R}^{r \times k}$ï¼Œ$r \ll \min(d,k)$

```python
import torch
import torch.nn as nn

class LoRALayer(nn.Module):
    def __init__(self, in_features, out_features, rank=16, alpha=32, dropout=0.1):
        super().__init__()
        self.rank = rank
        self.alpha = alpha
        self.scale = alpha / rank
        
        # åŸå§‹æƒé‡ï¼ˆå†»ç»“ï¼‰
        self.weight = nn.Parameter(torch.randn(out_features, in_features), requires_grad=False)
        
        # LoRA çŸ©é˜µ
        self.lora_A = nn.Parameter(torch.randn(rank, in_features))
        self.lora_B = nn.Parameter(torch.zeros(out_features, rank))
        
        self.dropout = nn.Dropout(dropout)
        
        # åˆå§‹åŒ–
        nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))
        nn.init.zeros_(self.lora_B)
    
    def forward(self, x):
        # åŸå§‹å‰å‘ä¼ æ’­
        result = F.linear(x, self.weight)
        
        # LoRA åˆ†æ”¯
        lora_result = F.linear(F.linear(self.dropout(x), self.lora_A), self.lora_B)
        
        return result + lora_result * self.scale

# å®é™…åº”ç”¨ç¤ºä¾‹
class LoRALinear(nn.Module):
    def __init__(self, base_layer, rank=16, alpha=32):
        super().__init__()
        self.base_layer = base_layer
        self.base_layer.weight.requires_grad = False  # å†»ç»“åŸå§‹æƒé‡
        
        in_features = base_layer.in_features
        out_features = base_layer.out_features
        
        self.lora_A = nn.Parameter(torch.randn(rank, in_features) / math.sqrt(rank))
        self.lora_B = nn.Parameter(torch.zeros(out_features, rank))
        self.scaling = alpha / rank
    
    def forward(self, x):
        base_output = self.base_layer(x)
        lora_output = (x @ self.lora_A.T @ self.lora_B.T) * self.scaling
        return base_output + lora_output
```

### LoRA è®­ç»ƒæµç¨‹
```python
def convert_to_lora(model, target_modules, rank=16):
    """å°†æŒ‡å®šæ¨¡å—è½¬æ¢ä¸º LoRA"""
    for name, module in model.named_modules():
        if any(target in name for target in target_modules):
            if isinstance(module, nn.Linear):
                parent = model
                for part in name.split('.')[:-1]:
                    parent = getattr(parent, part)
                
                lora_layer = LoRALinear(module, rank=rank)
                setattr(parent, name.split('.')[-1], lora_layer)
    
    return model

# ä½¿ç”¨ç¤ºä¾‹
model = AutoModel.from_pretrained("llama-7b")
model = convert_to_lora(model, target_modules=["q_proj", "v_proj"], rank=16)

# åªè®­ç»ƒ LoRA å‚æ•°
lora_params = [p for n, p in model.named_parameters() if "lora" in n]
optimizer = AdamW(lora_params, lr=1e-4)
```

## QLoRAï¼šé‡åŒ– + LoRA

### åŸç†
QLoRA ç»“åˆ 4-bit é‡åŒ–å’Œ LoRAï¼Œå®ç°æè‡´çš„å†…å­˜æ•ˆç‡ï¼š

```python
import bitsandbytes as bnb
from transformers import BitsAndBytesConfig

# QLoRA é…ç½®
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,                      # 4-bit é‡åŒ–
    bnb_4bit_quant_type="nf4",             # NormalFloat 4-bit
    bnb_4bit_compute_dtype=torch.float16,   # è®¡ç®—æ•°æ®ç±»å‹
    bnb_4bit_use_double_quant=True,        # åŒé‡é‡åŒ–
)

# åŠ è½½é‡åŒ–æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    "meta-llama/Llama-2-7b-hf",
    quantization_config=bnb_config,
    device_map="auto"
)

# åº”ç”¨ LoRA
from peft import LoraConfig, get_peft_model

lora_config = LoraConfig(
    r=64,                    # rank
    lora_alpha=128,         # scaling factor
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
    lora_dropout=0.1,
    bias="none",
    task_type="CAUSAL_LM"
)

model = get_peft_model(model, lora_config)
```

### å†…å­˜ä¼˜åŒ–æŠ€å·§
```python
class QLoRAOptimizedTrainer:
    def __init__(self, model, tokenizer):
        self.model = model
        self.tokenizer = tokenizer
        
        # å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
        self.model.gradient_checkpointing_enable()
        
        # ä¼˜åŒ–å™¨çŠ¶æ€å¸è½½
        self.optimizer = bnb.optim.PagedAdamW32bit(
            self.model.parameters(), 
            lr=1e-4
        )
    
    def train_step(self, batch):
        # æ··åˆç²¾åº¦è®­ç»ƒ
        with torch.cuda.amp.autocast():
            outputs = self.model(**batch)
            loss = outputs.loss
        
        # æ¢¯åº¦ç¼©æ”¾
        self.scaler.scale(loss).backward()
        
        # æ¢¯åº¦è£å‰ªï¼ˆåœ¨ LoRA å‚æ•°ä¸Šï¼‰
        lora_params = [p for p in self.model.parameters() if p.requires_grad]
        self.scaler.unscale_(self.optimizer)
        torch.nn.utils.clip_grad_norm_(lora_params, max_norm=1.0)
        
        self.scaler.step(self.optimizer)
        self.scaler.update()
        
        return loss.item()
```

## DoRAï¼šæƒé‡åˆ†è§£

### æ ¸å¿ƒæ”¹è¿›
DoRAï¼ˆWeight-Decomposed Low-Rank Adaptationï¼‰å°†æƒé‡åˆ†è§£ä¸ºå¤§å°ï¼ˆmagnitudeï¼‰å’Œæ–¹å‘ï¼ˆdirectionï¼‰ï¼š

$$W = W_0 + \Delta W = m \frac{W_0 + BA}{||W_0 + BA||_c}$$

```python
class DoRALayer(nn.Module):
    def __init__(self, base_layer, rank=16, alpha=32):
        super().__init__()
        self.base_layer = base_layer
        self.rank = rank
        self.alpha = alpha
        
        # å†»ç»“åŸå§‹æƒé‡
        self.base_layer.weight.requires_grad = False
        
        # LoRA çŸ©é˜µ
        d, k = base_layer.weight.shape
        self.lora_A = nn.Parameter(torch.randn(rank, k))
        self.lora_B = nn.Parameter(torch.zeros(d, rank))
        
        # magnitude å‘é‡
        self.magnitude = nn.Parameter(torch.ones(d))
        
        # é¢„è®¡ç®—åŸå§‹æƒé‡çš„åˆ—å‘é‡èŒƒæ•°
        with torch.no_grad():
            self.register_buffer('base_weight_norm', 
                               torch.norm(base_layer.weight, dim=1, keepdim=True))
    
    def forward(self, x):
        # è®¡ç®—æƒé‡çŸ©é˜µ
        base_weight = self.base_layer.weight
        lora_weight = self.lora_B @ self.lora_A * (self.alpha / self.rank)
        
        # ç»„åˆæƒé‡
        combined_weight = base_weight + lora_weight
        
        # å½’ä¸€åŒ–æ–¹å‘
        weight_norm = torch.norm(combined_weight, dim=1, keepdim=True)
        normalized_weight = combined_weight / (weight_norm + 1e-8)
        
        # åº”ç”¨ magnitude
        final_weight = self.magnitude.unsqueeze(1) * normalized_weight
        
        return F.linear(x, final_weight, self.base_layer.bias)
```

## Adapter ç³»åˆ—æ–¹æ³•

### Adapter Layers
åœ¨ Transformer å±‚ä¸­æ’å…¥å°çš„é€‚é…å™¨æ¨¡å—ï¼š

```python
class AdapterLayer(nn.Module):
    def __init__(self, hidden_size, adapter_size=64):
        super().__init__()
        self.down_proj = nn.Linear(hidden_size, adapter_size)
        self.up_proj = nn.Linear(adapter_size, hidden_size)
        self.activation = nn.ReLU()
        self.dropout = nn.Dropout(0.1)
        
        # åˆå§‹åŒ–æ¥è¿‘æ’ç­‰æ˜ å°„
        nn.init.zeros_(self.down_proj.weight)
        nn.init.zeros_(self.up_proj.weight)
        nn.init.zeros_(self.up_proj.bias)
    
    def forward(self, x):
        # æ®‹å·®è¿æ¥ç¡®ä¿é€‚é…å™¨å…³é—­æ—¶ä¸ºæ’ç­‰æ˜ å°„
        adapter_output = self.up_proj(
            self.dropout(self.activation(self.down_proj(x)))
        )
        return x + adapter_output

# é›†æˆåˆ° Transformer å±‚
class TransformerWithAdapter(nn.Module):
    def __init__(self, base_transformer, adapter_size=64):
        super().__init__()
        self.base_transformer = base_transformer
        
        # å†»ç»“åŸå§‹å‚æ•°
        for param in self.base_transformer.parameters():
            param.requires_grad = False
        
        # åœ¨æ¯ä¸€å±‚åæ·»åŠ  Adapter
        self.adapters = nn.ModuleList([
            AdapterLayer(base_transformer.config.hidden_size, adapter_size)
            for _ in range(base_transformer.config.num_hidden_layers)
        ])
    
    def forward(self, x):
        for i, layer in enumerate(self.base_transformer.layers):
            x = layer(x)
            x = self.adapters[i](x)  # Adapter å¤„ç†
        return x
```

### Prefix-Tuning
åœ¨è¾“å…¥åºåˆ—å‰æ·»åŠ å¯è®­ç»ƒçš„ prefixï¼š

```python
class PrefixTuningModel(nn.Module):
    def __init__(self, base_model, prefix_length=20, prefix_dim=768):
        super().__init__()
        self.base_model = base_model
        self.prefix_length = prefix_length
        
        # å†»ç»“åŸºç¡€æ¨¡å‹
        for param in base_model.parameters():
            param.requires_grad = False
        
        # å¯è®­ç»ƒçš„ prefix å‚æ•°
        self.prefix_tokens = nn.Parameter(
            torch.randn(prefix_length, prefix_dim) * 0.02
        )
        
        # prefix æŠ•å½±å±‚ï¼ˆæ˜ å°„åˆ°é”®å€¼ç©ºé—´ï¼‰
        self.prefix_projection = nn.Sequential(
            nn.Linear(prefix_dim, 2 * base_model.config.num_attention_heads * 
                     base_model.config.hidden_size // base_model.config.num_attention_heads),
            nn.Tanh(),
            nn.Linear(2 * base_model.config.num_attention_heads * 
                     base_model.config.hidden_size // base_model.config.num_attention_heads,
                     2 * base_model.config.hidden_size)
        )
    
    def get_prefix_key_values(self, batch_size):
        """ç”Ÿæˆå‰ç¼€çš„é”®å€¼å¯¹"""
        prefix_tokens = self.prefix_tokens.unsqueeze(0).expand(batch_size, -1, -1)
        key_values = self.prefix_projection(prefix_tokens)
        
        # é‡ç»„ä¸ºé”®å€¼å¯¹æ ¼å¼
        key_values = key_values.view(
            batch_size, self.prefix_length, 2, 
            self.base_model.config.num_attention_heads, -1
        )
        
        return key_values.split(1, dim=2)
    
    def forward(self, input_ids, attention_mask=None):
        batch_size = input_ids.size(0)
        
        # è·å– prefix é”®å€¼å¯¹
        prefix_keys, prefix_values = self.get_prefix_key_values(batch_size)
        
        # æ‰©å±•æ³¨æ„åŠ›æ©ç 
        prefix_attention_mask = torch.ones(
            batch_size, self.prefix_length, 
            device=input_ids.device, dtype=attention_mask.dtype
        )
        extended_attention_mask = torch.cat([prefix_attention_mask, attention_mask], dim=1)
        
        # å‰å‘ä¼ æ’­ï¼ˆéœ€è¦ä¿®æ”¹æ¨¡å‹æ¥å—å¤–éƒ¨é”®å€¼å¯¹ï¼‰
        return self.base_model(
            input_ids=input_ids,
            attention_mask=extended_attention_mask,
            prefix_key_values=(prefix_keys, prefix_values)
        )
```

### P-Tuning v2
è¿ç»­æç¤ºçš„æ”¹è¿›ç‰ˆæœ¬ï¼Œæ›´åŠ é«˜æ•ˆï¼š

```python
class PTuningV2(nn.Module):
    def __init__(self, base_model, num_virtual_tokens=20):
        super().__init__()
        self.base_model = base_model
        self.num_virtual_tokens = num_virtual_tokens
        
        # è™šæ‹Ÿ token åµŒå…¥
        self.virtual_token_embeddings = nn.Embedding(
            num_virtual_tokens, 
            base_model.config.hidden_size
        )
        
        # æ·±åº¦æç¤ºè°ƒä¼˜ï¼šæ¯å±‚éƒ½æœ‰ç‹¬ç«‹çš„è™šæ‹Ÿ token
        self.deep_prompt_embeddings = nn.Parameter(
            torch.randn(
                base_model.config.num_hidden_layers,
                num_virtual_tokens,
                base_model.config.hidden_size
            ) * 0.02
        )
    
    def forward(self, input_ids, **kwargs):
        batch_size, seq_len = input_ids.shape
        
        # è·å–åŸå§‹è¾“å…¥åµŒå…¥
        inputs_embeds = self.base_model.get_input_embeddings()(input_ids)
        
        # æ·»åŠ è™šæ‹Ÿ token
        virtual_embeds = self.virtual_token_embeddings.weight.unsqueeze(0).expand(
            batch_size, -1, -1
        )
        
        # æ‹¼æ¥è¾“å…¥
        full_embeds = torch.cat([virtual_embeds, inputs_embeds], dim=1)
        
        # ä¿®æ”¹æ³¨æ„åŠ›æ©ç 
        virtual_attention_mask = torch.ones(
            batch_size, self.num_virtual_tokens,
            device=input_ids.device
        )
        full_attention_mask = torch.cat([
            virtual_attention_mask, 
            kwargs.get('attention_mask', torch.ones_like(input_ids))
        ], dim=1)
        
        return self.base_model(
            inputs_embeds=full_embeds,
            attention_mask=full_attention_mask
        )
```

## æ–¹æ³•å¯¹æ¯”åˆ†æ

### å‚æ•°é‡ä¸æ˜¾å­˜å¯¹æ¯”

| æ–¹æ³• | å¯è®­ç»ƒå‚æ•° | æ˜¾å­˜å ç”¨ | æ¨ç†å¼€é”€ | è®­ç»ƒç¨³å®šæ€§ |
|------|------------|----------|----------|------------|
| **Full Fine-tuning** | 100% | é«˜ | æ—  | é«˜ |
| **LoRA** | 0.1-1% | ä½ | æä½ | é«˜ |
| **QLoRA** | 0.1-1% | æä½ | æä½ | ä¸­ç­‰ |
| **DoRA** | 0.1-1% + æƒé‡ç»´åº¦ | ä½ | ä½ | é«˜ |
| **Adapter** | 1-3% | ä¸­ç­‰ | ä¸­ç­‰ | é«˜ |
| **Prefix-Tuning** | 0.01-0.1% | ä½ | ä½ | ä¸­ç­‰ |
| **P-Tuning v2** | 0.01-0.1% | ä½ | ä½ | ä¸­ç­‰ |

### æ€§èƒ½å¯¹æ¯”ä»£ç 
```python
def compare_peft_methods():
    """å¯¹æ¯”ä¸åŒ PEFT æ–¹æ³•çš„æ•ˆæœ"""
    base_model = "meta-llama/Llama-2-7b-hf"
    dataset = "alpaca"
    
    results = {}
    
    # LoRA å®éªŒ
    lora_config = LoraConfig(r=16, alpha=32, target_modules=["q_proj", "v_proj"])
    lora_results = train_and_evaluate(base_model, lora_config, dataset)
    results["LoRA"] = lora_results
    
    # QLoRA å®éªŒ
    qlora_config = LoraConfig(r=64, alpha=128, target_modules=["q_proj", "v_proj"])
    qlora_results = train_and_evaluate(base_model, qlora_config, dataset, use_quantization=True)
    results["QLoRA"] = qlora_results
    
    # Adapter å®éªŒ
    adapter_config = AdapterConfig(adapter_size=64)
    adapter_results = train_and_evaluate_adapter(base_model, adapter_config, dataset)
    results["Adapter"] = adapter_results
    
    return results

# é€‰å‹æŒ‡å—
class PEFTSelector:
    @staticmethod
    def recommend_method(
        model_size_gb: float,
        available_memory_gb: float, 
        target_performance: str,
        inference_latency_critical: bool
    ):
        """æ ¹æ®çº¦æŸæ¡ä»¶æ¨è PEFT æ–¹æ³•"""
        
        if available_memory_gb < model_size_gb * 0.3:
            if target_performance == "high":
                return "QLoRA", "æä½å†…å­˜ï¼Œå¯æ¥å—çš„æ€§èƒ½æŸå¤±"
            else:
                return "Prefix-Tuning", "æœ€ä½å†…å­˜å ç”¨"
        
        elif available_memory_gb < model_size_gb * 0.6:
            if inference_latency_critical:
                return "LoRA", "å¹³è¡¡å†…å­˜å’Œæ¨ç†é€Ÿåº¦"
            else:
                return "DoRA", "æ›´å¥½çš„æ€§èƒ½è¡¨ç°"
        
        else:
            if target_performance == "highest":
                return "Adapter", "æœ€é«˜æ€§èƒ½ï¼Œå¯æ¥å—æ¨ç†å¼€é”€"
            else:
                return "LoRA", "é€šç”¨æœ€ä½³é€‰æ‹©"

# ä½¿ç”¨ç¤ºä¾‹
selector = PEFTSelector()
method, reason = selector.recommend_method(
    model_size_gb=13.0,     # 13B æ¨¡å‹
    available_memory_gb=24.0, # 24GB æ˜¾å­˜
    target_performance="high",
    inference_latency_critical=True
)
print(f"æ¨èæ–¹æ³•: {method}, ç†ç”±: {reason}")
```

## é¢è¯•å¸¸è§é—®é¢˜

### Q1: LoRA ä¸ºä»€ä¹ˆæœ‰æ•ˆï¼Ÿç†è®ºåŸºç¡€æ˜¯ä»€ä¹ˆï¼Ÿ

**ç­”æ¡ˆï¼š**
1. **ä½ç§©å‡è®¾**ï¼šå¾®è°ƒè¿‡ç¨‹ä¸­æƒé‡å˜åŒ–çŸ©é˜µé€šå¸¸å…·æœ‰ä½ç§©ç‰¹æ€§ï¼ŒLoRA åˆ©ç”¨è¿™ä¸€å…ˆéªŒ
2. **å†…åœ¨ç»´åº¦ç†è®º**ï¼šç¥ç»ç½‘ç»œçš„æœ‰æ•ˆå‚æ•°ç©ºé—´ç»´åº¦è¿œä½äºå®é™…å‚æ•°æ•°é‡
3. **é¢„è®­ç»ƒçŸ¥è¯†ä¿æŒ**ï¼šå†»ç»“åŸå§‹æƒé‡ä¿æŒé¢„è®­ç»ƒçŸ¥è¯†ï¼Œåªå­¦ä¹ ä»»åŠ¡ç‰¹å®šçš„é€‚åº”
4. **å®éªŒè¯æ®**ï¼šåœ¨å¤šä¸ªä»»åŠ¡ä¸Šå±•ç°å‡ºæ¥è¿‘å…¨é‡å¾®è°ƒçš„æ€§èƒ½

### Q2: QLoRA çš„åŒé‡é‡åŒ–ï¼ˆdouble quantizationï¼‰æ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ

**ç­”æ¡ˆï¼š**
1. **ç¬¬ä¸€å±‚é‡åŒ–**ï¼šå°† FP16 æƒé‡é‡åŒ–ä¸º 4-bit NormalFloat
2. **ç¬¬äºŒå±‚é‡åŒ–**ï¼šå°†é‡åŒ–å¸¸æ•°ï¼ˆquantization constantsï¼‰ä» FP32 é‡åŒ–ä¸º 8-bit
3. **å†…å­˜èŠ‚çœ**ï¼šæ¯ä¸ªå‚æ•°ä» 16-bit é™åˆ° 4.25-bitï¼ˆ4-bit + 0.25-bit å¸¸æ•°ï¼‰
4. **ç²¾åº¦ä¿æŒ**ï¼šNF4 æ•°æ®ç±»å‹ä¸“é—¨ä¸ºæ­£æ€åˆ†å¸ƒæƒé‡è®¾è®¡ï¼Œå‡å°‘é‡åŒ–è¯¯å·®

### Q3: ä»€ä¹ˆæƒ…å†µä¸‹åº”è¯¥é€‰æ‹© DoRA è€Œä¸æ˜¯ LoRAï¼Ÿ

**ç­”æ¡ˆï¼š**
1. **æ€§èƒ½è¦æ±‚é«˜**ï¼šDoRA åœ¨å¤šæ•°ä»»åŠ¡ä¸Šä¼˜äº LoRAï¼Œç‰¹åˆ«æ˜¯éœ€è¦æ”¹å˜æƒé‡å¤§å°çš„ä»»åŠ¡
2. **æƒé‡åˆ†æé‡è¦**ï¼šéœ€è¦åˆ†ææƒé‡å˜åŒ–çš„æ–¹å‘å’Œå¤§å°æ—¶
3. **å¯æ¥å—é¢å¤–å¼€é”€**ï¼šDoRA éœ€è¦é¢å¤–çš„ magnitude å‚æ•°å’ŒèŒƒæ•°è®¡ç®—
4. **å…·ä½“ä»»åŠ¡**ï¼šæ•°å­¦æ¨ç†ã€ä»£ç ç”Ÿæˆç­‰éœ€è¦ç²¾ç¡®æƒé‡è°ƒæ•´çš„ä»»åŠ¡

### Q4: Prefix-Tuning å’Œ P-Tuning v2 çš„ä¸»è¦åŒºåˆ«ï¼Ÿ

**ç­”æ¡ˆï¼š**
1. **ä½œç”¨ä½ç½®**ï¼šPrefix-Tuning åªåœ¨è¾“å…¥å±‚ï¼ŒP-Tuning v2 åœ¨æ¯ä¸€å±‚éƒ½æœ‰æç¤º
2. **å‚æ•°æ•°é‡**ï¼šP-Tuning v2 å‚æ•°æ›´å¤šä½†æ•ˆæœæ›´å¥½
3. **ä»»åŠ¡é€‚åº”æ€§**ï¼šP-Tuning v2 å¯¹ç†è§£ç±»ä»»åŠ¡æ•ˆæœæ›´ä½³
4. **å®ç°å¤æ‚åº¦**ï¼šPrefix-Tuning å®ç°æ›´ç®€å•ï¼ŒP-Tuning v2 éœ€è¦ä¿®æ”¹æ¯å±‚å‰å‘ä¼ æ’­

### Q5: å¦‚ä½•ä¸ºæ–°ä»»åŠ¡é€‰æ‹©åˆé€‚çš„ PEFT æ–¹æ³•ï¼Ÿ

**ç­”æ¡ˆï¼š**
1. **èµ„æºçº¦æŸ**ï¼š
   - æ˜¾å­˜ç´§å¼ ï¼šQLoRA > LoRA > Adapter
   - æ¨ç†é€Ÿåº¦æ•æ„Ÿï¼šLoRA > DoRA > Adapter
2. **ä»»åŠ¡ç±»å‹**ï¼š
   - ç”Ÿæˆä»»åŠ¡ï¼šLoRAã€DoRA
   - ç†è§£ä»»åŠ¡ï¼šP-Tuning v2ã€Prefix-Tuning
   - å¤šä»»åŠ¡å­¦ä¹ ï¼šAdapter
3. **æ€§èƒ½è¦æ±‚**ï¼š
   - æœ€é«˜æ€§èƒ½ï¼šDoRA > LoRA > Adapter
   - å¹³è¡¡é€‰æ‹©ï¼šLoRAï¼ˆé€šç”¨æ€§æœ€ä½³ï¼‰
4. **å®éªŒéªŒè¯**ï¼šåœ¨éªŒè¯é›†ä¸Šå¯¹æ¯”ä¸åŒæ–¹æ³•çš„æ•ˆæœ

---

---

## See Also

- [[AI/LLM/SFT/LoRA|LoRAï¼ˆä½ç§©é€‚åº”ï¼‰]] â€” PEFTå®¶æ—æ ¸å¿ƒæˆå‘˜ï¼Œæœ¬æ–‡å¯¹æ¯”çš„åŸºå‡†æ–¹æ³•ï¼›LoRAçš„ranké€‰æ‹©ç›´æ¥å†³å®šå‚æ•°æ•ˆç‡ä¸è¡¨è¾¾èƒ½åŠ›çš„æŠ˜ä¸­
- [[AI/LLM/SFT/EWC-LoRA-Continual-Learning-Low-Rank|EWC-LoRAï¼ˆæŒç»­å­¦ä¹ LoRAï¼‰]] â€” LoRAåœ¨æŒç»­å­¦ä¹ åœºæ™¯çš„æ‰©å±•ï¼šFisher informationæ­£åˆ™åŒ–å…‹æœç¾éš¾æ€§é—å¿˜ï¼Œæ˜¯PEFTæ–¹æ³•åœ¨multi-taskåœºæ™¯ä¸‹çš„å‰æ²¿æ¼”åŒ–æ–¹å‘
- [[AI/LLM/SFT/LLMå¾®è°ƒå®æˆ˜-2026æŠ€æœ¯å…¨æ™¯|LLMå¾®è°ƒå®æˆ˜2026å…¨æ™¯]] â­ â€” PEFTæ–¹æ³•çš„å·¥ç¨‹è½åœ°æŒ‡å—ï¼›å“ªä¸ªåœºæ™¯ç”¨LoRAã€QLoRAã€DoRAï¼Œæœ¬æ–‡ç†è®º + å¾®è°ƒå®æˆ˜æä¾›å®è·µé…æ–¹
- [[AI/LLM/Inference/Progressive-Thought-Encoding-Cache-Efficient-RL|PTEï¼ˆæ¸è¿›å¼æ€ç»´ç¼–ç ï¼‰]] â€” PEFTæ€æƒ³å‘æ¨ç†é˜¶æ®µçš„è¿ç§»ï¼šPTEåœ¨KV cacheè¢«å‹ç¼©æ—¶ç”¨LoRA Î”Wåœ¨çº¿è’¸é¦ä¿å­˜evicted tokenï¼Œæœ¬è´¨æ˜¯LoRAä½œä¸º"è®°å¿†å‹ç¼©å™¨"çš„åˆ›æ–°ç”¨æ³•
- [[AI/LLM/SFT/Post-Training Unified View è®ºæ–‡|Post-Training ç»Ÿä¸€è§†è§’]] â€” PEFTæ˜¯post-trainingå·¥ç¨‹çš„æ ¸å¿ƒå·¥å…·ï¼›ç»Ÿä¸€è§†è§’è®ºæ–‡æä¾›äº†SFT/RLHF/DPOåœ¨PEFTæ¡†æ¶ä¸‹çš„ç³»ç»Ÿæ€§ç†è§£

> ğŸ“ **ç‰ˆæœ¬è¯´æ˜**ï¼š`AI/LLM/SFT/PEFT-æ–¹æ³•ç»¼è¿°.md` ä¸ºæ—©æœŸç®€åŒ–ç‰ˆï¼ˆ343è¡Œï¼Œdeprecatedï¼‰ï¼Œæœ¬æ–‡ä¸ºå®Œæ•´æ­£å¼ç‰ˆï¼ˆ530è¡Œï¼‰ã€‚