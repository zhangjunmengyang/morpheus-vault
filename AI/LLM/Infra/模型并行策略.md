---
title: "模型并行策略：从 DP 到 5D 并行"
date: 2026-02-13
tags:
  - ai/llm/training
  - ai/distributed
  - ai/infrastructure
  - type/concept
  - interview/hot
status: active
---

# 模型并行策略：从 DP 到 5D 并行

> 大模型训练的核心工程挑战——如何把一个万亿参数的模型分布到数千张 GPU 上高效训练

## 1. 为什么需要并行？

以 LLaMA 3 405B 为例：
- 参数量：405B × 2 bytes (BF16) ≈ **810 GB**（仅权重）
- 优化器状态（Adam）：405B × 12 bytes ≈ **4.86 TB**
- 单张 H100 显存：80 GB

→ 单卡根本放不下，必须跨卡/跨节点分布。

## 2. 数据并行（Data Parallelism, DP）

### 原理

```
最朴素的并行：每张 GPU 持有完整模型副本，各自处理不同 mini-batch

GPU 0: Model copy → forward(batch_0) → backward → grad_0 ─┐
GPU 1: Model copy → forward(batch_1) → backward → grad_1 ─┤── AllReduce → 更新
GPU 2: Model copy → forward(batch_2) → backward → grad_2 ─┤
GPU 3: Model copy → forward(batch_3) → backward → grad_3 ─┘
```

### 通信开销

```
AllReduce 通信量 = 2 × model_size × (N-1)/N ≈ 2 × model_size
```

- 通信与参数量成正比，与数据量无关
- 适用于**模型能放入单卡**的场景

### PyTorch DDP 示例

```python
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP

# 初始化
dist.init_process_group(backend="nccl")
model = MyModel().to(local_rank)
model = DDP(model, device_ids=[local_rank])

# 训练循环——与单卡代码几乎一致
for batch in dataloader:
    loss = model(batch)
    loss.backward()  # DDP 自动在 backward 中 overlap AllReduce
    optimizer.step()
```

**局限**：每张卡都存完整模型 + 优化器状态 → 显存浪费严重。

## 3. ZeRO（Zero Redundancy Optimizer）

DeepSpeed 团队提出（Rajbhandari et al., 2020），**消除数据并行中的冗余存储**：

```
                      每卡显存占用（以 7.5B 模型为例）
                      ──────────────────────────────
方式            参数(W)   梯度(G)   优化器状态(OS)   总计
────────────────────────────────────────────────────
DDP             15GB     15GB      60GB           ~90GB
ZeRO Stage 1   15GB     15GB      60/N GB        ↓
ZeRO Stage 2   15GB     15/N GB   60/N GB        ↓↓
ZeRO Stage 3   15/N GB  15/N GB   60/N GB        ~90/N GB
────────────────────────────────────────────────────
N = GPU 数量
```

### 三阶段策略

```
ZeRO-1: 分片优化器状态（OS）
  → 每张 GPU 只存 1/N 的 optimizer state
  → forward/backward 不变，只在 step 时通信

ZeRO-2: 分片优化器状态 + 梯度（OS + G）
  → 梯度 Reduce-Scatter 后只保留本片段
  → 通信量与 DDP 相同

ZeRO-3 (FSDP): 分片所有（OS + G + W）
  → forward 前 AllGather 收集参数，用完立即释放
  → backward 时再 AllGather，计算梯度后 Reduce-Scatter
  → 通信量 = 3 × model_size（比 DDP 多 50%）
```

### PyTorch FSDP 示例

```python
from torch.distributed.fsdp import FullyShardedDataParallel as FSDP
from torch.distributed.fsdp import ShardingStrategy

model = MyLLM()
model = FSDP(
    model,
    sharding_strategy=ShardingStrategy.FULL_SHARD,  # ZeRO-3
    mixed_precision=MixedPrecision(
        param_dtype=torch.bfloat16,
        reduce_dtype=torch.float32,
    ),
    auto_wrap_policy=transformer_auto_wrap_policy,
)
```

## 4. 张量并行（Tensor Parallelism, TP）

Megatron-LM（Shoeybi et al., 2020）提出——**将单个层的矩阵运算切分到多张 GPU**。

### MLP 层的列切分/行切分

```
原始 MLP: Y = GeLU(XA) · B

TP 切分（2 卡为例）:
  A = [A₁ | A₂]  (列切分)
  B = [B₁]        (行切分)
      [B₂]

GPU 0: Y₁ = GeLU(X·A₁) · B₁
GPU 1: Y₂ = GeLU(X·A₂) · B₂

Y = AllReduce(Y₁ + Y₂)
```

### Self-Attention 的切分

```
多头注意力天然适合 TP——按 head 切分

GPU 0: heads 0-15  → Q₀K₀V₀ → Attention₀ → O₀ ─┐
GPU 1: heads 16-31 → Q₁K₁V₁ → Attention₁ → O₁ ─┤── AllReduce
```

### 通信开销

```
每个 Transformer Layer 需要:
  Forward:  2 次 AllReduce（MLP + Attention）
  Backward: 2 次 AllReduce

通信量 = O(batch_size × seq_len × hidden_dim)

关键：TP 的通信发生在层内（latency-sensitive），
     需要高带宽互联（NVLink > 600 GB/s）
     → TP 通常限制在单节点内（8卡）
```

## 5. 流水线并行（Pipeline Parallelism, PP）

**将模型按层分段，每段放在不同 GPU 上**：

```
Stage 0 (GPU 0): Layers 0-7
Stage 1 (GPU 1): Layers 8-15
Stage 2 (GPU 2): Layers 16-23
Stage 3 (GPU 3): Layers 24-31
```

### 朴素实现的问题——Bubble

```
朴素流水线：大量 GPU 空闲时间（bubble）

时间 →  t1    t2    t3    t4    t5    t6    t7    t8
GPU 0:  [F0]  [F1]  [F2]  [F3]  idle  idle  idle  [B3][B2][B1][B0]
GPU 1:  idle  [F0]  [F1]  [F2]  [F3]  idle  idle  idle ...
GPU 2:  idle  idle  [F0]  [F1]  [F2]  [F3]  idle  idle ...
GPU 3:  idle  idle  idle  [F0]  [F1]  [F2]  [F3]  [B3]...

Bubble ratio = (P-1) / (M+P-1)，P=stages, M=micro-batches
```

### 调度优化

```
1F1B (One Forward One Backward):
  → 稳态阶段交替执行 F 和 B，减少 bubble
  → 显存更友好（及时释放激活值）

Interleaved 1F1B:
  → 每个 GPU 持有多个非连续 stage
  → 进一步减少 bubble，但增加通信

Zero Bubble PP (ZB-PP, 2024):
  → 将 backward 拆为 B（计算输入梯度）和 W（计算权重梯度）
  → 通过重排 F/B/W 实现几乎零 bubble
```

### 通信开销

```
相邻 Stage 间: 点对点通信 (P2P Send/Recv)
通信量 = O(batch_size × seq_len × hidden_dim) per micro-batch
优势：通信量与模型大小无关，只与激活值大小有关
     → 适合跨节点（IB 网络即可）
```

## 6. 序列并行（Sequence Parallelism, SP）

### Megatron SP

解决 TP 中 **LayerNorm / Dropout 的激活值冗余**：

```
标准 TP: LayerNorm 和 Dropout 在每张卡上都对完整序列执行
  → 这些 op 的激活值没有被切分，造成冗余

Megatron SP: 在非 TP 区域沿序列维度切分
  → AllReduce 替换为 ReduceScatter + AllGather
  → 激活值内存减少到 1/TP_size
```

### Context Parallelism (CP)

Ring Attention 思想——**将超长序列切分到多张 GPU**：

```
序列长度 128K，4 卡 CP:
GPU 0: tokens 0-32K
GPU 1: tokens 32K-64K
GPU 2: tokens 64K-96K
GPU 3: tokens 96K-128K

通过 Ring 通信传递 KV，每卡计算完整 Attention
→ 解决 KV Cache 和激活值的显存瓶颈
```

## 7. 4D/5D 并行：工业实践

LLaMA 3 405B 训练使用 **16K H100 GPU** 的 4D 并行：

```
                    16,384 GPUs
                    ┌─────────────────────────┐
 Data Parallel:     │  DP = 128 组            │  跨节点
                    │  ┌──────────────────┐    │
 Pipeline Parallel: │  │  PP = 16 stages  │    │  跨节点
                    │  │  ┌────────────┐   │   │
 Tensor Parallel:   │  │  │ TP = 8     │   │   │  节点内 NVLink
                    │  │  │  (1 node)  │   │   │
 Context Parallel:  │  │  │ CP = ?     │   │   │  长序列时启用
                    │  │  └────────────┘   │   │
                    │  └──────────────────┘    │
                    └─────────────────────────┘

总 GPU = DP × PP × TP (× CP) = 128 × 16 × 8 = 16,384
```

## 8. 选型指南

```
场景                     推荐策略                    理由
──────────────────────────────────────────────────────────────
7B 模型 / 单节点 8卡      FSDP (ZeRO-3)              简单高效
13-70B / 多节点           FSDP + TP (节点内)          平衡显存和通信
70B-400B / 大规模         TP + PP + FSDP              3D 并行标配
超长序列 (128K+)          + Context Parallelism        切分 KV Cache
万卡训练                  4D/5D 并行 + 精细调度       Meta/Google 级别
推理 (非训练)             TP (节点内) + PP (跨节点)    最小化延迟
```

## 9. 面试高频题

### Q1: 数据并行和模型并行的本质区别？
**答**：数据并行是"相同模型、不同数据"——每张卡持有完整模型副本，处理不同 mini-batch，需要 AllReduce 同步梯度。模型并行是"不同模型片、相同数据"——将模型拆分到多卡，需要在前向/反向中传递中间激活值。数据并行的通信量与参数量成正比；模型并行（TP/PP）的通信量与激活值大小成正比。

### Q2: ZeRO Stage 3 和 TP 都能解决单卡放不下模型的问题，如何选择？
**答**：ZeRO-3 (FSDP) 在 forward 前 AllGather 参数、backward 后 Reduce-Scatter 梯度，通信量是 DDP 的 1.5 倍，但对网络带宽要求低（可跨节点）。TP 在每层内部做 AllReduce，通信频率高但每次量小，对延迟敏感，必须用 NVLink（节点内）。实践中：**节点内用 TP，跨节点用 FSDP/ZeRO-3**。

### Q3: Pipeline Parallelism 的 bubble 如何减少？
**答**：三个方向：(1) 增大 micro-batch 数量 M，bubble ratio = (P-1)/(M+P-1) → M 越大 bubble 越小；(2) 采用 Interleaved 1F1B 调度，每卡持有多个 stage 的虚拟 chunk；(3) Zero Bubble PP 将 backward 拆为 B（输入梯度）和 W（权重梯度），通过精细调度 F/B/W 消除几乎所有 bubble。

### Q4: 序列并行和上下文并行的区别？
**答**：Megatron Sequence Parallelism 是 TP 的补充——在 TP 不切分的区域（LayerNorm、Dropout）沿序列维度切分**激活值**，减少冗余显存，不改变计算逻辑。Context Parallelism 是独立维度——将超长序列真正切分到多卡，每卡只处理一段 token，通过 Ring Attention 传递 KV 完成全局 Attention 计算，解决的是**序列长度**带来的显存和计算瓶颈。

### Q5: 如何设计一个 70B 模型在 64 张 H100 上的训练并行策略？
**答**：8 台 8xH100 节点。推荐配置：节点内 TP=8（利用 NVLink 900 GB/s），跨节点 FSDP（ZeRO-3 或 ZeRO-2），不需要 PP（70B 用 TP=8+FSDP 即可）。实际 GPU 分配：64 / 8(TP) = 8 组 FSDP。若序列长度 ≤ 8K，这就够了；若 128K+，加 CP=2，此时 DP=4, TP=8, CP=2。关键是先算显存：70B × 18 bytes(BF16+Adam) / 64 ≈ 20 GB/卡的参数+优化器，加上激活值（取决于 seq_len 和 micro-batch），选择合适的 activation checkpointing 策略。

---

**相关笔记**：[[FlashAttention]] | [[Transformer 位置编码]] | [[小规模训练手册]]
