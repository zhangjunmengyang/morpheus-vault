---
title: "分布式"
type: project
domain: ai/llm/infra
created: "2026-02-13"
updated: "2026-02-13"
tags:
  - ai/llm/infra
  - type/project
---
# 分布式训练

> 大模型训练的核心命题：怎么把一个装不进单卡的模型高效地训起来。

参考视频：https://space.bilibili.com/59807853/lists/1384251?type=season
verl 分布式训练：https://verl.readthedocs.io/en/latest/start/multinode.html

## 并行策略全景

```
                    分布式训练
                       │
        ┌──────────────┼──────────────┐
        │              │              │
   Data Parallel   Model Parallel  Pipeline Parallel
     (DP/ZeRO)       (TP/SP)          (PP)
        │              │              │
   每卡完整模型     层内切分         层间切分
   不同数据        同一层拆到多卡    不同层放不同卡
```

### Data Parallelism (DP)

最简单的并行：每张卡放一份完整模型，喂不同的数据，梯度做 AllReduce。

```python
# PyTorch DDP - 最朴素的 DP
model = DistributedDataParallel(model, device_ids=[local_rank])

# 问题：模型太大放不下一张卡怎么办？
# 答案：ZeRO
```

**ZeRO (Zero Redundancy Optimizer)**：DeepSpeed 的核心贡献。

| 级别 | 切分内容 | 显存节省 | 通信量 |
|------|---------|---------|--------|
| ZeRO-1 | Optimizer States | ~4x | 不变 |
| ZeRO-2 | + Gradients | ~8x | 不变 |
| ZeRO-3 | + Parameters | ~N倍(N=GPU数) | 增加 1.5x |

ZeRO-3 通信量增加的原因：forward/backward 时需要 AllGather 参数，相当于多了一轮通信。

### Tensor Parallelism (TP)

把单个矩阵乘法拆到多卡。**Megatron-LM** 的核心贡献。

```python
# Self-Attention: Q, K, V 按 head 维度切分
# 每张卡只计算部分 heads，最后 AllReduce

# MLP: 
# W1 按列切 → 每卡算部分 hidden
# W2 按行切 → AllReduce 聚合
```

TP 的通信发生在**每一层的 forward 和 backward**，非常频繁，所以必须用高带宽互连（NVLink/NVSwitch，900GB/s）。**绝对不要跨节点做 TP**。

### Pipeline Parallelism (PP)

按层切分，不同层放不同卡/节点。

```python
# 核心问题：bubble（空闲等待）
# 假设 4 个 stage，1 个 micro-batch：
# Stage 0: [F] [  ] [  ] [B]  ← 75% 时间在等
# Stage 1: [  ] [F] [B] [  ]
# Stage 2: [  ] [F] [B] [  ]
# Stage 3: [  ] [  ] [F] [B]

# 解决方案：micro-batching + 1F1B schedule
# 把 batch 切成 M 个 micro-batch，M >> PP_size
# bubble 比例 ≈ (PP_size - 1) / M
```

### Sequence Parallelism (SP)

TP 的延伸：在非 TP 区域（LayerNorm、Dropout）也做切分，避免这些操作重复计算。Megatron-LM v3 引入。

## 混合并行的最佳实践

训练一个 70B 模型，集群有 64 张 A100-80GB：

```
TP = 8   (一个节点 8 卡，NVLink 互连)
PP = 2   (2 个节点串联)
DP = 4   (4 组并行数据)
总 GPU = 8 × 2 × 4 = 64 ✓

# 不同并行度对通信的需求：
# TP: 高带宽、低延迟 → NVLink (同节点)
# PP: 中等带宽 → IB/RoCE (可跨节点)
# DP: 低频大块 → IB/RoCE (可跨节点)
```

## FSDP vs ZeRO

PyTorch 原生的 `FullyShardedDataParallel` 本质上就是 ZeRO-3：

```python
from torch.distributed.fsdp import FullyShardedDataParallel as FSDP

model = FSDP(
    model,
    sharding_strategy=ShardingStrategy.FULL_SHARD,  # ZeRO-3
    # ShardingStrategy.SHARD_GRAD_OP → ZeRO-2
    # ShardingStrategy.NO_SHARD → DDP
)
```

FSDP 的优势是**原生 PyTorch**，和生态兼容性好。缺点是早期实现不够成熟，checkpoint 格式变来变去。PyTorch 2.x 的 FSDP2 改进了不少。

## 通信原语速查

| 原语 | 场景 | 通信量 |
|------|------|--------|
| AllReduce | DP 梯度聚合 | 2(N-1)/N × size |
| AllGather | ZeRO-3 参数聚合 | (N-1)/N × size |
| ReduceScatter | ZeRO-3 梯度分发 | (N-1)/N × size |
| P2P Send/Recv | PP stage 间传递 | activation size |

## 我的经验

1. **7B 以下**：单卡或 DDP/ZeRO-2，不需要模型并行
2. **7B-13B**：ZeRO-3 或 FSDP，还是数据并行思路
3. **13B-70B**：TP + DP，有条件加 PP
4. **70B+**：三维并行，Megatron 基本是标配
5. **RL 训练**：用 Ray 编排，比 torchrun 灵活得多

## 相关

- [[AI/LLM/Infra/Megatron-LM|Megatron-LM]] — Tensor/Pipeline Parallelism 实现
- [[AI/LLM/Infra/Ray|Ray]] — 分布式编排框架
- [[AI/LLM/Frameworks/verl/训练后端|verl 训练后端]] — verl 的分布式后端选择
- [[AI/LLM/Frameworks/verl/硬件资源预估|硬件资源预估]] — 资源规划
- [[AI/LLM/Infra/FSDP|FSDP]]
- [[AI/LLM/Infra/DeepSpeed|DeepSpeed]]
- [[AI/LLM/Frameworks/verl/verl 概述|verl 概述]]
- [[AI/LLM/Frameworks/TRL/TRL 概述|TRL 概述]]
- [[AI/LLM/Frameworks/OpenRLHF/OpenRLHF|OpenRLHF]]
