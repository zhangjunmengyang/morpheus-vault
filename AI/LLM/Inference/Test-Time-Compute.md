---
title: "Test-Time Compute (TTC) â€” æ¨ç†æ—¶æ‰©å±•ç»¼è¿°"
brief: "TTC æ˜¯å¯¹ training-time scaling çš„æ­£äº¤è¡¥å……â€”â€”åœ¨æ¨ç†é˜¶æ®µåˆ†é…æ›´å¤šç®—åŠ›ï¼ˆCoT/Best-of-N/PRM/Budget Forcingï¼‰æ¥æå‡å‡†ç¡®ç‡ï¼Œè€Œéè®­ç»ƒæ›´å¤§æ¨¡å‹ï¼›Snell et al. (arXiv:2408.03314) è¯æ˜å¯¹éš¾é¢˜å°æ¨¡å‹+å¤§TTCå¯è¶…è¶Šå¤§æ¨¡å‹+å°TTCï¼›ç†è§£ TTC æ˜¯è¯»æ‡‚ o1/R1/s1 æ¨ç†èŒƒå¼çš„å…³é”®"
type: survey
domain: ai/llm/inference
created: "2026-02-19"
updated: "2026-02-22"
tags:
  - ai/llm/inference
  - concept/ttc
  - concept/scaling
  - type/survey
  - interview/hot
status: complete
sources:
  - "Scaling LLM Test-Time Compute Optimally arXiv:2408.03314 (Snell et al., Google DeepMind, 2024)"
  - "Let's Verify Step by Step (PRM) arXiv:2305.20050 (Lightman et al., OpenAI, 2023)"
  - "Self-Consistency Improves Chain of Thought Reasoning arXiv:2203.11171 (Wang et al., 2022)"
  - "Chain-of-Thought Prompting arXiv:2201.11903 (Wei et al., Google, 2022)"
  - "Deep-Thinking Ratio arXiv:2602.13517 (2026)"
  - "s1: Simple Test-Time Scaling (Stanford, 2025)"
related:
  - "[[AI/LLM/Inference/æ¨ç†ä¼˜åŒ–|æ¨ç†ä¼˜åŒ–]]"
  - "[[AI/LLM/RL/GRPO/GRPO æ·±åº¦ç†è§£|GRPO]]"
  - "[[AI/LLM/Architecture/DeepSeek-R1|DeepSeek-R1]]"
  - "[[AI/LLM/Inference/Gemini-3-Deep-Think|Gemini-3-Deep-Think]]"
  - "[[AI/LLM/Evaluation/ICLR-2026-è¶‹åŠ¿åˆ†æ|ICLR-2026-è¶‹åŠ¿åˆ†æ]]"
  - "[[AI/LLM/RL/Theory/RLVR-Edge-of-Competence|RLVR-Edge-of-Competence]]"
  - "[[AI/LLM/Inference/Deep-Thinking-Ratio-DTR|Deep-Thinking-Ratio-DTR]]"
  - "[[AI/LLM/Inference/é‡‡æ ·ç­–ç•¥|é‡‡æ ·ç­–ç•¥]]"
---

# Test-Time Compute (TTC) â€” æ¨ç†æ—¶æ‰©å±•ç»¼è¿°

> **Brief**ï¼šTTC åœ¨æ¨ç†é˜¶æ®µåˆ†é…æ›´å¤šç®—åŠ›ï¼ˆCoT/Best-of-N/PRM/Budget Forcingï¼‰æ¥æå‡å‡†ç¡®ç‡ï¼Œæ˜¯å¯¹ training-time scaling çš„æ­£äº¤è¡¥å……ã€‚Snell et al. (arXiv:2408.03314) çš„å…³é”®å‘ç°ï¼šå¯¹éš¾é¢˜ï¼Œå°æ¨¡å‹+å¤§TTC å¯è¶…è¶Šå¤§æ¨¡å‹+å°TTCã€‚
>
> æ¥æºï¼šSnell et al. arXiv:2408.03314; Let's Verify Step by Step arXiv:2305.20050; Self-Consistency arXiv:2203.11171

> å…³é”®è¯ï¼šinference-time scaling, test-time compute, chain-of-thought, self-verification, budget forcing

## ä¸€å¥è¯å®šä¹‰

**åœ¨æ¨ç†é˜¶æ®µåˆ†é…æ›´å¤šç®—åŠ›ï¼ˆè€Œä¸æ˜¯è®­ç»ƒæ›´å¤§çš„æ¨¡å‹ï¼‰æ¥æå‡ä»»åŠ¡å‡†ç¡®ç‡ã€‚**

è¿™æ˜¯å¯¹ training-time scaling lawï¼ˆChinchilla, arXiv:2203.15556ï¼‰çš„æ­£äº¤è¡¥å……ç»´åº¦ã€‚

---

## èƒŒæ™¯ä¸åŠ¨æœº

### Chinchilla Scaling çš„ç“¶é¢ˆ

ä¼ ç»Ÿ scaling è·¯çº¿ï¼šæ›´å¤šæ•°æ® + æ›´å¤šå‚æ•° + æ›´å¤šè®­ç»ƒç®—åŠ› â†’ æ€§èƒ½æå‡ã€‚

ä½†è¿™æ¡è·¯è¶Šæ¥è¶Šè´µï¼šGPT-4 è®­ç»ƒæˆæœ¬ ~$100Mï¼ŒGPT-5 æ•°é‡çº§æ›´é«˜ã€‚

### TTC çš„æ ¸å¿ƒæ´å¯Ÿ

**äººç±»é¢å¯¹éš¾é¢˜æ—¶ä¼šå¤šæ€è€ƒï¼Œè€Œä¸æ˜¯æ›¿æ¢è‡ªå·±çš„å¤§è„‘ã€‚**

LLM å¯ä»¥åšåŒæ ·çš„äº‹ï¼šåœ¨ inference æ—¶å¤šåˆ†é…ç®—åŠ›ï¼Œè€Œä¸æ˜¯è®­ç»ƒæ›´å¤§çš„æ¨¡å‹ã€‚

å…³é”® empirical å‘ç°ï¼š
- **å¯¹éš¾é¢˜**ï¼šå°æ¨¡å‹ + å¤§é‡ TTC > å¤§æ¨¡å‹ + å°‘é‡ TTC
- **compute-optimal ç‚¹éšä»»åŠ¡éš¾åº¦ç§»åŠ¨**ï¼šéš¾é¢˜å€¼å¾—åˆ†é…æ›´å¤šæ¨ç†ç®—åŠ›

> æ¥æºï¼šSnell et al. arXiv:2408.03314 "Scaling LLM Test-Time Compute Optimally Can be More Effective than Scaling Model Parameters", Sec. 4

---

## æ ¸å¿ƒæŠ€æœ¯è·¯å¾„

### 1. Chain-of-Thoughtï¼ˆCoTï¼‰

æœ€æ—©æœŸçš„ TTC å½¢å¼ã€‚è®©æ¨¡å‹æ˜¾å¼è¾“å‡ºæ¨ç†æ­¥éª¤ï¼Œè€Œä¸æ˜¯ç›´æ¥è¾“å‡ºç­”æ¡ˆã€‚

```
[ç›´æ¥å›ç­”] "The answer is 42."
[CoT]      "Step 1: ... Step 2: ... Therefore 42."
```

CoT æŠŠ latent reasoning å˜æˆ token generationï¼Œæ¨¡å‹å¯ä»¥åœ¨ä¸­é—´æ­¥éª¤ä¸Šåš conditional generationã€‚

### 2. Process Reward Modelï¼ˆPRMï¼‰

åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­ï¼Œå¯¹æ¯ä¸€æ­¥æ¨ç†åšè¯„åˆ†ï¼Œè€Œä¸æ˜¯åªè¯„æœ€ç»ˆç­”æ¡ˆã€‚

> æ¥æºï¼šLightman et al. arXiv:2305.20050 "Let's Verify Step by Step" (OpenAI, 2023)

- **Outcome Reward Model (ORM)**ï¼šåªçœ‹ç»“æœå¯¹ä¸å¯¹
- **Process Reward Model (PRM)**ï¼šæ¯æ­¥éƒ½æ‰“åˆ†
- PRM èƒ½æ›´æ—©å‘ç°é”™è¯¯è·¯å¾„ï¼Œå¼•å¯¼æ¨¡å‹ self-correct

### 3. Best-of-N / Self-Consistency

> æ¥æºï¼šWang et al. arXiv:2203.11171 "Self-Consistency Improves Chain of Thought Reasoning in Language Models"

- ç”Ÿæˆ N ä¸ªå€™é€‰ç­”æ¡ˆï¼Œç”¨ majority vote æˆ– reward model é€‰æœ€ä¼˜
- ç®€å•æœ‰æ•ˆï¼Œcompute çº¿æ€§æ‰©å±•
- é™åˆ¶ï¼šN ä¸ª sample å½¼æ­¤ç‹¬ç«‹ï¼Œæ— æ³•äº’ç›¸çº é”™

### 4. Beam Search / Tree-of-Thought

- å¹¶è¡Œç»´æŠ¤å¤šæ¡æ¨ç†è·¯å¾„ï¼ˆbeamï¼‰
- ä¸­é—´å‰ªæä¸é è°±çš„è·¯å¾„ï¼Œæ‰©å±•æœ‰æ½œåŠ›çš„
- Tree-of-Thought æ˜¯æ³›åŒ–ï¼šæ ‘å½¢æœç´¢ + æ˜¾å¼çŠ¶æ€è¯„ä¼°

### 5. Budget Forcing

Stanford s1 è®ºæ–‡æå‡ºï¼ˆ2025ï¼‰ï¼š

**å¼ºåˆ¶æ¨¡å‹åˆ†é…å›ºå®š thinking budgetï¼ˆtoken æ•°ï¼‰ï¼Œä¸å…è®¸æå‰åœæ­¢ã€‚**

å³ä½¿æ¨¡å‹æƒ³è¾“å‡º "ç­”æ¡ˆæ˜¯ X"ï¼Œä¹Ÿ force å®ƒç»§ç»­ "think longer"ã€‚

å®éªŒç»“è®ºï¼šåŒä¸€å°æ¨¡å‹ï¼Œç»™æ›´å¤š thinking budget â†’ æ€§èƒ½å¤§å¹…æå‡ï¼Œæ¥è¿‘ GPT-4 æ°´å¹³ã€‚

### 6. Extended Thinking / Internal Verificationï¼ˆå‰æ²¿ï¼‰

Gemini 3 Deep Thinkï¼ˆ2026ï¼‰çš„è·¯çº¿ï¼š

- æ¨ç†æ­¥éª¤ä¸ä¸€å®šè¾“å‡ºï¼Œåœ¨ internal state é‡Œå®Œæˆ
- æ¨¡å‹å†…éƒ¨åš **self-verification**ï¼šç”Ÿæˆç­”æ¡ˆ â†’ å†…éƒ¨æ£€æŸ¥é€»è¾‘ä¸€è‡´æ€§ â†’ å‘ç°é”™è¯¯ â†’ å›æº¯ä¿®æ­£
- è¿™å±‚éªŒè¯å¯¹ç”¨æˆ·é€æ˜ï¼Œä¸å è¾“å‡º token

---

## å·¥ä¸šè½åœ°é‡Œç¨‹ç¢‘

| æ—¶é—´ | æ¨¡å‹ | æŠ€æœ¯è·¯çº¿ | å…³é”® Benchmark |
|------|------|---------|---------------|
| 2024-09 | OpenAI o1 | Long CoT + PRM | AIME 2024: 83% |
| 2025-01 | DeepSeek-R1 | GRPO + RL-trained long CoT | AIME 2025: 79.8% |
| 2025-01 | Stanford s1 | Budget forcing on 1B model | è¶…è¶Š o1 on AIME |
| 2026-02 | Gemini 3 Deep Think | TTC + internal verification | ARC-AGI-2: 84.6% (è¶…äººç±»å‡å€¼) |

> å‚è€ƒï¼š[[AI/LLM/Inference/Gemini-3-Deep-Think|Gemini-3-Deep-Think]] [[AI/LLM/Evaluation/ICLR-2026-è¶‹åŠ¿åˆ†æ|ICLR-2026-è¶‹åŠ¿åˆ†æ]]

---

## æ ¸å¿ƒ Trade-off

```
æ›´å¤š TTC â†’ æ›´é«˜å‡†ç¡®ç‡
         â†’ æ›´é«˜ latency
         â†’ æ›´é«˜ cost
```

**Compute-optimal åˆ†é…**ï¼ˆSnell et al., 2024ï¼‰ï¼š

- ç»™å®šæ€»ç®—åŠ›é¢„ç®— B
- å¦‚ä½•åœ¨ "è®­ç»ƒæ›´å¤§æ¨¡å‹" vs "æ¨ç†ç”¨æ›´å¤šç®—åŠ›" ä¹‹é—´åˆ†é…ï¼Ÿ
- ç­”ï¼š**ä»»åŠ¡éš¾åº¦ > threshold æ—¶ï¼Œåˆ†é…ç»™ TTC æ›´åˆ’ç®—**

---

## TTC vs Training-time Scaling

| ç»´åº¦ | Training-time Scaling | Test-time Compute |
|------|----------------------|-------------------|
| æŠ•å…¥æ—¶æœº | è®­ç»ƒé˜¶æ®µ | æ¨ç†é˜¶æ®µ |
| æˆæœ¬ | ä¸€æ¬¡æ€§ï¼ˆamortizedï¼‰ | æ¯æ¬¡æ¨ç†éƒ½ä»˜ |
| çµæ´»æ€§ | å›ºå®š | å¯åŠ¨æ€è°ƒæ•´ |
| é€‚åˆåœºæ™¯ | é€šç”¨èƒ½åŠ›æå‡ | ç‰¹å®šéš¾é¢˜æ”»åš |
| å…¸å‹ä»£è¡¨ | Chinchilla, GPT-4 | o1, R1, s1 |

ä¸¤è€… **orthogonalï¼Œå¯ä»¥ç»„åˆ**ï¼šå¤§æ¨¡å‹ + å¤§ TTC = æœ€å¼ºæ¨ç†èƒ½åŠ›ï¼Œä½†æœ€è´µã€‚

---

## å¯¹ç®—æ³•å·¥ç¨‹å¸ˆçš„å¯ç¤º

### é¢è¯•é«˜é¢‘è€ƒç‚¹ï¼ˆICLR 2026 TTC è®ºæ–‡ 257 ç¯‡ï¼‰

1. **TTC ä¸ºä»€ä¹ˆ workï¼Ÿ**
   - ç­‰æ•ˆäºæœç´¢ï¼šåœ¨ solution space ä¸­æœç´¢æ›´ä¹…
   - éš¾é¢˜éœ€è¦æ›´é•¿æ¨ç†é“¾ï¼ŒCoT æä¾›ä¸­é—´çŠ¶æ€
   - PRM æä¾› guidanceï¼Œé¿å…ç›²ç›®æœç´¢

2. **ä¸ RLVR çš„å…³ç³»**
   - RLVRï¼ˆ[[AI/LLM/RL/Theory/RLVR-Edge-of-Competence|RLVR-Edge-of-Competence]]ï¼‰è®­ç»ƒå‡ºèƒ½åšé•¿ CoT çš„æ¨¡å‹
   - TTC æ˜¯è¿™äº›æ¨¡å‹åœ¨æ¨ç†æ—¶çš„ deployment ç­–ç•¥
   - ä¸¤è€…ååŒï¼šRL è®­ç»ƒèµ‹äºˆèƒ½åŠ›ï¼ŒTTC åœ¨æ¨ç†æ—¶æ¿€å‘

3. **Budget forcing çš„ç›´è§‰**
   - ç±»æ¯”ï¼šè€ƒè¯•ä¸åˆ°æœ€åä¸€åˆ†é’Ÿä¸å…è®¸äº¤å·
   - æ¨¡å‹è¢«è¿« "å†æƒ³æƒ³"ï¼Œæœ‰æ—¶å€™èƒ½çº æ­£ç¬¬ä¸€å°è±¡çš„é”™è¯¯

### å·¥ç¨‹å®è·µæ³¨æ„

- å®æ—¶åº”ç”¨æ…ç”¨å¤§ TTCï¼ˆlatency é—®é¢˜ï¼‰
- ç¦»çº¿ä»»åŠ¡ï¼ˆä»£ç  reviewã€è®ºæ–‡åˆ†æï¼‰å¯ä»¥ç»™å¤§ budget
- Best-of-N æ˜¯æœ€ç®€å•çš„ TTC å®ç°ï¼Œä½æˆæœ¬éªŒè¯æœ‰æ•ˆæ€§

---

## 2026-02 æ–°è¿›å±•ï¼šè´¨é‡ vs æ•°é‡çš„é‡æ–°å®šä¹‰

### Deep-Thinking Ratio (DTR)ï¼ˆ2602.13517ï¼‰

ä¸€ä¸ªé¢ è¦†"é•¿åº¦ = è´¨é‡"å‡è®¾çš„é‡è¦å‘ç°ï¼š

**å…³é”®æ•°å­—**ï¼š
- Token count ä¸å‡†ç¡®ç‡ Pearson r = **-0.544**ï¼ˆè´Ÿç›¸å…³ï¼ï¼‰
- DTR ä¸å‡†ç¡®ç‡ Pearson r = **+0.828**ï¼ˆå¼ºæ­£ç›¸å…³ï¼‰

**DTR å®šä¹‰**ï¼šåºåˆ—ä¸­"æ·±å±‚æ‰æ”¶æ•›"çš„ token æ¯”ä¾‹ã€‚ä½¿ç”¨ logit lens æŠ€æœ¯ï¼Œè®¡ç®—æ¯å±‚ hidden state æŠ•å½±çš„åˆ†å¸ƒä¸æœ€ç»ˆå±‚çš„ JSD æ•£åº¦ï¼Œæ”¶æ•›å±‚æ·±çš„ token = æ·±åº¦æ€è€ƒ tokenã€‚

**Think@n**ï¼šåŸºäº DTR çš„ test-time scaling ç­–ç•¥ï¼Œç”¨ DTR æ—©æœŸç­›é€‰ + æ‹’ç»ä½è´¨é‡ç”Ÿæˆï¼Œåœ¨åŒ¹é… SC@n å‡†ç¡®ç‡çš„åŒæ—¶é™ä½çº¦ 50% è®¡ç®—æˆæœ¬ã€‚

è¯¦è§ï¼š[[AI/LLM/Inference/Deep-Thinking-Ratio-DTR|Deep-Thinking-Ratio-DTR]]

**å¯¹ TTC çš„å¯ç¤º**ï¼šTTC çš„ç›®æ ‡ä¸åº”è¯¥æ˜¯"æ›´å¤š token"ï¼Œè€Œæ˜¯"æ›´å¤šæ·±å±‚æ¨ç† token"ã€‚Budget forcing åªçº¦æŸæ•°é‡ï¼Œæœªæ¥çš„æ”¹è¿›æ–¹å‘å¯èƒ½æ˜¯çº¦æŸ DTRï¼Œé¼“åŠ±æ¨¡å‹ç”¨æœ‰é™ token è¿›è¡Œæ›´æ·±åº¦çš„æ€è€ƒã€‚

---

## çŸ¥è¯†ç¼ºå£

- [ ] Inference-time scaling law æ•°å­¦æ¨å¯¼ï¼ˆSnell et al. 2024 åŸè®ºæ–‡ï¼‰
- [ ] PRM çš„è®­ç»ƒæ–¹å¼ï¼ˆå“ªäº›æ•°æ®ï¼Œæ€ä¹ˆæ‰“ step labelï¼‰
- [ ] o3 TTC çš„å…·ä½“æœºåˆ¶ï¼ˆæœªå…¬å¼€ï¼‰
- [ ] DTR åœ¨ MoE æ¨¡å‹ä¸Šçš„é€‚ç”¨æ€§
- [ ] DTR ä½œä¸º RL reward ä¿¡å·çš„å¯è¡Œæ€§

---

## å…³è”ç¬”è®°

- [[AI/LLM/Inference/Gemini-3-Deep-Think|Gemini-3-Deep-Think]] â€” TTC å‰æ²¿è½åœ°æ¡ˆä¾‹
- [[AI/LLM/Inference/æ¨ç†ä¼˜åŒ–|æ¨ç†ä¼˜åŒ–]] â€” å·¥ç¨‹å±‚é¢çš„ inference ä¼˜åŒ–
- [[AI/LLM/Inference/Speculative Decoding|Speculative Decoding]] â€” å¦ä¸€ç§æ¨ç†åŠ é€Ÿæ–¹å‘ï¼ˆå‡å°‘ latencyï¼Œä¸ TTC ç›®æ ‡ç›¸åï¼‰
- [[AI/LLM/Evaluation/ICLR-2026-è¶‹åŠ¿åˆ†æ|ICLR-2026-è¶‹åŠ¿åˆ†æ]] â€” TTC æ˜¯ ICLR 2026 æœ€å¤§çƒ­ç‚¹ï¼ˆ257ç¯‡ï¼‰
- [[AI/LLM/RL/Theory/RLVR-Edge-of-Competence|RLVR-Edge-of-Competence]] â€” RL è®­ç»ƒå¦‚ä½•èµ‹äºˆæ¨¡å‹ TTC èƒ½åŠ›
- [[AI/LLM/Inference/é‡‡æ ·ç­–ç•¥|é‡‡æ ·ç­–ç•¥]] â€” Best-of-Nã€Beam Search å®ç°ç»†èŠ‚
- [[AI/LLM/Inference/Deep-Thinking-Ratio-DTR|Deep-Thinking-Ratio-DTR]] â€” æ¨ç†è´¨é‡æ–°æŒ‡æ ‡ï¼Œè¶…è¶Š token é•¿åº¦

---

## ğŸ”§ è½åœ°åº”ç”¨

### ä»€ä¹ˆæ—¶å€™ç”¨ TTCï¼Ÿ

| åœºæ™¯ | TTC ç­–ç•¥ | æ•ˆæœ | æˆæœ¬ |
|------|---------|------|------|
| æ•°å­¦/ä»£ç ç«èµ› | Best-of-N + PRM | æå¥½ | é«˜ï¼ˆN æ¬¡æ¨ç†ï¼‰ |
| å¤æ‚æ¨ç†ä»»åŠ¡ | Long CoT + Budget Forcing | å¾ˆå¥½ | ä¸­é«˜ï¼ˆé•¿è¾“å‡ºï¼‰ |
| å®æ—¶å¯¹è¯ | ä¸é€‚åˆå¤§ TTC | â€” | å»¶è¿Ÿä¸å¯æ¥å— |
| ç¦»çº¿æ‰¹å¤„ç†ï¼ˆä»£ç  reviewã€è®ºæ–‡åˆ†æï¼‰ | å¤§ Budget + PRM | æœ€ä½³ | å¯æ¥å— |
| ç®€å• QA | ä¸éœ€è¦ TTC | â€” | æµªè´¹ç®—åŠ› |

### å·¥ç¨‹å®ç°è¦ç‚¹

- **Best-of-N æ˜¯æœ€ç®€å•çš„ TTC å®ç°**ï¼šN=8-16 é€šå¸¸å°±èƒ½æ˜¾è‘—æå‡å‡†ç¡®ç‡ï¼Œä½æˆæœ¬éªŒè¯æœ‰æ•ˆæ€§
- **PRM è®­ç»ƒéœ€è¦ step-level æ ‡æ³¨**ï¼šæˆæœ¬é«˜ï¼Œä½†ä¸€æ—¦è®­ç»ƒå¥½å¯ä»¥å¤ç”¨
- **Budget Forcing çš„å®ç°**ï¼šåœ¨ç”Ÿæˆæ—¶è®¾ç½®æœ€å° token æ•°ï¼Œé‡åˆ° `<end>` token æ›¿æ¢ä¸º `\n` ç»§ç»­ç”Ÿæˆ
- **åŠ¨æ€é¢„ç®—åˆ†é…**ï¼šç®€å•é—®é¢˜ç»™å°‘é‡ TTCï¼Œéš¾é¢˜ç»™å¤§é‡ TTC â†’ éœ€è¦ä¸€ä¸ªéš¾åº¦è¯„ä¼°å™¨ï¼ˆå¯ä»¥ç”¨ prompt çš„ perplexity æˆ–åˆå§‹ logits çš„ entropy ä¼°ç®—ï¼‰

### é¢è¯•é«˜é¢‘é—®æ³•

- **Q: TTC ä¸ºä»€ä¹ˆ workï¼Ÿå’Œæœç´¢æœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ**
  A: TTC æœ¬è´¨æ˜¯åœ¨ solution space ä¸­æœç´¢æ›´ä¹…ã€‚CoT æä¾›ä¸­é—´çŠ¶æ€ä½¿æœç´¢æœ‰æ–¹å‘ï¼ŒPRM æä¾› guidance é¿å…ç›²ç›®æœç´¢ï¼ŒBest-of-N æ˜¯æœ€ç®€å•çš„å¹¶è¡Œæœç´¢ã€‚

- **Q: ç»™ä½ å›ºå®šç®—åŠ›é¢„ç®—ï¼Œæ˜¯è®­ç»ƒæ›´å¤§æ¨¡å‹è¿˜æ˜¯ç”¨æ›´å¤š TTCï¼Ÿ**
  A: å–å†³äºä»»åŠ¡éš¾åº¦ã€‚Snell et al. (arXiv:2408.03314) è¯æ˜ï¼šéš¾é¢˜ä¸Š TTC çš„ ROI æ›´é«˜ï¼Œç®€å•ä»»åŠ¡ç”¨å¤§æ¨¡å‹æ›´åˆ’ç®—ã€‚Compute-optimal ç‚¹éšéš¾åº¦ç§»åŠ¨ã€‚

- **Q: Budget Forcing å’Œ Chain-of-Thought çš„åŒºåˆ«ï¼Ÿ**
  A: CoT æ˜¯"è®©æ¨¡å‹å±•ç¤ºæ¨ç†æ­¥éª¤"ï¼Œæ¨¡å‹è‡ªå·±å†³å®šæƒ³å¤šä¹…ã€‚Budget Forcing æ˜¯"å¼ºåˆ¶æ¨¡å‹æƒ³æ›´ä¹…"ï¼Œå³ä½¿æ¨¡å‹æƒ³æ—©åœä¹Ÿä¸å…è®¸ã€‚åè€…å¾€å¾€èƒ½å‘ç°ç¬¬ä¸€å°è±¡çš„é”™è¯¯ã€‚

---

## ğŸ’¡ å¯å‘ä¸æ€è€ƒ

### So Whatï¼Ÿ

TTC æ­ç¤ºäº†ä¸€ä¸ªæ·±åˆ»çš„èŒƒå¼è½¬å˜ï¼š**æ¨ç†èƒ½åŠ›ä¸ä»…å¯ä»¥é€šè¿‡è®­ç»ƒè·å¾—ï¼Œä¹Ÿå¯ä»¥é€šè¿‡æ¨ç†æ—¶çš„è®¡ç®—åˆ†é…æ¥å¢å¼º**ã€‚è¿™ç±»ä¼¼äºäººç±»çš„ç›´è§‰å’Œæ·±æ€â€”â€”å¿«é€Ÿç›´è§‰ï¼ˆSystem 1ï¼‰å¯¹åº”æ ‡å‡†æ¨ç†ï¼Œæ·±å…¥æ€è€ƒï¼ˆSystem 2ï¼‰å¯¹åº” TTCã€‚

å¯¹è€æ¿çš„å¯ç¤ºï¼š
- **Agent è®¾è®¡ä¸­åº”è¯¥å†…ç½® TTC ç­–ç•¥**ï¼šå¯¹ç®€å•è¯·æ±‚å¿«é€Ÿå“åº”ï¼Œå¯¹å¤æ‚ä»»åŠ¡è‡ªåŠ¨åˆ†é…æ›´å¤šæ€è€ƒé¢„ç®—
- **æˆæœ¬æ§åˆ¶çš„æ–°ç»´åº¦**ï¼šä¸å†åªæ˜¯"ç”¨å¤šå¤§çš„æ¨¡å‹"ï¼Œè¿˜è¦è€ƒè™‘"ç»™å¤šå°‘æ¨ç†é¢„ç®—"
- **å°æ¨¡å‹ + å¤§ TTC å¯èƒ½æ˜¯æ€§ä»·æ¯”æœ€é«˜çš„æ–¹æ¡ˆ**ï¼šæ¯”å¦‚ 7B æ¨¡å‹ + Best-of-16 å¯èƒ½æ¯” 70B æ¨¡å‹ + å•æ¬¡æ¨ç†æ›´å¥½

### å±€é™ä¸æœªè§£é—®é¢˜

- **å»¶è¿Ÿé—®é¢˜**ï¼šTTC å¢åŠ æ¨ç†æ—¶é—´ï¼Œå®æ—¶åº”ç”¨éš¾ä»¥æ¥å—ï¼ˆo1 çš„"æ€è€ƒä¸­..."å°±æ˜¯å»¶è¿Ÿçš„ä½“ç°ï¼‰
- **æˆæœ¬çº¿æ€§å¢é•¿**ï¼šBest-of-N çš„æˆæœ¬éš N çº¿æ€§å¢é•¿ï¼Œæ²¡æœ‰"å…è´¹åˆé¤"
- **PRM çš„è®­ç»ƒæ•°æ®è·å–å›°éš¾**ï¼šstep-level æ ‡æ³¨æˆæœ¬æé«˜ï¼Œè‡ªåŠ¨æ ‡æ³¨æ–¹æ³•ä»åœ¨æ¢ç´¢
- **DTR ç ”ç©¶è¿˜å¾ˆåˆæ­¥**ï¼šDeep-Thinking Ratio è¯æ˜"æ€è€ƒæ·±åº¦æ¯”é•¿åº¦é‡è¦"ï¼Œä½†å¦‚ä½•å¼•å¯¼æ¨¡å‹æ·±åº¦æ€è€ƒä»ä¸æ¸…æ¥š
- **TTC å¯¹ä¸åŒæ¨¡å‹æ¶æ„çš„æ•ˆæœå·®å¼‚**ï¼šMoE vs Dense æ¨¡å‹åœ¨ TTC ä¸Šçš„è¡¨ç°æ˜¯å¦ä¸åŒï¼Ÿ

### è„‘æš´æ‹“å±•

- **è‡ªé€‚åº” TTC é¢„ç®—åˆ†é…å™¨**ï¼šè®­ç»ƒä¸€ä¸ªè½»é‡æ¨¡å‹é¢„æµ‹"è¿™ä¸ªé—®é¢˜éœ€è¦å¤šå°‘ TTC"â†’ åœ¨å»¶è¿Ÿå’Œå‡†ç¡®ç‡é—´åŠ¨æ€ trade-off
- **TTC + MoE çš„ååŒ**ï¼šä¸åŒ expert å¤„ç†ä¸åŒæ¨ç†æ·±åº¦ï¼Ÿæµ…å±‚ expert è´Ÿè´£ System 1 æ¨ç†ï¼Œæ·±å±‚ expert è´Ÿè´£ System 2ï¼Ÿ
- **DTR ä½œä¸º RL reward ä¿¡å·**ï¼šåœ¨ RLVR è®­ç»ƒä¸­ç”¨ DTR ä»£æ›¿ï¼ˆæˆ–è¾…åŠ©ï¼‰ORM/PRMï¼Œé¼“åŠ±æ¨¡å‹ç”Ÿæˆ"æ·±åº¦æ€è€ƒ token"è€Œé"é•¿ä½†æµ…çš„ token"

> ğŸ”— See also:
> - [[AI/LLM/Inference/æ¨ç†ä¼˜åŒ–|æ¨ç†ä¼˜åŒ–]] â€” å·¥ç¨‹å±‚é¢çš„ inference ä¼˜åŒ–ï¼ˆå‡å°‘ latencyï¼‰
> - [[AI/LLM/RL/GRPO/GRPO æ·±åº¦ç†è§£|GRPO]] â€” RL è®­ç»ƒèµ‹äºˆæ¨¡å‹ TTC èƒ½åŠ›
> - [[AI/LLM/Architecture/DeepSeek-R1|DeepSeek-R1]] â€” GRPO + long CoT çš„å®è·µ
> - [[AI/LLM/Inference/Deep-Thinking-Ratio-DTR|Deep-Thinking-Ratio-DTR]] â€” æ¨ç†è´¨é‡æ–°æŒ‡æ ‡ï¼Œæ€è€ƒæ·±åº¦ > æ€è€ƒé•¿åº¦

---

## ğŸ“š æ¨èé˜…è¯»

### åŸå§‹è®ºæ–‡
- [Scaling LLM Test-Time Compute Optimally Can be More Effective than Scaling Model Parameters](https://arxiv.org/abs/2408.03314) â€” TTC é¢†åŸŸæœ€é‡è¦çš„ç†è®ºå·¥ä½œï¼Œè¯æ˜ compute-optimal åˆ†é…ç­–ç•¥ â­â­â­â­â­
- [Let's Verify Step by Step](https://arxiv.org/abs/2305.20050) â€” PRM çš„å¥ åŸºè®ºæ–‡ï¼Œprocess reward æ¯” outcome reward æ›´æœ‰æ•ˆ â­â­â­â­â­
- [Self-Consistency Improves Chain of Thought Reasoning](https://arxiv.org/abs/2203.11171) â€” Best-of-N + majority vote çš„ç®€å•ä½†å¼ºå¤§çš„ TTC æ–¹æ³• â­â­â­â­â­
- [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903) â€” CoT çš„å¼€å±±ä¹‹ä½œï¼Œæœ€æ—©çš„ TTC å½¢å¼ â­â­â­â­â­
- [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601) â€” æ ‘å½¢æœç´¢ + æ˜¾å¼çŠ¶æ€è¯„ä¼° â­â­â­â­

### æ·±åº¦è§£è¯»
- [OpenAI o1 System Card](https://openai.com/index/openai-o1-system-card/) â€” o1 çš„è®¾è®¡å“²å­¦å’Œå®‰å…¨è€ƒé‡ â­â­â­â­
- [DeepSeek-R1 Technical Report](https://arxiv.org/abs/2501.12948) â€” GRPO + long CoT è®­ç»ƒçš„å·¥ç¨‹å®è·µ â­â­â­â­â­

### å®è·µèµ„æº
- [s1: Simple Test-Time Scaling (GitHub)](https://github.com/simplescaling/s1) â€” Stanford çš„ Budget Forcing å®ç°ï¼Œå°æ¨¡å‹è¶…è¶Š o1 â­â­â­â­
- [PRM800K Dataset (OpenAI)](https://github.com/openai/prm800k) â€” PRM è®­ç»ƒæ•°æ®é›†ï¼Œ800K step-level æ ‡æ³¨ â­â­â­â­

---

*Created: 2026-02-19 by Librarian heartbeat â€” è¡¥å…¨çŸ¥è¯†ç¼ºå£ TTC*
*Updated: 2026-02-22 â€” è¡¥å…… frontmatter/å‡ºå¤„/æ¨èé˜…è¯»/è½åœ°åº”ç”¨/å¯å‘æ€è€ƒ*
