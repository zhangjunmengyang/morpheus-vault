---
brief: "Unsloth 多卡并行——从单卡到多 GPU 的 Unsloth 扩展配置；数据并行（DDP）设置、梯度累积调整、多卡显存分配策略；Unsloth 在多卡场景的性能特性和限制。"
title: "多卡并行"
type: concept
domain: ai/llm/frameworks/unsloth
created: "2026-02-13"
updated: "2026-02-13"
tags:
  - ai/llm/frameworks/unsloth
  - type/concept
---
# Unsloth 多卡并行

> 文档：https://docs.unsloth.ai/basics/multi-gpu-training-with-unsloth

Unsloth 的核心优势是单卡高效——通过 kernel fusion 等优化在单 GPU 上榨干性能。但当模型大到单卡放不下，或者训练数据太多需要加速时，就需要多卡并行。

## Unsloth 的多卡方案

Unsloth 原生支持通过 HuggingFace Accelerate 做数据并行（DDP）。对于 LoRA 微调来说，这通常就够了——LoRA 的参数量很小，模型本体被冻结，单卡就能放下。

### 数据并行（DDP）

每张卡放一份完整模型，各自处理不同 batch，梯度聚合后更新：

```bash
# 使用 accelerate 启动
accelerate launch --num_processes 4 train.py
```

```python
# train.py 中的代码几乎不用改
from unsloth import FastLanguageModel

model, tokenizer = FastLanguageModel.from_pretrained(
    model_name="unsloth/Qwen2.5-7B-Instruct-bnb-4bit",
    max_seq_length=2048,
)

model = FastLanguageModel.get_peft_model(
    model,
    r=16,
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj",
                     "gate_proj", "up_proj", "down_proj"],
    lora_alpha=16,
    lora_dropout=0,
    use_gradient_checkpointing="unsloth",
)

# Trainer 自动处理多卡分发
trainer = SFTTrainer(
    model=model,
    tokenizer=tokenizer,
    train_dataset=dataset,
    args=TrainingArguments(
        per_device_train_batch_size=4,  # 每张卡的 batch size
        gradient_accumulation_steps=4,
        # 总 effective batch = 4卡 × 4batch × 4accumulation = 64
    ),
)
trainer.train()
```

### Accelerate 配置

```yaml
# accelerate_config.yaml
compute_environment: LOCAL_MACHINE
distributed_type: MULTI_GPU
num_machines: 1
num_processes: 4
mixed_precision: bf16
```

```bash
accelerate launch --config_file accelerate_config.yaml train.py
```

## 什么时候需要模型并行

如果模型大到单卡放不下（即使 4bit 量化后），需要模型并行：

| 模型大小 | 4bit 显存 | 方案 |
|----------|-----------|------|
| 7B | ~6GB | 单卡即可 |
| 14B | ~10GB | 单卡 A100 可以 |
| 32B | ~20GB | 需要多卡或大显存 |
| 72B | ~40GB | 必须多卡 |

对于需要模型并行的场景，建议用 DeepSpeed ZeRO 或直接用 verl/OpenRLHF 等框架。

### DeepSpeed ZeRO

```json
// ds_config.json
{
    "zero_optimization": {
        "stage": 2,
        "offload_optimizer": {
            "device": "cpu"
        }
    },
    "bf16": {"enabled": true},
    "train_batch_size": "auto",
    "train_micro_batch_size_per_gpu": "auto"
}
```

```bash
accelerate launch --use_deepspeed --deepspeed_config ds_config.json train.py
```

## 性能调优

### Batch Size 与 Gradient Accumulation

```
effective_batch_size = num_gpus × per_device_batch × gradient_accumulation

# 经验值：
# - SFT: effective_batch_size = 32-128
# - RL(GRPO): effective_batch_size = 128-512
```

### 通信优化

```bash
# 多机多卡时，NCCL 通信可能成为瓶颈
export NCCL_IB_DISABLE=0  # 启用 InfiniBand
export NCCL_P2P_LEVEL=NVL  # 使用 NVLink
```

### Gradient Checkpointing

Unsloth 有自己优化过的 gradient checkpointing：

```python
model = FastLanguageModel.get_peft_model(
    model,
    use_gradient_checkpointing="unsloth",  # 比标准实现节省 ~30% 显存
)
```

## 相关

- [[AI/LLM/Frameworks/Unsloth/Unsloth 概述|Unsloth 概述]]
- [[AI/LLM/Frameworks/Unsloth/训练示例概述|训练示例概述]]
- [[AI/LLM/Infra/分布式训练|分布式训练]]
- [[AI/LLM/Infra/DeepSpeed|DeepSpeed]]
- [[AI/LLM/Infra/FSDP|FSDP]]
