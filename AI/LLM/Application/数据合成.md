---
brief: "数据合成（Prompt 视角）——用 LLM 生成训练数据的 Prompt 工程；Self-Instruct/Evol-Instruct/WizardLM 方法的 prompt 设计；质量过滤策略和 Model Collapse 风险控制。"
title: "数据合成"
type: concept
domain: ai/llm/prompt-engineering
created: "2026-02-13"
updated: "2026-02-13"
tags:
  - ai/llm/prompt-engineering
  - type/concept
---
# 数据合成（Prompt 视角）

用 LLM 生成训练数据是当前最热的 Prompt Engineering 应用场景之一。核心挑战不是"能不能生成"，而是"生成的数据质量够不够"。

## 为什么要用 Prompt 合成数据

1. **人工标注成本高**：一条高质量的 SFT 数据人工标注成本可以到几美元
2. **领域数据稀缺**：医疗、法律等垂直领域的标注数据极难获取
3. **数据多样性**：人工标注容易陷入模式固化，LLM 反而能覆盖更多变体

## 核心 Pipeline

```
种子数据 → Prompt 模板 → LLM 生成 → 质量过滤 → 去重 → 训练集
```

### Step 1: 种子数据准备

种子数据不需要多，但要**高质量且有代表性**：

```python
seeds = [
    {"instruction": "解释什么是 MapReduce", "response": "MapReduce 是一种..."},
    {"instruction": "Spark 和 Flink 的区别", "response": "两者都是..."},
    # 10-50 条即可
]
```

### Step 2: 进化式生成（Evol-Instruct）

WizardLM 提出的 Evol-Instruct 是最经典的方法——通过 prompt 让 LLM 对种子指令做"进化"：

```python
evolve_prompt = """我有一条指令，请用以下方式之一改写，使其更复杂：

1. 增加约束条件
2. 增加推理步骤  
3. 要求处理 edge case
4. 将简单任务变为复合任务

原始指令：{instruction}

改写后的指令（只输出改写结果）：
"""
```

然后用更强的模型（如 GPT-4o / Claude）生成 response。

### Step 3: 质量过滤

生成容易，过滤才是关键。常用策略：

```python
def quality_filter(item):
    # 1. 长度检查
    if len(item["response"]) < 50:
        return False
    
    # 2. 格式检查（是否遵循指令要求的格式）
    if not format_check(item):
        return False
    
    # 3. LLM-as-Judge 打分
    score = judge_llm(f"""
    对以下回答打分（1-5分）：
    问题：{item["instruction"]}
    回答：{item["response"]}
    评分标准：准确性、完整性、有用性
    只输出数字。
    """)
    return int(score) >= 4

    # 4. Reward Model 打分（更准但更贵）
```

### Step 4: 去重

语义级去重比字面去重更重要：

```python
from sentence_transformers import SentenceTransformer
import numpy as np

model = SentenceTransformer("BAAI/bge-large-zh-v1.5")
embeddings = model.encode([d["instruction"] for d in dataset])

# 余弦相似度 > 0.85 视为重复
from sklearn.metrics.pairwise import cosine_similarity
sim_matrix = cosine_similarity(embeddings)
duplicates = set()
for i in range(len(sim_matrix)):
    for j in range(i+1, len(sim_matrix)):
        if sim_matrix[i][j] > 0.85:
            duplicates.add(j)
```

## 实用技巧

- **多模型交叉生成**：用 A 模型生成，B 模型打分，效果好于单模型
- **拒绝采样**：生成 N 条，只取得分最高的 K 条（N/K 通常 3-5x）
- **Persona-driven**：在 prompt 里加入不同角色（学生/工程师/研究员），增加多样性
- **批判式生成**：先生成一版，再让模型自我批评并修改

## 注意事项

⚠️ **模型坍缩**：如果用模型 A 的输出训练模型 A，多轮后会质量退化（Model Collapse）。解决方案是用更强的模型生成，或掺入真实数据。

⚠️ **License 风险**：用 GPT-4 生成的数据训练竞品模型可能违反 ToS，需要关注。

## 相关

- [[AI/LLM/Application/Synthetic-Data/Synthetic Data|Synthetic Data 综述]]
- [[AI/LLM/Application/Synthetic-Data/DataFlow|DataFlow 框架]]
- [[AI/LLM/Frameworks/Unsloth/数据合成|Unsloth 数据合成]]
- [[AI/LLM/SFT/SFT 原理|SFT 原理]]
- [[AI/LLM/Application/Prompt-Engineering-概述|Prompt Engineering 概述]]
