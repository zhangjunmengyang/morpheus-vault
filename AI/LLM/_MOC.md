---
title: "å¤§è¯­è¨€æ¨¡å‹ LLM"
type: moc
domain: ai/llm
tags:
  - ai/llm
  - type/reference
---

# ğŸ§  å¤§è¯­è¨€æ¨¡å‹ LLM

> ä»æ¨¡å‹æ¶æ„åˆ°è®­ç»ƒéƒ¨ç½²çš„ LLM å…¨æ ˆçŸ¥è¯†

## æ¨¡å‹æ¶æ„ (Architecture)
- [[AI/LLM/Architecture/Transformeræ¶æ„æ·±åº¦è§£æ-2026æŠ€æœ¯å…¨æ™¯|Transformer æ¶æ„æ·±åº¦è§£æ 2026]] â­ â€” é¢è¯•ç»ˆææ­¦å™¨ï¼Œ1617è¡Œï¼Œä»æ•°å­¦ç¬¬ä¸€æ€§åŸç†åˆ° MoE/SSM/2026å‰æ²¿å…¨è¦†ç›–ï¼Œé™„ 15+é“éš¾åº¦é€’è¿›é¢è¯•é¢˜+å¿…èƒŒå…¬å¼è¡¨ â˜…â˜…â˜…â˜…â˜…
- [[AI/LLM/Architecture/BERT|BERT]] â€” åŒå‘ç¼–ç å™¨
- [[AI/LLM/Architecture/GPT|GPT]] â€” è‡ªå›å½’ç”Ÿæˆ
- [[AI/LLM/Architecture/T5|T5]] â€” Encoder-Decoder
- [[AI/LLM/Architecture/LLaMA|LLaMA]] â€” Meta å¼€æºç³»åˆ—
- [[AI/LLM/Architecture/Qwen|Qwen]] â€” é˜¿é‡Œé€šä¹‰ç³»åˆ—
- [[AI/Models/Qwen3.5-Plus|Qwen3.5-Plus]] â€” 397B-A17B MoE + Linear Attention
- [[AI/LLM/Architecture/DeepSeek-R1|DeepSeek-R1]] â€” æ¨ç†èƒ½åŠ›çªç ´
- [[AI/LLM/Architecture/Engram-Conditional-Memory-DeepSeek-V4|Engramï¼ˆDeepSeek V4 æ¶æ„ï¼‰]] â€” è®°å¿†ç¨€ç–ç¬¬äºŒè½´ï¼šN-gram åµŒå…¥ O(1) æŸ¥æ‰¾ + MoE è®¡ç®—ç¨€ç–äº’è¡¥ï¼Œ100B å‚æ•°è¡¨å¸è½½ <3% overheadï¼ˆarXiv:2601.07372ï¼Œâ˜…â˜…â˜…â˜…â˜…ï¼‰
- [[AI/LLM/Architecture/MoE æ·±åº¦è§£æ|MoE æ·±åº¦è§£æ]] â€” æ··åˆä¸“å®¶æ¶æ„
- [[AI/LLM/Architecture/Mamba-SSM|Mamba-SSM]] â€” çŠ¶æ€ç©ºé—´æ¨¡å‹
- [[AI/LLM/Architecture/ReFINE-Fast-Weight-RL-Next-Sequence-Prediction|ReFINE]] â€” Fast Weight + GRPOï¼šNSP ç›®æ ‡è§£å†³ NTP ä¸é•¿ç¨‹è®°å¿†çš„ç»“æ„æ€§ mismatchï¼ŒLaCT-760M RULER +8.5~15%ï¼ŒPrinceton ICMLï¼ˆâ˜…â˜…â˜…â˜…â˜†ï¼‰
- [[AI/LLM/Architecture/Growing-to-Looping-Iterative-Computation-Unification|Growing to Looping]] â€” Depth Growing ä¸ Looping ç»Ÿä¸€ç†è®ºï¼šä¸¤è€…éƒ½æ˜¯è¿­ä»£è®¡ç®—çš„å˜ä½“ï¼Œå…ˆ grow å† loop å¯æ¨ç†æ—¶å…è®­ç»ƒè·æœ€é«˜ 2x æå‡ï¼ŒTU Munich + Googleï¼ˆarXiv:2602.16490ï¼Œâ˜…â˜…â˜…â˜…â˜†ï¼‰
- [[Architecture/Transformer æ¶æ„æ¼”è¿› 2026|Transformer æ¶æ„æ¼”è¿› 2026ï¼ˆé¢è¯•æ­¦å™¨ç‰ˆï¼‰]] â€” ä» Vanilla Transformer â†’ MoE â†’ SSM â†’ 2026 å‰æ²¿ï¼Œ817è¡Œï¼Œé¢è¯•åœºæ™¯é©±åŠ¨ï¼ˆè·¯å¾„å¾…è¿ç§»è‡³ AI/LLM/Architecture/ï¼‰
- [[AI/LLM/Architecture/æ¶æ„èŒƒå¼å¯¹æ¯”|æ¶æ„èŒƒå¼å¯¹æ¯”]]
- [[AI/LLM/Architecture/Attention å˜ä½“ç»¼è¿°|Attention å˜ä½“ç»¼è¿°]]
- [[AI/LLM/Architecture/MiniCPM-SALA|MiniCPM-SALA]] â€” Sparse + Linear Attention æ··åˆæ¶æ„ï¼š256K ä¸Šä¸‹æ–‡ 3.5Ã— åŠ é€Ÿï¼Œ1M token æ”¯æŒï¼ˆarXiv 2602.11761ï¼‰
- [[AI/LLM/Architecture/SLA2-Learnable-Router|SLA2]] â€” å¯å­¦ä¹ è·¯ç”±å™¨åŠ¨æ€é€‰ sparse/linear åˆ†æ”¯ï¼šè§†é¢‘ diffusion 97% ç¨€ç–åº¦ + 18.6Ã— attention åŠ é€Ÿï¼ˆarXiv 2602.12675ï¼‰
- [[AI/LLM/Architecture/FlashAttention|FlashAttention]] â€” é«˜æ•ˆæ³¨æ„åŠ›
- [[AI/LLM/Architecture/GQA-MQA|GQA-MQA]] â€” Grouped/Multi-Query Attention
- [[AI/LLM/Architecture/Multi-Head Latent Attention|Multi-Head Latent Attention]]
- [[AI/LLM/Architecture/Manifold-Constrained Hyper-Connections|Manifold-Constrained Hyper-Connections]] â€” æ—©æœŸé¢è¯•ç‰ˆï¼ˆ305è¡Œï¼Œ2026-02-14ï¼‰
- [[AI/LLM/Architecture/mHC-Manifold-Constrained-Hyper-Connections-DeepSeek|mHCï¼ˆDeepSeek V4 æ¶æ„ï¼‰]] â€” æµå½¢çº¦æŸè¶…è¿æ¥æ·±åº¦ç‰ˆï¼šå¤šæµæ®‹å·®æ‹“æ‰‘æ›¿ä»£å•è·¯æ®‹å·®ï¼Œè®­ç»ƒç¨³å®šæ€§++ï¼ŒDeepSeek-AIï¼ˆarXiv:2512.24880ï¼Œâ˜…â˜…â˜…â˜…â˜†ï¼‰
- [[AI/LLM/Architecture/Transformer ä½ç½®ç¼–ç |Transformer ä½ç½®ç¼–ç ]] â€” RoPE ç­‰
- [[AI/LLM/Architecture/Tokenizer|Tokenizer]]
- [[AI/LLM/Architecture/Tokenizer æ·±åº¦ç†è§£|Tokenizer æ·±åº¦ç†è§£]]
- [[AI/LLM/Architecture/é•¿ä¸Šä¸‹æ–‡å¤„ç†|é•¿ä¸Šä¸‹æ–‡å¤„ç†]]
- [[AI/LLM/Architecture/é•¿ä¸Šä¸‹æ–‡æŠ€æœ¯|é•¿ä¸Šä¸‹æ–‡æŠ€æœ¯]]
- [[AI/LLM/Architecture/AI Models Collapse è®ºæ–‡|AI Models Collapse]] â€” é€’å½’è®­ç»ƒåå¡Œ
- [[AI/LLM/Architecture/GLM-5 Agentic Engineering|GLM-5]] â€” ä» Vibe Coding åˆ° Agentic Engineering
- [[AI/LLM/Architecture/LaViDa-R1-Diffusion-LLM-Reasoning|LaViDa-R1]] â€” æ‰©æ•£è¯­è¨€æ¨¡å‹æ¨ç†ï¼šAnswer-Forcing + Tree Search + GRPOï¼ŒAdobe/UCLA/GaTechï¼ˆâ˜…â˜…â˜…â˜…â˜†ï¼‰

## Prompt Engineering
- [[AI/LLM/Prompt-Engineering-2026å®æˆ˜å…¨æ™¯|Prompt Engineering 2026 å®æˆ˜å…¨æ™¯]] â­ â€” 2784è¡Œæ·±åº¦å…¨æ™¯ï¼šCoTÂ·Few-shotÂ·System Promptè®¾è®¡Â·è‡ªåŠ¨ä¼˜åŒ–Â·å¯¹æŠ—é˜²æŠ¤ï¼Œå«å¤§é‡ä»£ç ç¤ºä¾‹ï¼ˆ2026-02-20ï¼‰â˜…â˜…â˜…â˜…â˜…
- [[AI/LLM/Prompt-Engineering/Prompt Engineering|Prompt Engineering]] â€” æç¤ºå·¥ç¨‹
- [[AI/LLM/Prompt-Engineering/Prompt engineering æ¦‚è¿°|Prompt æ¦‚è¿°]]
- [[AI/LLM/Prompt-Engineering/é«˜çº§ Prompt æŠ€å·§|é«˜çº§ Prompt æŠ€å·§]]
- [[AI/LLM/Prompt-Engineering/prompt æ”»å‡»|Prompt æ”»å‡»]] â€” å®‰å…¨å¯¹æŠ—
- [[AI/LLM/Prompt-Engineering/Tools|Prompt å·¥å…·]]
- [[AI/LLM/Prompt-Engineering/æ•°æ®åˆæˆ|æ•°æ®åˆæˆ]]

## ç›‘ç£å¾®è°ƒ SFT
- [[AI/LLM/Training/LLMå¾®è°ƒå®æˆ˜-2026æŠ€æœ¯å…¨æ™¯|LLM å¾®è°ƒå®æˆ˜ 2026 å…¨æ™¯]] â­ â€” é¢è¯•æ­¦å™¨ç‰ˆï¼Œ1850è¡Œï¼ŒSFTâ†’LoRAâ†’QLoRAâ†’RLHFâ†’DPOâ†’GRPOå…¨é“¾è·¯ï¼Œå«å®æˆ˜ä»£ç +å¸¸è§å‘ â˜…â˜…â˜…â˜…â˜…
- [[AI/LLM/SFT/SFT åŸç†|SFT åŸç†]] â€” ç›‘ç£å¾®è°ƒåŸºç¡€
- [[AI/LLM/SFT/SFT-TRLå®è·µ|SFT-TRLå®è·µ]]
- [[AI/LLM/SFT/LoRA|LoRA]] â€” ä½ç§©é€‚åº”
- [[AI/LLM/SFT/PEFT æ–¹æ³•å¯¹æ¯”|PEFT æ–¹æ³•å¯¹æ¯”]]
- [[AI/LLM/SFT/è®­ç»ƒæ•°æ®æ„å»º|è®­ç»ƒæ•°æ®æ„å»º]]
- [[AI/LLM/SFT/Post-Training Unified View è®ºæ–‡|Post-Training ç»Ÿä¸€è§†è§’]]
- [[AI/LLM/SFT/EWC-LoRA-Continual-Learning-Low-Rank|EWC-LoRAï¼ˆæŒç»­å­¦ä¹ +ä½ç§©æ­£åˆ™ï¼‰]] â­ â€” è¯æ˜ç‹¬ç«‹Fisherä¼°è®¡A/Båœ¨bilinearç»“æ„ä¸‹æ•°å­¦ä¸å®Œæ•´ï¼›å…¨ç»´FisheræŠ•å½±åˆ°LoRAç©ºé—´ï¼›å­˜å‚¨æ’å®š+Î»è¿ç»­å¯è°ƒï¼›ICLR 2026ï¼ˆè¥¿å®‰äº¤é€šå¤§å­¦ï¼‰â˜…â˜…â˜…â˜…â˜†

## â­ å¼ºåŒ–å­¦ä¹  RL â†’ [[AI/LLM/RL/_MOC|RL è¯¦ç»† MOC]]
- PPO / GRPO / DPO / DAPO / KTO / RLOO åŠæ›´å¤šç®—æ³•
- TRL / verl / Unsloth / OpenRLHF æ¡†æ¶å®è·µ

## æ¨ç†éƒ¨ç½² (Inference)
- [[AI/LLM/Inference/LLM-æ¨ç†ä¼˜åŒ–-2026-å…¨æ™¯|LLM æ¨ç†ä¼˜åŒ– 2026 å…¨æ™¯]] â€” é¢è¯•æ­¦å™¨ç‰ˆï¼Œ941è¡Œï¼ŒvLLM/TRT-LLM/KV Cache/Speculative Decoding å…¨è¦†ç›–
- [[AI/LLM/Inference/vLLM|vLLM]] â€” é«˜æ€§èƒ½æ¨ç†
- [[AI/LLM/Inference/TensorRT-LLM|TensorRT-LLM]] â€” NVIDIA æ¨ç†ä¼˜åŒ–
- [[AI/LLM/Inference/Ollama|Ollama]] â€” æœ¬åœ°éƒ¨ç½²
- [[AI/LLM/Inference/Test-Time-Compute|Test-Time Compute (TTC)]] â€” æ¨ç†æ—¶æ‰©å±•ç»¼è¿°ï¼šCoT/PRM/Best-of-N/Budget Forcing
- [[AI/LLM/Inference/Gemini-3-Deep-Think|Gemini 3 Deep Think]] â€” ARC-AGI-2 84.6%, TTC scaling
- [[AI/LLM/Inference/Deep-Thinking-Ratio-DTR|Deep-Thinking Ratio (DTR)]] â€” è´¨é‡ > æ•°é‡ï¼šæ·±å±‚ token å æ¯” r=0.828 å‡†ç¡®ç‡ï¼Œæ¨ç¿»"CoT è¶Šé•¿è¶Šå¥½"ï¼ŒUVA+Googleï¼ˆâ˜…â˜…â˜…â˜…â˜†ï¼‰
- [[AI/LLM/Inference/Deep-Thinking-Ratio-DTR-v2-Think-At-N|DTR v2 + Think@N]] â­ â€” ç²¾è¯»å®Œæ•´ç‰ˆï¼š50-token prefix DTR æ¯”å…¨åºåˆ—æ›´å‡†ï¼›Think@N åœ¨ AIME25 å‡†ç¡®ç‡+2%åŒæ—¶æˆæœ¬å‡åŠï¼›"æ¨ç†æ·±åº¦åœ¨å¼€å¤´50 tokenå·²å†³å®š"ï¼ˆâ˜…â˜…â˜…â˜…â˜…ï¼‰
- [[AI/LLM/Inference/KV Cache|KV Cache]] â€” æ¨ç†æ ¸å¿ƒæœºåˆ¶
- [[AI/LLM/Inference/KV Cache ä¼˜åŒ–|KV Cache ä¼˜åŒ–]]
- [[AI/LLM/Inference/DMS KV Cacheå‹ç¼©|DMS KV Cache å‹ç¼©]]
- [[AI/LLM/Inference/Continuous Batching|Continuous Batching]] â€” åŠ¨æ€æ‰¹å¤„ç†
- [[AI/LLM/Inference/Speculative Decoding|Speculative Decoding]] â€” æ¨æµ‹è§£ç 
- [[AI/LLM/Inference/Sparrow-Video-LLM-Speculative-Decoding|Sparrow]] â€” Video LLM æ¨æµ‹è§£ç ï¼šVisual Semantic Internalizationï¼Œ25k visual tokens ä¸‹ 2.82x åŠ é€Ÿï¼ŒNUDTï¼ˆâ˜…â˜…â˜…â˜…â˜†ï¼‰
- [[AI/LLM/Inference/MAGE-Block-Diffusion-LLM-Sparse-Attention|MAGE]] â€” Block Diffusion LLM ç¨€ç–æ³¨æ„åŠ›ï¼šAll-[MASK]ç¬¬ä¸€æ­¥é¢„æµ‹å…¨å±€é‡è¦KVï¼Œ128Kä¸‹åç»­æ­¥6.3xåŠ é€Ÿï¼Œnear-losslessï¼ˆâ˜…â˜…â˜…â˜…â˜†ï¼‰
- [[AI/LLM/Inference/Sink-Aware-Pruning-Diffusion-LLM|Sink-Aware Pruning]] â€” Diffusion LLM æ³¨æ„åŠ› sink æ„ŸçŸ¥å‰ªæï¼šLLaDA ä¸Š 40% å†—ä½™å±‚å¯è£å‰ªï¼ŒMMLU/GSM8K ä»…é™ <0.5%ï¼ŒMBZUAIï¼ˆarXiv:2602.17664ï¼Œâ˜…â˜…â˜…â˜…â˜†ï¼‰
- [[AI/LLM/Inference/Progressive-Thought-Encoding-Cache-Efficient-RL|PTEï¼ˆProgressive Thought Encodingï¼‰]] â­ â€” KV cache æ»¡æ—¶å…ˆå­¦ä¹ å† evictï¼šcross-attention å‹ç¼© evicted token åˆ° LoRA Î”Wï¼Œonline self-distillationï¼›AIME +33%ï¼Œå†…å­˜ -40%ï¼›ICLR 2026ï¼Œå¾®è½¯ç ”ç©¶é™¢ï¼ˆarXiv:2602.16839ï¼‰â˜…â˜…â˜…â˜…â˜…
- [[AI/LLM/Inference/Accordion-Thinking-Self-Regulated-Step-Summaries|Accordion-Thinking]] â€” è®©æ¨¡å‹ç”¨ RL å­¦ä¼šä¸»åŠ¨å‹ç¼©ï¼šæ¯æ­¥ç”Ÿæˆ summary å foldï¼ˆä¸¢å¼ƒåŸå§‹ CoTï¼‰ï¼ŒRL å¼ºåˆ¶ summary æ— æŸï¼›Gap-Vanishing ç°è±¡è¯æ˜å‹ç¼©=ç­‰ä»·ï¼›4Ã— throughput é›¶ç²¾åº¦æŸå¤±ï¼›ICML 2026ï¼ˆarXiv:2602.03249ï¼‰â˜…â˜…â˜…â˜…â˜†
- [[AI/LLM/Inference/æ¨ç†ä¼˜åŒ–|æ¨ç†ä¼˜åŒ–]] â€” ç»¼è¿°
- [[AI/LLM/Inference/ç«¯ä¾§æ¨ç†é‡åŒ–ç²¾åº¦é™·é˜±-è·¨éªé¾™èŠ¯ç‰‡ç²¾åº¦å¤±çœŸ|ç«¯ä¾§é‡åŒ–ç²¾åº¦é™·é˜±]] â€” åŒä¸€ INT8 æ¨¡å‹è·¨ 5 æ¬¾éªé¾™ SoC ç²¾åº¦å·® 20%ï¼›äº‘ç«¯ benchmark å®Œå…¨å¤±çœŸï¼›NPU INT8 ç®—å­å®ç°å·®å¼‚æ ¹å› ï¼›PTQ vs QAT ç«¯ä¾§é€‰å‹å»ºè®®ï¼ˆé¦†é•¿å·¥ç¨‹ç¬”è®°ï¼Œ2026-02-20ï¼‰â˜…â˜…â˜…â˜…â˜†
- [[AI/LLM/Inference/æ¨ç†æœåŠ¡æ¶æ„|æ¨ç†æœåŠ¡æ¶æ„]]
- [[AI/LLM/Inference/æ¨¡å‹éƒ¨ç½²å®è·µ|æ¨¡å‹éƒ¨ç½²å®è·µ]]
- [[AI/LLM/Inference/é‡‡æ ·ç­–ç•¥|é‡‡æ ·ç­–ç•¥]]
- [[AI/LLM/Inference/é‡åŒ–æŠ€æœ¯ç»¼è¿°|é‡åŒ–æŠ€æœ¯ç»¼è¿°]]
- [[AI/LLM/Inference/é‡åŒ–ç»¼è¿°|é‡åŒ–ç»¼è¿°]]
- [[AI/LLM/Inference/å‰ªæä¸è’¸é¦|å‰ªæä¸è’¸é¦]]

## è®­ç»ƒåŸºç¡€è®¾æ–½ (Infra)
- [[AI/LLM/Infra/DeepSpeed|DeepSpeed]] â€” åˆ†å¸ƒå¼è®­ç»ƒä¼˜åŒ–
- [[AI/LLM/Infra/FSDP|FSDP]] â€” PyTorch åŸç”Ÿåˆ†å¸ƒå¼
- [[AI/LLM/Infra/Megatron-LM|Megatron-LM]] â€” å¤§è§„æ¨¡å¹¶è¡Œ
- [[AI/LLM/Infra/Ray|Ray]] â€” åˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶
- [[AI/LLM/Infra/åˆ†å¸ƒå¼è®­ç»ƒ|åˆ†å¸ƒå¼è®­ç»ƒ]] â€” ç»¼è¿°
- [[AI/LLM/Infra/GPU æ˜¾å­˜è®¡ç®—æŒ‡å—|GPU æ˜¾å­˜è®¡ç®—æŒ‡å—]]
- [[AI/LLM/Infra/æ··åˆç²¾åº¦è®­ç»ƒ|æ··åˆç²¾åº¦è®­ç»ƒ]]

## è®­ç»ƒæ¡†æ¶ (Frameworks)
- [[AI/LLM/Frameworks/TRL/TRL æ¦‚è¿°|TRL]] â€” HuggingFace è®­ç»ƒæ¡†æ¶
- [[AI/LLM/Frameworks/OpenRLHF/OpenRLHF|OpenRLHF]]
- [[AI/LLM/Frameworks/Slime-RL-Framework|Slime-RL]] â€” THUDM å¼‚æ­¥ RL Post-Training æ¡†æ¶

### Unsloth
- [[AI/LLM/Frameworks/Unsloth/Unsloth æ¦‚è¿°|Unsloth æ¦‚è¿°]] â€” ä½èµ„æºå¾®è°ƒ
- [[AI/LLM/Frameworks/Unsloth/è®­ç»ƒç¤ºä¾‹æ¦‚è¿°|è®­ç»ƒç¤ºä¾‹æ¦‚è¿°]]
- [[AI/LLM/Frameworks/Unsloth/CPT|CPT]] â€” Continued Pretraining
- [[AI/LLM/Frameworks/Unsloth/Chat Templates|Chat Templates]]
- [[AI/LLM/Frameworks/Unsloth/Checkpoint|Checkpoint]]
- [[AI/LLM/Frameworks/Unsloth/è¿è¡Œ & ä¿å­˜æ¨¡å‹|è¿è¡Œ & ä¿å­˜æ¨¡å‹]]
- [[AI/LLM/Frameworks/Unsloth/é‡åŒ–|é‡åŒ–]]
- [[AI/LLM/Frameworks/Unsloth/é‡åŒ– & æ˜¾å­˜é¢„ä¼°|é‡åŒ– & æ˜¾å­˜é¢„ä¼°]]
- [[AI/LLM/Frameworks/Unsloth/å¤šå¡å¹¶è¡Œ|å¤šå¡å¹¶è¡Œ]]
- [[AI/LLM/Frameworks/Unsloth/æ•°æ®åˆæˆ|æ•°æ®åˆæˆ]]
- [[AI/LLM/Frameworks/Unsloth/notebook åˆé›†|notebook åˆé›†]]
- [[AI/LLM/Frameworks/Unsloth/Gemma 3 è®­ç»ƒ|Gemma 3 è®­ç»ƒ]]
- [[AI/LLM/Frameworks/Unsloth/Qwen3 è®­ç»ƒ|Qwen3 è®­ç»ƒ]]
- [[AI/LLM/Frameworks/Unsloth/gpt-oss è®­ç»ƒ|gpt-oss è®­ç»ƒ]]
- [[AI/LLM/Frameworks/Unsloth/TTS è®­ç»ƒ|TTS è®­ç»ƒ]]

### verl
- [[AI/LLM/Frameworks/verl/verl æ¦‚è¿°|verl æ¦‚è¿°]] â€” å­—èŠ‚ RL æ¡†æ¶
- [[AI/LLM/Frameworks/verl/ç®—æ³•æ¦‚è¿°|ç®—æ³•æ¦‚è¿°]]
- [[AI/LLM/Frameworks/verl/HybridFlow|HybridFlow]] â€” æ ¸å¿ƒæ¶æ„
- [[AI/LLM/Frameworks/verl/verl è®­ç»ƒå‚æ•°|è®­ç»ƒå‚æ•°]]
- [[AI/LLM/Frameworks/verl/é…ç½®æ–‡ä»¶|é…ç½®æ–‡ä»¶]]
- [[AI/LLM/Frameworks/verl/è®­ç»ƒåç«¯|è®­ç»ƒåç«¯]]
- [[AI/LLM/Frameworks/verl/Reward Function|Reward Function]]
- [[AI/LLM/Frameworks/verl/Post-Training æ•°æ®å‡†å¤‡|Post-Training æ•°æ®å‡†å¤‡]]
- [[AI/LLM/Frameworks/verl/RL with Lora|RL with LoRA]]
- [[AI/LLM/Frameworks/verl/Off Policy å¼‚æ­¥è®­ç»ƒå™¨|Off Policy å¼‚æ­¥è®­ç»ƒå™¨]]
- [[AI/LLM/Frameworks/verl/å¤šè½® RL è®­ç»ƒäº¤äº’|å¤šè½® RL è®­ç»ƒäº¤äº’]]
- [[AI/LLM/Frameworks/verl/å®ç°å…¶ä»– RL æ–¹æ³•|å®ç°å…¶ä»– RL æ–¹æ³•]]
- [[AI/LLM/Frameworks/verl/æ€§èƒ½è°ƒä¼˜|æ€§èƒ½è°ƒä¼˜]]
- [[AI/LLM/Frameworks/verl/ç¡¬ä»¶èµ„æºé¢„ä¼°|ç¡¬ä»¶èµ„æºé¢„ä¼°]]
- [[AI/LLM/Frameworks/verl/Sandbox Fusion æ²™ç®±|Sandbox Fusion æ²™ç®±]]
- [[AI/LLM/Frameworks/verl/grafana çœ‹æ¿|Grafana çœ‹æ¿]]

## åº”ç”¨å±‚ (Application)

### Embedding & å‘é‡æ£€ç´¢
- [[AI/LLM/Application/Embedding/Embedding|Embedding]] â€” å‘é‡åŒ–
- [[AI/LLM/Application/Embedding/Embedding é€‰å‹|Embedding é€‰å‹]]
- [[AI/LLM/Application/Embedding ä¸å‘é‡æ£€ç´¢|Embedding ä¸å‘é‡æ£€ç´¢]]
- [[AI/LLM/Application/Embedding/å¤§æ¨¡å‹çº¿ä¸Šæ’æŸ¥ SOP|çº¿ä¸Šæ’æŸ¥ SOP]]

### RAG
- [[AI/LLM/Application/RAG/RAG åŸç†ä¸æ¶æ„|RAG åŸç†ä¸æ¶æ„]]
- [[AI/LLM/Application/RAG/Advanced RAG|Advanced RAG]]
- [[AI/LLM/Application/Advanced RAG|Advanced RAG (æ—§)]]
- [[AI/LLM/Application/RAG å·¥ç¨‹å®è·µ|RAG å·¥ç¨‹å®è·µ]]
- [[AI/LLM/Application/RAG/RAG vs Fine-tuning|RAG vs Fine-tuning]]
- [[AI/LLM/Application/RAG/RAG è¯„æµ‹|RAG è¯„æµ‹]]
- [[AI/LLM/Application/RAG/Reranker|Reranker]]
- [[AI/LLM/Application/RAG/å‘é‡æ•°æ®åº“é€‰å‹|å‘é‡æ•°æ®åº“é€‰å‹]]
- [[AI/LLM/Application/RAG/æ–‡æœ¬åˆ†å—ç­–ç•¥|æ–‡æœ¬åˆ†å—ç­–ç•¥]]
- [[AI/LLM/Application/RAG/æ–‡æ¡£è§£æ|æ–‡æ¡£è§£æ]]
- [[AI/LLM/Application/RAG/æ£€ç´¢ç­–ç•¥|æ£€ç´¢ç­–ç•¥]]

### åˆæˆæ•°æ®
- [[AI/LLM/Application/Synthetic-Data/Synthetic Data|åˆæˆæ•°æ®]]
- [[AI/LLM/Application/Synthetic-Data/DataFlow|DataFlow]]

### ä»£ç ç”Ÿæˆ
- [[AI/LLM/Application/LLMä»£ç ç”Ÿæˆ-2026æŠ€æœ¯å…¨æ™¯|LLM ä»£ç ç”Ÿæˆ 2026 å…¨æ™¯]] â­ â€” é¢è¯•æ­¦å™¨åº“ #17ï¼Œ1083è¡Œï¼šé¢„è®­ç»ƒæ•°æ®å·¥ç¨‹â†’ä»£ç æ¨¡å‹æ¶æ„â†’æ ¸å¿ƒæ¨¡å‹å¯¹æ¯”â†’ä»£ç  RL è®­ç»ƒâ†’å®‰å…¨åˆè§„ï¼ˆ2026-02-20ï¼‰â˜…â˜…â˜…â˜…â˜…

### å…¶ä»–åº”ç”¨
- [[AI/LLM/Application/LLMOps|LLMOps]]
- [[AI/LLM/Application/Prompt Engineering é«˜çº§|Prompt Engineering é«˜çº§]]
- [[AI/LLM/Application/å¹»è§‰é—®é¢˜|å¹»è§‰é—®é¢˜]]

## æ¨¡å‹ç³»åˆ— (Models)
- [[AI/Models/Qwen ç³»åˆ—æ¶æ„|Qwen ç³»åˆ—æ¶æ„]] â€” Qwen ç³»åˆ—æ¨¡å‹æ¶æ„è¯¦è§£

## é¢„è®­ç»ƒ (Pretraining)
- [[AI/LLM/Pretraining/é¢„è®­ç»ƒåŸç†|é¢„è®­ç»ƒåŸç†]]
- [[AI/LLM/Pretraining/LLM-é¢„è®­ç»ƒä¸åˆ†å¸ƒå¼è®­ç»ƒ-2026-å…¨æ™¯|LLM é¢„è®­ç»ƒä¸åˆ†å¸ƒå¼è®­ç»ƒ 2026 å…¨æ™¯]] â€” 2183è¡Œï¼Œè¦†ç›–æ•°æ®å·¥ç¨‹â†’åˆ†å¸ƒå¼è®­ç»ƒâ†’MoEâ†’é•¿ä¸Šä¸‹æ–‡â†’é¢è¯•è€ƒç‚¹ï¼ˆé¢è¯•æ­¦å™¨ç‰ˆï¼‰
- [[AI/LLM/Training/LLMæ•°æ®å·¥ç¨‹2026æŠ€æœ¯å…¨æ™¯|LLM æ•°æ®å·¥ç¨‹ 2026 æŠ€æœ¯å…¨æ™¯]] â€” 3778è¡Œæ·±åº¦ä¸“é¡¹ï¼šé¢„è®­ç»ƒç®¡çº¿Â·åˆæˆæ•°æ®Â·SFTæ„å»ºÂ·è´¨é‡è¯„ä¼°Â·åˆè§„å®‰å…¨ï¼Œå«ä»£ç ç¤ºä¾‹ + 12é“é¢è¯•é¢˜ï¼ˆäº’è¡¥ä¸Šæ–¹å…¨æ™¯ç‰ˆï¼‰

## è®­ç»ƒæŠ€æœ¯ (Training)
- [[AI/LLM/Training/SFT å®æˆ˜æŒ‡å—|SFT å®æˆ˜æŒ‡å—]]
- [[AI/LLM/Training/PEFT æ–¹æ³•ç»¼è¿°|PEFT æ–¹æ³•ç»¼è¿°]]
- [[AI/LLM/Training/æ•°æ®å·¥ç¨‹ for LLM|æ•°æ®å·¥ç¨‹ for LLM]]
- [[AI/LLM/Training/æ¨¡å‹å¹¶è¡Œç­–ç•¥|æ¨¡å‹å¹¶è¡Œç­–ç•¥]]
- [[AI/LLM/Training/æ¨¡å‹è’¸é¦|æ¨¡å‹è’¸é¦]]
- [[AI/LLM/Training/Karpathy nanochat|Karpathy nanochat]] â€” $72 è®­ç»ƒ GPT-2

## æ•ˆç‡ä¸å‹ç¼© (Efficiency & Compression)
- [[AI/LLM/Efficiency/çŸ¥è¯†è’¸é¦ä¸æ¨¡å‹å‹ç¼©-2026æŠ€æœ¯å…¨æ™¯|çŸ¥è¯†è’¸é¦ä¸æ¨¡å‹å‹ç¼© 2026 å…¨æ™¯]] â­ â€” é¢è¯•æ­¦å™¨åº“ #18ï¼Œ2061è¡Œï¼šKD/é‡åŒ–/å‰ªæ/ä½ç§©åˆ†è§£/æ¶æ„æ•ˆç‡/ç«¯ä¾§éƒ¨ç½²å…¨è¦†ç›–ï¼ˆ2026-02-21ï¼‰â˜…â˜…â˜…â˜…â˜…

## è¯„ä¼°ä¸è¶‹åŠ¿ (Evaluation)
- [[AI/LLM/LLMè¯„ä¼°ä¸Benchmark-2026æŠ€æœ¯å…¨æ™¯|LLM è¯„ä¼°ä¸ Benchmark 2026 æŠ€æœ¯å…¨æ™¯]] â­ â€” 1854è¡Œå…¨æ™¯ï¼šBenchmark è®¾è®¡Â·ä¸»æµè¯„æµ‹é›†Â·è‡ªåŠ¨åŒ–è¯„ä¼°Â·å‰æ²¿è¶‹åŠ¿ï¼ˆ2026-02-20ï¼‰â˜…â˜…â˜…â˜…â˜…
- [[AI/LLM/Evaluation/LLM è¯„æµ‹ä½“ç³»|LLM è¯„æµ‹ä½“ç³»]]
- [[AI/LLM/Evaluation/ICLR-2026-è¶‹åŠ¿åˆ†æ|ICLR 2026 è¶‹åŠ¿åˆ†æ]] â€” 5357 ç¯‡ accepted papers è¶‹åŠ¿

## å…¶ä»–
- [[AI/LLM/å°è§„æ¨¡è®­ç»ƒæ‰‹å†Œ|å°è§„æ¨¡è®­ç»ƒæ‰‹å†Œ]] â€” æ„å»ºä¸–ç•Œçº§ LLM çš„ç§˜å¯†
- [[AI/LLM/å¹»è§‰é—®é¢˜ä¸ç¼“è§£|å¹»è§‰é—®é¢˜ä¸ç¼“è§£]]
- [[AI/LLM/LLM è¯„æµ‹ä½“ç³»|LLM è¯„æµ‹ä½“ç³» (æ—§)]]

## ç›¸å…³ MOC
- â†‘ ä¸Šçº§ï¼š[[AI/_MOC]]
- â† å‰ç½®ï¼š[[AI/Foundations/_MOC]]
- â†’ ç›¸å…³ï¼š[[AI/MLLM/_MOC]]ã€[[AI/Agent/_MOC]]
