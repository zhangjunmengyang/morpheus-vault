---
title: "ReAct ä¸ CoT æ¨ç†æ¨¡å¼ï¼šä»æ€ç»´é“¾åˆ°è¡ŒåŠ¨å¾ªç¯"
brief: "ç³»ç»Ÿæ¢³ç†LLMæ¨ç†èŒƒå¼ï¼šChain-of-Thought(Few-shot/Zero-shot)è®©æ¨¡å‹'æ€è€ƒå‡ºå£°'æå‡æ¨ç†èƒ½åŠ›ã€Self-Consistencyå¤šè·¯å¾„æŠ•ç¥¨æé«˜å¯é æ€§ã€ReActå°†æ¨ç†ä¸å·¥å…·äº¤äº’ç»“åˆå®ç°Agenté—­ç¯ã€Tree-of-Thoughtæ ‘å½¢æœç´¢æ¢ç´¢æœ€ä¼˜è§£ã€Reflexionè‡ªæˆ‘åæ€è¿­ä»£æ”¹è¿›ã€‚æ ¸å¿ƒæ´å¯Ÿï¼šCoTè§£å†³'æ€ä¹ˆæƒ³'ï¼ŒReActè§£å†³'æ€ä¹ˆåš'ï¼ŒToTè§£å†³'æƒ³å¤šæ¡è·¯'ï¼ŒReflexionè§£å†³'ä»é”™è¯¯ä¸­å­¦'ã€‚"
tags: [Agent, æ¨ç†, CoT, ReAct, æ€ç»´é“¾, æ¨ç†æ¨¡å¼]
type: survey
domain: ai/agent/reasoning
created: 2026-02-14
updated: "2026-02-22"
status: review
dikw: K
sources:
  - "Chain-of-Thought Prompting â€” Wei et al. arXiv:2201.11903"
  - "ReAct: Synergizing Reasoning and Acting â€” Yao et al. arXiv:2210.03629"
  - "Self-Ask â€” Press et al. arXiv:2210.03350"
  - "Reflexion â€” Shinn et al. arXiv:2303.11366"
  - "Zero-shot CoT ('Let's think step by step') â€” Kojima et al. arXiv:2205.01068"
  - "Self-Consistency â€” Wang et al. arXiv:2203.11171"
  - "Tree of Thoughts â€” Yao et al. arXiv:2305.10601"
  - "Plan-and-Solve â€” Wang et al. arXiv:2305.04091"
related:
  - "[[AI/Agent/Fundamentals/Agent ç”Ÿäº§å®è·µ|Agent ç”Ÿäº§å®è·µ]]"
  - "[[AI/Agent/Fundamentals/Tool Use|Tool Use]]"
  - "[[AI/Agent/AI-Agent-2026-æŠ€æœ¯å…¨æ™¯|AI Agent æŠ€æœ¯å…¨æ™¯]]"
  - "[[AI/LLM/Application/å¹»è§‰é—®é¢˜|å¹»è§‰é—®é¢˜]]"
  - "[[AI/Safety/AIå®‰å…¨ä¸å¯¹é½-2026æŠ€æœ¯å…¨æ™¯|AI å®‰å…¨ä¸å¯¹é½]]"
---

# ReAct ä¸ CoT æ¨ç†æ¨¡å¼ï¼šä»æ€ç»´é“¾åˆ°è¡ŒåŠ¨å¾ªç¯

ç°ä»£ LLM çš„æ¨ç†èƒ½åŠ›ä¸ä»…ä½“ç°åœ¨é—®é¢˜è§£å†³ä¸Šï¼Œæ›´åœ¨äºæ¨ç†è¿‡ç¨‹çš„å¯è§£é‡Šæ€§å’Œç³»ç»Ÿæ€§ã€‚ä» Chain-of-Thought (CoT) çš„æ€ç»´é“¾åˆ° ReAct çš„æ¨ç†-è¡ŒåŠ¨å¾ªç¯ï¼Œå†åˆ°æ›´é«˜çº§çš„ Tree-of-Thoughtï¼Œè¿™äº›æ¨ç†èŒƒå¼ä¸º AI Agent æä¾›äº†å¼ºå¤§çš„è®¤çŸ¥æ¡†æ¶ã€‚

## Chain-of-Thought (CoT) åŸºç¡€

### æ ¸å¿ƒæ¦‚å¿µ

> æ¥æºï¼šWei et al. "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models" arXiv:2201.11903

CoT æ˜¯é€šè¿‡æ˜¾å¼å±•ç¤ºæ¨ç†æ­¥éª¤æ¥æå‡LLMæ¨ç†èƒ½åŠ›çš„æ–¹æ³•ã€‚æ ¸å¿ƒæ€æƒ³æ˜¯"è®©æ¨¡å‹æ€è€ƒå‡ºå£°"ã€‚

```python
class CoTPrompt:
    def __init__(self, task_type="math"):
        self.task_type = task_type
        self.examples = self._get_examples()
    
    def _get_examples(self):
        if self.task_type == "math":
            return [
                {
                    "question": "Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?",
                    "reasoning": "Roger started with 5 tennis balls. 2 cans of 3 tennis balls each is 2 * 3 = 6 tennis balls. 5 + 6 = 11.",
                    "answer": "11"
                },
                {
                    "question": "The cafeteria had 23 apples. If they used 20 to make lunch and bought 6 more, how many apples do they have?",
                    "reasoning": "The cafeteria started with 23 apples. They used 20, so they had 23 - 20 = 3 apples left. They bought 6 more, so they have 3 + 6 = 9 apples now.",
                    "answer": "9"
                }
            ]
        elif self.task_type == "reasoning":
            return [
                {
                    "question": "All birds have wings. Penguins are birds. Do penguins have wings?",
                    "reasoning": "Let me think step by step. The premise states that all birds have wings. The second premise states that penguins are birds. If all birds have wings, and penguins are birds, then by logical deduction, penguins must have wings.",
                    "answer": "Yes, penguins have wings."
                }
            ]
    
    def generate_prompt(self, question):
        """ç”Ÿæˆ Few-shot CoT prompt"""
        prompt = "Let's solve these step by step.\n\n"
        
        # æ·»åŠ ç¤ºä¾‹
        for ex in self.examples:
            prompt += f"Question: {ex['question']}\n"
            prompt += f"Let's think step by step. {ex['reasoning']}\n"
            prompt += f"Answer: {ex['answer']}\n\n"
        
        # æ·»åŠ ç›®æ ‡é—®é¢˜
        prompt += f"Question: {question}\n"
        prompt += "Let's think step by step."
        
        return prompt

# ä½¿ç”¨ç¤ºä¾‹
cot = CoTPrompt("math")
prompt = cot.generate_prompt("A store sold 12 apples in the morning and 8 apples in the afternoon. Each apple costs $0.5. How much money did they make?")
print(prompt)
```

### Zero-shot CoT

> æ¥æºï¼šKojima et al. "Large Language Models are Zero-Shot Reasoners" arXiv:2205.01068 â€” ä»…éœ€ä¸€å¥ "Let's think step by step" å³å¯æ¿€æ´»æ¨ç†èƒ½åŠ›

```python
class ZeroShotCoT:
    """é›¶æ ·æœ¬æ€ç»´é“¾æ¨ç†"""
    
    def __init__(self):
        self.trigger_phrases = [
            "Let's think step by step.",
            "Let's work this out in a step by step way to be sure we have the right answer.",
            "Let's break this down step by step.",
            "Let me think about this step by step."
        ]
    
    def generate_prompt(self, question, trigger="step_by_step"):
        """ç”Ÿæˆé›¶æ ·æœ¬CoTæç¤º"""
        triggers = {
            "step_by_step": "Let's think step by step.",
            "work_out": "Let's work this out in a step by step way to be sure we have the right answer.",
            "break_down": "Let's break this down step by step.",
            "think": "Let me think about this step by step."
        }
        
        prompt = f"{question}\n\n{triggers.get(trigger, triggers['step_by_step'])}"
        return prompt
    
    def extract_answer(self, response):
        """ä»CoTå“åº”ä¸­æå–æœ€ç»ˆç­”æ¡ˆ"""
        import re
        
        # å¯»æ‰¾å¸¸è§çš„ç­”æ¡ˆæ¨¡å¼
        patterns = [
            r"Therefore,?\s*(.+?)\.?\s*$",
            r"So,?\s*(.+?)\.?\s*$",
            r"The answer is\s*(.+?)\.?\s*$",
            r"Answer:\s*(.+?)\.?\s*$",
        ]
        
        for pattern in patterns:
            match = re.search(pattern, response, re.IGNORECASE | re.MULTILINE)
            if match:
                return match.group(1).strip()
        
        # å¦‚æœæ‰¾ä¸åˆ°æ¨¡å¼ï¼Œè¿”å›æœ€åä¸€å¥è¯
        sentences = response.strip().split('.')
        return sentences[-1].strip() if sentences else response

# ä½¿ç”¨ç¤ºä¾‹
zero_shot_cot = ZeroShotCoT()
question = "If a train travels 60 miles per hour for 2.5 hours, how far does it travel?"
prompt = zero_shot_cot.generate_prompt(question)

# æ¨¡æ‹Ÿæ¨¡å‹å“åº”
response = """Let's think step by step.
The train travels at 60 miles per hour.
The train travels for 2.5 hours.
To find the distance, I need to multiply speed by time.
Distance = 60 miles/hour Ã— 2.5 hours = 150 miles.
Therefore, the train travels 150 miles."""

answer = zero_shot_cot.extract_answer(response)
print(f"æå–çš„ç­”æ¡ˆ: {answer}")
```

### Self-Consistency

> æ¥æºï¼šWang et al. "Self-Consistency Improves Chain of Thought Reasoning in Language Models" arXiv:2203.11171

æå‡ CoT å¯é æ€§çš„é‡è¦æŠ€æœ¯ï¼š

```python
import random
from collections import Counter

class SelfConsistency:
    """è‡ªä¸€è‡´æ€§æ¨ç†"""
    
    def __init__(self, num_samples=5):
        self.num_samples = num_samples
    
    def generate_diverse_prompts(self, question):
        """ç”Ÿæˆå¤šæ ·åŒ–çš„CoTæç¤º"""
        templates = [
            f"{question}\nLet's think step by step.",
            f"{question}\nLet me work through this carefully.",
            f"{question}\nI'll solve this step by step.",
            f"{question}\nLet me break this down:",
            f"{question}\nThinking through this problem:"
        ]
        
        return random.sample(templates, min(self.num_samples, len(templates)))
    
    def aggregate_answers(self, responses):
        """èšåˆå¤šä¸ªæ¨ç†è·¯å¾„çš„ç­”æ¡ˆ"""
        answers = []
        
        for response in responses:
            # æå–æ•°å€¼ç­”æ¡ˆï¼ˆç®€åŒ–ç¤ºä¾‹ï¼‰
            import re
            numbers = re.findall(r'-?\d+\.?\d*', response.split('Therefore')[-1])
            if numbers:
                try:
                    answers.append(float(numbers[-1]))
                except ValueError:
                    continue
        
        if not answers:
            return None, 0.0
        
        # æ‰¾åˆ°æœ€å¸¸è§çš„ç­”æ¡ˆ
        answer_counts = Counter(answers)
        most_common = answer_counts.most_common(1)[0]
        confidence = most_common[1] / len(answers)
        
        return most_common[0], confidence
    
    def reason_with_consistency(self, question, model_fn):
        """ä½¿ç”¨è‡ªä¸€è‡´æ€§è¿›è¡Œæ¨ç†"""
        prompts = self.generate_diverse_prompts(question)
        responses = []
        
        for prompt in prompts:
            response = model_fn(prompt)
            responses.append(response)
        
        final_answer, confidence = self.aggregate_answers(responses)
        
        return {
            'answer': final_answer,
            'confidence': confidence,
            'responses': responses,
            'reasoning_paths': len(responses)
        }

# æ¨¡æ‹Ÿä½¿ç”¨
def mock_model(prompt):
    """æ¨¡æ‹Ÿæ¨¡å‹å“åº”"""
    # åœ¨çœŸå®åœºæ™¯ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨å®é™…çš„LLM
    responses = [
        "Step 1: 15 * 4 = 60. Step 2: 60 + 25 = 85. Therefore, the answer is 85.",
        "First, 15 * 4 = 60. Then add 25: 60 + 25 = 85. The answer is 85.",
        "15 * 4 = 60, plus 25 equals 85. So the answer is 85.",
    ]
    return random.choice(responses)

sc = SelfConsistency(num_samples=3)
result = sc.reason_with_consistency(
    "What is 15 * 4 + 25?", 
    mock_model
)
print(f"æœ€ç»ˆç­”æ¡ˆ: {result['answer']}, ç½®ä¿¡åº¦: {result['confidence']:.2f}")
```

## ReActï¼šReasoning + Acting

> æ¥æºï¼šYao et al. "ReAct: Synergizing Reasoning and Acting in Language Models" arXiv:2210.03629

### æ ¸å¿ƒæ¶æ„

ReAct ç»“åˆæ¨ç†å’Œè¡ŒåŠ¨ï¼Œè®©æ¨¡å‹èƒ½å¤Ÿä¸ç¯å¢ƒäº¤äº’ï¼š

```python
import json
from typing import List, Dict, Any
from abc import ABC, abstractmethod

class Tool(ABC):
    """å·¥å…·æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    def execute(self, params: Dict[str, Any]) -> str:
        pass
    
    @abstractmethod
    def description(self) -> str:
        pass

class SearchTool(Tool):
    """æœç´¢å·¥å…·"""
    
    def __init__(self):
        self.knowledge_base = {
            "python": "Python is a high-level programming language.",
            "machine learning": "ML is a method of data analysis that automates analytical model building.",
            "transformer": "Transformer is a deep learning model architecture."
        }
    
    def execute(self, params: Dict[str, Any]) -> str:
        query = params.get("query", "").lower()
        
        for key, value in self.knowledge_base.items():
            if key in query:
                return f"Search result for '{query}': {value}"
        
        return f"No information found for '{query}'"
    
    def description(self) -> str:
        return "search(query: str) - Search for information about a topic"

class CalculatorTool(Tool):
    """è®¡ç®—å™¨å·¥å…·"""
    
    def execute(self, params: Dict[str, Any]) -> str:
        expression = params.get("expression", "")
        try:
            # å®‰å…¨çš„æ•°å­¦è®¡ç®—ï¼ˆå®é™…åº”ç”¨ä¸­éœ€è¦æ›´ä¸¥æ ¼çš„éªŒè¯ï¼‰
            import ast
            import operator
            
            operators = {
                ast.Add: operator.add,
                ast.Sub: operator.sub,
                ast.Mult: operator.mul,
                ast.Div: operator.truediv,
                ast.Pow: operator.pow,
            }
            
            def eval_expr(node):
                if isinstance(node, ast.Num):
                    return node.n
                elif isinstance(node, ast.BinOp):
                    return operators[type(node.op)](eval_expr(node.left), eval_expr(node.right))
                else:
                    raise TypeError(node)
            
            result = eval_expr(ast.parse(expression, mode='eval').body)
            return f"Calculation result: {expression} = {result}"
        
        except Exception as e:
            return f"Error in calculation: {str(e)}"
    
    def description(self) -> str:
        return "calculate(expression: str) - Perform mathematical calculations"

class ReActAgent:
    """ReAct æ¨ç†ä»£ç†"""
    
    def __init__(self, tools: List[Tool], max_iterations=5):
        self.tools = {tool.__class__.__name__.lower().replace('tool', ''): tool for tool in tools}
        self.max_iterations = max_iterations
        self.conversation_history = []
    
    def _format_tools_description(self) -> str:
        """æ ¼å¼åŒ–å·¥å…·æè¿°"""
        descriptions = []
        for name, tool in self.tools.items():
            descriptions.append(f"- {tool.description()}")
        return "\n".join(descriptions)
    
    def _create_react_prompt(self, question: str) -> str:
        """åˆ›å»ºReActæç¤ºæ¨¡æ¿"""
        tools_desc = self._format_tools_description()
        
        prompt = f"""You are a helpful assistant that can use tools to answer questions. You have access to the following tools:

{tools_desc}

Use the following format:
Question: the input question you must answer
Thought: you should always think about what to do
Action: the action to take, should be one of [{', '.join(self.tools.keys())}]
Action Input: the input to the action
Observation: the result of the action
... (this Thought/Action/Action Input/Observation can repeat N times)
Thought: I now know the final answer
Final Answer: the final answer to the original input question

Question: {question}
Thought:"""
        
        return prompt
    
    def _parse_action(self, text: str) -> tuple:
        """è§£æåŠ¨ä½œå’Œè¾“å…¥"""
        import re
        
        # å¯»æ‰¾ Action: å’Œ Action Input: æ¨¡å¼
        action_match = re.search(r'Action:\s*([^\n]+)', text, re.IGNORECASE)
        input_match = re.search(r'Action Input:\s*([^\n]+)', text, re.IGNORECASE)
        
        if action_match and input_match:
            action = action_match.group(1).strip().lower()
            action_input = input_match.group(1).strip()
            return action, action_input
        
        return None, None
    
    def _execute_action(self, action: str, action_input: str) -> str:
        """æ‰§è¡ŒåŠ¨ä½œ"""
        if action in self.tools:
            try:
                # è§£æè¾“å…¥å‚æ•°
                if action == "search":
                    params = {"query": action_input}
                elif action == "calculator":
                    params = {"expression": action_input}
                else:
                    params = {"input": action_input}
                
                return self.tools[action].execute(params)
            except Exception as e:
                return f"Error executing {action}: {str(e)}"
        else:
            return f"Unknown action: {action}. Available actions: {list(self.tools.keys())}"
    
    def solve(self, question: str) -> Dict[str, Any]:
        """ä½¿ç”¨ReActæ¨¡å¼è§£å†³é—®é¢˜"""
        conversation = self._create_react_prompt(question)
        iterations = 0
        
        while iterations < self.max_iterations:
            iterations += 1
            
            # æ¨¡æ‹Ÿæ¨¡å‹å“åº”ï¼ˆå®é™…åº”ç”¨ä¸­ä¼šè°ƒç”¨LLMï¼‰
            response = self._mock_llm_response(conversation, iterations, question)
            conversation += f" {response}\n"
            
            # è§£ææ˜¯å¦åŒ…å«æœ€ç»ˆç­”æ¡ˆ
            if "Final Answer:" in response:
                final_answer = response.split("Final Answer:")[-1].strip()
                return {
                    "answer": final_answer,
                    "conversation": conversation,
                    "iterations": iterations,
                    "success": True
                }
            
            # è§£æå¹¶æ‰§è¡ŒåŠ¨ä½œ
            action, action_input = self._parse_action(response)
            
            if action and action_input:
                observation = self._execute_action(action, action_input)
                conversation += f"Observation: {observation}\nThought:"
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆåŠ¨ä½œï¼Œç»§ç»­æ€è€ƒ
                conversation += "\nThought:"
        
        return {
            "answer": "Unable to solve within maximum iterations",
            "conversation": conversation,
            "iterations": iterations,
            "success": False
        }
    
    def _mock_llm_response(self, conversation: str, iteration: int, question: str) -> str:
        """æ¨¡æ‹ŸLLMå“åº”ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        if "What is 15 * 4 + 25" in question and iteration == 1:
            return "I need to perform a mathematical calculation to solve this problem.\nAction: calculator\nAction Input: 15 * 4 + 25"
        elif "What is 15 * 4 + 25" in question and iteration == 2:
            return "I now know the final answer\nFinal Answer: 85"
        elif "python programming" in question.lower() and iteration == 1:
            return "I should search for information about Python programming.\nAction: search\nAction Input: python programming"
        elif "python programming" in question.lower() and iteration == 2:
            return "I now know the final answer\nFinal Answer: Python is a high-level programming language that is widely used for various applications including web development, data science, and automation."
        else:
            return "Let me think about this problem and determine the best approach."

# ä½¿ç”¨ç¤ºä¾‹
tools = [SearchTool(), CalculatorTool()]
agent = ReActAgent(tools)

# æ•°å­¦é—®é¢˜
math_result = agent.solve("What is 15 * 4 + 25?")
print("æ•°å­¦é—®é¢˜ç»“æœ:")
print(f"ç­”æ¡ˆ: {math_result['answer']}")
print(f"è¿­ä»£æ¬¡æ•°: {math_result['iterations']}\n")

# çŸ¥è¯†é—®ç­”
knowledge_result = agent.solve("Tell me about Python programming")
print("çŸ¥è¯†é—®ç­”ç»“æœ:")
print(f"ç­”æ¡ˆ: {knowledge_result['answer']}")
print(f"è¿­ä»£æ¬¡æ•°: {knowledge_result['iterations']}")
```

### Plan-and-Solve

æ”¹è¿›çš„æ¨ç†æ¨¡å¼ï¼Œå¼ºè°ƒè®¡åˆ’åˆ¶å®šï¼š

```python
class PlanAndSolveAgent:
    """è®¡åˆ’-è§£å†³æ¨ç†ä»£ç†"""
    
    def __init__(self, tools: List[Tool]):
        self.tools = {tool.__class__.__name__.lower().replace('tool', ''): tool for tool in tools}
        self.current_plan = []
        self.execution_log = []
    
    def create_plan(self, question: str) -> List[str]:
        """ä¸ºé—®é¢˜åˆ›å»ºæ‰§è¡Œè®¡åˆ’"""
        # ç®€åŒ–çš„è®¡åˆ’ç”Ÿæˆé€»è¾‘
        if any(op in question for op in ['+', '-', '*', '/', 'calculate', 'compute']):
            plan = [
                "Extract mathematical expression from the question",
                "Use calculator tool to compute the result",
                "Format the final answer"
            ]
        elif any(keyword in question.lower() for keyword in ['what is', 'tell me about', 'explain']):
            plan = [
                "Identify the main topic in the question",
                "Search for relevant information",
                "Synthesize and present the information"
            ]
        else:
            plan = [
                "Analyze the question to understand what's being asked",
                "Determine which tools might be helpful",
                "Execute appropriate actions",
                "Formulate final answer"
            ]
        
        return plan
    
    def solve_with_plan(self, question: str) -> Dict[str, Any]:
        """ä½¿ç”¨è®¡åˆ’-è§£å†³æ¨¡å¼"""
        # ç¬¬ä¸€æ­¥ï¼šåˆ¶å®šè®¡åˆ’
        plan = self.create_plan(question)
        self.current_plan = plan
        
        plan_text = "\n".join([f"{i+1}. {step}" for i, step in enumerate(plan)])
        
        prompt = f"""Question: {question}

Let me first devise a plan to solve this problem:
{plan_text}

Now I'll execute this plan step by step:

Step 1: {plan[0]}"""
        
        # æ¨¡æ‹Ÿæ‰§è¡Œè®¡åˆ’
        conversation = prompt
        final_answer = ""
        
        if "calculate" in question.lower() or any(op in question for op in ['+', '-', '*', '/']):
            # æ•°å­¦é—®é¢˜çš„æ‰§è¡Œ
            import re
            math_expr = re.findall(r'[\d+\-*/\s()]+', question)
            if math_expr:
                calc_tool = self.tools.get('calculator')
                if calc_tool:
                    result = calc_tool.execute({"expression": math_expr[0].strip()})
                    final_answer = result.split("=")[-1].strip() if "=" in result else "Could not calculate"
        
        elif any(keyword in question.lower() for keyword in ['what is', 'tell me about']):
            # çŸ¥è¯†é—®ç­”çš„æ‰§è¡Œ
            search_tool = self.tools.get('search')
            if search_tool:
                # æå–æœç´¢å…³é”®è¯
                keywords = question.lower().replace('what is', '').replace('tell me about', '').strip()
                result = search_tool.execute({"query": keywords})
                final_answer = result
        
        return {
            "answer": final_answer,
            "plan": plan,
            "conversation": conversation,
            "success": bool(final_answer)
        }

# ä½¿ç”¨ç¤ºä¾‹
plan_solve_agent = PlanAndSolveAgent(tools)
result = plan_solve_agent.solve_with_plan("What is 12 * 8 + 5?")
print("Plan-and-Solve ç»“æœ:")
print(f"è®¡åˆ’: {result['plan']}")
print(f"ç­”æ¡ˆ: {result['answer']}")
```

## Tree-of-Thought (ToT)

### æ ‘å½¢æœç´¢æ¨ç†

```python
from typing import List, Tuple
import heapq

class ThoughtNode:
    """æ€ç»´èŠ‚ç‚¹"""
    
    def __init__(self, thought: str, parent=None, depth=0):
        self.thought = thought
        self.parent = parent
        self.children = []
        self.depth = depth
        self.score = 0.0
        self.is_solution = False
    
    def add_child(self, child_thought: str):
        child = ThoughtNode(child_thought, parent=self, depth=self.depth + 1)
        self.children.append(child)
        return child
    
    def get_path(self) -> List[str]:
        """è·å–ä»æ ¹åˆ°å½“å‰èŠ‚ç‚¹çš„è·¯å¾„"""
        path = []
        current = self
        while current:
            path.append(current.thought)
            current = current.parent
        return path[::-1]

class TreeOfThought:
    """æ€ç»´æ ‘æ¨ç†"""
    
    def __init__(self, max_depth=4, beam_width=3):
        self.max_depth = max_depth
        self.beam_width = beam_width
    
    def generate_thoughts(self, current_thought: str, problem: str) -> List[str]:
        """ç”Ÿæˆå€™é€‰æ€ç»´ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        if "24" in problem and "8 3 8 3" in problem:
            # 24ç‚¹æ¸¸æˆç¤ºä¾‹
            if current_thought == "Start":
                return [
                    "Try 8 + 3 = 11",
                    "Try 8 - 3 = 5", 
                    "Try 8 * 3 = 24"
                ]
            elif "8 + 3 = 11" in current_thought:
                return [
                    "11 + 8 = 19, then 19 + 3 = 22 (not 24)",
                    "11 - 8 = 3, then 3 * 3 = 9 (not 24)",
                    "11 * 3 = 33, then 33 - 8 = 25 (close!)"
                ]
            elif "8 - 3 = 5" in current_thought:
                return [
                    "5 + 8 = 13, then 13 + 3 = 16 (not 24)",
                    "5 * 8 = 40, then 40 - 3 = 37 (not 24)",
                    "(8 - 3) * 3 = 15, then 15 + 8 = 23 (close!)"
                ]
            elif "8 * 3 = 24" in current_thought:
                return [
                    "Found solution: 8 * 3 = 24, other 8,3 unused",
                    "This uses all numbers correctly"
                ]
        
        return ["Continue thinking..."]
    
    def evaluate_thought(self, thought: str, problem: str) -> float:
        """è¯„ä¼°æ€ç»´çš„è´¨é‡ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        if "solution" in thought.lower():
            return 1.0
        elif "24" in thought:
            return 0.8
        elif "close" in thought:
            return 0.6
        elif any(op in thought for op in ['+', '-', '*', '/']):
            return 0.4
        else:
            return 0.2
    
    def search(self, problem: str) -> Tuple[str, List[str]]:
        """ä½¿ç”¨BFSæœç´¢æ€ç»´æ ‘"""
        root = ThoughtNode("Start")
        queue = [(0, root)]  # (negative_score, node) for max-heap behavior
        best_solution = None
        
        while queue and len(queue) < 100:  # é™åˆ¶æœç´¢è§„æ¨¡
            _, current_node = heapq.heappop(queue)
            
            if current_node.depth >= self.max_depth:
                continue
            
            # ç”Ÿæˆå­æ€ç»´
            candidate_thoughts = self.generate_thoughts(current_node.thought, problem)
            
            for thought in candidate_thoughts[:self.beam_width]:
                child = current_node.add_child(thought)
                child.score = self.evaluate_thought(thought, problem)
                
                # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°è§£å†³æ–¹æ¡ˆ
                if child.score >= 0.9 or "solution" in thought.lower():
                    child.is_solution = True
                    if not best_solution or child.score > best_solution.score:
                        best_solution = child
                
                # å°†æœ‰å‰é€”çš„èŠ‚ç‚¹åŠ å…¥é˜Ÿåˆ—
                if child.score > 0.3:
                    heapq.heappush(queue, (-child.score, child))
        
        if best_solution:
            return best_solution.thought, best_solution.get_path()
        else:
            return "No solution found", []

# ä½¿ç”¨ç¤ºä¾‹
tot = TreeOfThought(max_depth=3, beam_width=3)
solution, path = tot.search("Use numbers 8, 3, 8, 3 exactly once to make 24")

print("Tree-of-Thought ç»“æœ:")
print(f"è§£å†³æ–¹æ¡ˆ: {solution}")
print("æ¨ç†è·¯å¾„:")
for i, step in enumerate(path):
    print(f"  {i+1}. {step}")
```

## Reflexionï¼šè‡ªæˆ‘åæ€

> æ¥æºï¼šShinn et al. "Reflexion: Language Agents with Verbal Reinforcement Learning" arXiv:2303.11366

```python
class ReflexionAgent:
    """å…·æœ‰è‡ªæˆ‘åæ€èƒ½åŠ›çš„ä»£ç†"""
    
    def __init__(self, max_trials=3):
        self.max_trials = max_trials
        self.memory = []  # å­˜å‚¨å¤±è´¥çš„å°è¯•å’Œåæ€
    
    def attempt_solution(self, problem: str, trial: int) -> Dict[str, Any]:
        """å°è¯•è§£å†³é—®é¢˜"""
        if trial == 1:
            # ç¬¬ä¸€æ¬¡å°è¯•ï¼šç›´æ¥æ¨ç†
            response = self._direct_reasoning(problem)
        else:
            # åç»­å°è¯•ï¼šåŸºäºåæ€çš„æ¨ç†
            response = self._reasoning_with_reflection(problem, trial)
        
        return response
    
    def _direct_reasoning(self, problem: str) -> Dict[str, Any]:
        """ç›´æ¥æ¨ç†ï¼ˆç¬¬ä¸€æ¬¡å°è¯•ï¼‰"""
        if "24" in problem and "8 3 8 3" in problem:
            reasoning = "Let me try: 8 + 8 = 16, 16 + 3 = 19, 19 + 3 = 22. That's not 24."
            answer = "22"
            confidence = 0.3
        else:
            reasoning = "Let me think about this problem step by step."
            answer = "I need more information"
            confidence = 0.1
        
        return {
            "reasoning": reasoning,
            "answer": answer,
            "confidence": confidence,
            "success": confidence > 0.8
        }
    
    def _reasoning_with_reflection(self, problem: str, trial: int) -> Dict[str, Any]:
        """åŸºäºåæ€çš„æ¨ç†"""
        # å›é¡¾ä¹‹å‰çš„å¤±è´¥
        previous_attempts = [mem for mem in self.memory if mem['problem'] == problem]
        
        reflection = self._generate_reflection(previous_attempts)
        
        if "24" in problem and trial == 2:
            reasoning = f"Previous reflection: {reflection}\nLet me try multiplication: 8 * 3 = 24. That works! The other 8 and 3 can be: (8-3) doesn't matter since 8*3 already gives 24."
            answer = "8 * 3 = 24"
            confidence = 0.9
        elif "24" in problem and trial >= 3:
            reasoning = f"Reflecting on attempts: {reflection}\nCorrect approach: Use (8Ã·8+3)Ã—3 = (1+3)Ã—3 = 4Ã—3 = 12. Wait, that's still wrong. Actually: 8Ã·(3-8Ã·3) isn't valid. Let me try: 8Ã—3Ã—(8-3) won't work... Actually: 8Ã—3=24 exactly!"
            answer = "8 Ã— 3 = 24 (using just two of the four numbers)"
            confidence = 0.95
        else:
            reasoning = f"Reflecting: {reflection}. I need a different approach."
            answer = "Still working on it"
            confidence = 0.4
        
        return {
            "reasoning": reasoning,
            "answer": answer,
            "confidence": confidence,
            "success": confidence > 0.8,
            "reflection": reflection
        }
    
    def _generate_reflection(self, previous_attempts: List[Dict]) -> str:
        """ç”Ÿæˆåæ€"""
        if not previous_attempts:
            return "This is my first attempt."
        
        failures = [att for att in previous_attempts if not att.get('success', False)]
        
        reflection_points = []
        for failure in failures:
            if "add" in failure.get('reasoning', '').lower():
                reflection_points.append("Addition alone didn't work")
            if "22" in str(failure.get('answer', '')):
                reflection_points.append("Got 22, need 2 more - maybe try multiplication")
        
        if reflection_points:
            return "; ".join(reflection_points)
        else:
            return "Previous approaches were unsuccessful, need new strategy"
    
    def solve_with_reflection(self, problem: str) -> Dict[str, Any]:
        """ä½¿ç”¨åæ€å¾ªç¯è§£å†³é—®é¢˜"""
        for trial in range(1, self.max_trials + 1):
            print(f"\n--- Trial {trial} ---")
            
            result = self.attempt_solution(problem, trial)
            
            # è®°å½•è¿™æ¬¡å°è¯•
            attempt_record = {
                'problem': problem,
                'trial': trial,
                'reasoning': result['reasoning'],
                'answer': result['answer'],
                'confidence': result['confidence'],
                'success': result['success']
            }
            self.memory.append(attempt_record)
            
            print(f"æ¨ç†: {result['reasoning']}")
            print(f"ç­”æ¡ˆ: {result['answer']}")
            print(f"ç½®ä¿¡åº¦: {result['confidence']:.2f}")
            
            if result['success']:
                return {
                    'final_answer': result['answer'],
                    'trials_used': trial,
                    'success': True,
                    'all_attempts': self.memory
                }
        
        return {
            'final_answer': "Could not solve within maximum trials",
            'trials_used': self.max_trials,
            'success': False,
            'all_attempts': self.memory
        }

# ä½¿ç”¨ç¤ºä¾‹
reflexion_agent = ReflexionAgent(max_trials=3)
result = reflexion_agent.solve_with_reflection("Use 8, 3, 8, 3 exactly once each to make 24")

print(f"\n=== æœ€ç»ˆç»“æœ ===")
print(f"ç­”æ¡ˆ: {result['final_answer']}")
print(f"ä½¿ç”¨å°è¯•æ¬¡æ•°: {result['trials_used']}")
print(f"æˆåŠŸ: {result['success']}")
```

## æ¨ç†æ¨¡å¼å¯¹æ¯”ä¸é€‰æ‹©

### æ€§èƒ½å¯¹æ¯”

```python
import pandas as pd
import matplotlib.pyplot as plt

def compare_reasoning_methods():
    """å¯¹æ¯”ä¸åŒæ¨ç†æ–¹æ³•çš„æ€§èƒ½"""
    
    # æ¨¡æ‹Ÿå®éªŒæ•°æ®
    methods = ['Standard', 'CoT', 'Zero-shot CoT', 'ReAct', 'Plan-Solve', 'Tree-of-Thought', 'Reflexion']
    
    # ä¸åŒä»»åŠ¡ç±»å‹çš„æ€§èƒ½
    performance_data = {
        'æ•°å­¦æ¨ç†': [60, 78, 71, 82, 85, 89, 87],
        'é€»è¾‘æ¨ç†': [55, 72, 68, 80, 83, 91, 88],
        'å¸¸è¯†æ¨ç†': [70, 82, 79, 85, 84, 86, 89],
        'å¤šæ­¥æ¨ç†': [45, 65, 58, 88, 90, 94, 92],
        'å·¥å…·ä½¿ç”¨': [30, 35, 32, 95, 88, 78, 85]
    }
    
    df = pd.DataFrame(performance_data, index=methods)
    
    # å¯è§†åŒ–
    fig, ax = plt.subplots(figsize=(12, 8))
    df.plot(kind='bar', ax=ax, width=0.8)
    ax.set_title('ä¸åŒæ¨ç†æ–¹æ³•åœ¨å„ç±»ä»»åŠ¡ä¸Šçš„æ€§èƒ½å¯¹æ¯”')
    ax.set_xlabel('æ¨ç†æ–¹æ³•')
    ax.set_ylabel('æ€§èƒ½åˆ†æ•°')
    ax.legend(title='ä»»åŠ¡ç±»å‹', bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.show()
    
    return df

# è¿è¡Œå¯¹æ¯”
performance_df = compare_reasoning_methods()
print("æ€§èƒ½å¯¹æ¯”è¡¨:")
print(performance_df)
```

### é€‰æ‹©æŒ‡å—

```python
class ReasoningMethodSelector:
    """æ¨ç†æ–¹æ³•é€‰æ‹©å™¨"""
    
    def __init__(self):
        self.method_profiles = {
            'CoT': {
                'strengths': ['æå‡å¤æ‚æ¨ç†', 'å¯è§£é‡Šæ€§å¥½', 'ç®€å•å®ç°'],
                'weaknesses': ['éœ€è¦ç¤ºä¾‹', 'ä¾èµ–æç¤ºè´¨é‡'],
                'best_for': ['æ•°å­¦é—®é¢˜', 'é€»è¾‘æ¨ç†', 'æ­¥éª¤æ¸…æ™°çš„ä»»åŠ¡'],
                'computational_cost': 'Low',
                'accuracy_gain': 'Medium'
            },
            'Zero-shot CoT': {
                'strengths': ['æ— éœ€ç¤ºä¾‹', 'é€šç”¨æ€§å¼º', 'ç®€å•è§¦å‘'],
                'weaknesses': ['æ•ˆæœä¸å¦‚Few-shot', 'å¯èƒ½ç”Ÿæˆæ— å…³å†…å®¹'],
                'best_for': ['å¿«é€ŸåŸå‹', 'æœªçŸ¥é¢†åŸŸ', 'èµ„æºå—é™åœºæ™¯'],
                'computational_cost': 'Low',
                'accuracy_gain': 'Low-Medium'
            },
            'ReAct': {
                'strengths': ['å·¥å…·é›†æˆ', 'å®é™…è¡ŒåŠ¨èƒ½åŠ›', 'çµæ´»äº¤äº’'],
                'weaknesses': ['éœ€è¦å·¥å…·ç¯å¢ƒ', 'å¯èƒ½é™·å…¥å¾ªç¯'],
                'best_for': ['éœ€è¦å¤–éƒ¨ä¿¡æ¯', 'å·¥å…·ä½¿ç”¨', 'å®æ—¶äº¤äº’'],
                'computational_cost': 'Medium',
                'accuracy_gain': 'High'
            },
            'Plan-and-Solve': {
                'strengths': ['ç»“æ„åŒ–æ€è€ƒ', 'å¤æ‚ä»»åŠ¡åˆ†è§£', 'é«˜å‡†ç¡®ç‡'],
                'weaknesses': ['è®¡åˆ’å¯èƒ½ä¸å‡†ç¡®', 'å®ç°å¤æ‚'],
                'best_for': ['å¤šæ­¥éª¤ä»»åŠ¡', 'å¤æ‚é—®é¢˜', 'éœ€è¦è§„åˆ’'],
                'computational_cost': 'Medium',
                'accuracy_gain': 'High'
            },
            'Tree-of-Thought': {
                'strengths': ['æ¢ç´¢å¤šç§è·¯å¾„', 'æœ€é«˜å‡†ç¡®ç‡', 'ç³»ç»Ÿæ€§å¼º'],
                'weaknesses': ['è®¡ç®—å¼€é”€å¤§', 'å®ç°å¤æ‚', 'é€Ÿåº¦æ…¢'],
                'best_for': ['åˆ›æ„ä»»åŠ¡', 'æ¸¸æˆæ±‚è§£', 'å…³é”®å†³ç­–'],
                'computational_cost': 'High',
                'accuracy_gain': 'Very High'
            },
            'Reflexion': {
                'strengths': ['è‡ªæˆ‘æ”¹è¿›', 'å­¦ä¹ å¤±è´¥', 'é€‚åº”æ€§å¼º'],
                'weaknesses': ['éœ€è¦å¤šè½®äº¤äº’', 'å¯èƒ½è¿‡æ‹Ÿåˆ'],
                'best_for': ['è¿­ä»£ä¼˜åŒ–', 'å­¦ä¹ åœºæ™¯', 'é•¿æœŸä»»åŠ¡'],
                'computational_cost': 'High',
                'accuracy_gain': 'High'
            }
        }
    
    def recommend_method(self, task_type: str, constraints: Dict[str, str]) -> str:
        """æ¨èæ¨ç†æ–¹æ³•"""
        computational_budget = constraints.get('computational_budget', 'medium').lower()
        accuracy_requirement = constraints.get('accuracy_requirement', 'medium').lower()
        has_tools = constraints.get('has_tools', 'no').lower() == 'yes'
        iterative_improvement = constraints.get('iterative_improvement', 'no').lower() == 'yes'
        
        # å†³ç­–é€»è¾‘
        if has_tools:
            return 'ReAct'
        elif computational_budget == 'low':
            if accuracy_requirement == 'high':
                return 'Zero-shot CoT'
            else:
                return 'CoT'
        elif accuracy_requirement == 'very_high':
            if computational_budget == 'high':
                return 'Tree-of-Thought'
            else:
                return 'Plan-and-Solve'
        elif iterative_improvement:
            return 'Reflexion'
        elif 'multi-step' in task_type.lower() or 'complex' in task_type.lower():
            return 'Plan-and-Solve'
        else:
            return 'CoT'
    
    def explain_choice(self, method: str) -> str:
        """è§£é‡Šé€‰æ‹©ç†ç”±"""
        profile = self.method_profiles.get(method, {})
        
        explanation = f"""
æ¨èæ–¹æ³•: {method}

ä¼˜åŠ¿:
{chr(10).join(f'â€¢ {strength}' for strength in profile.get('strengths', []))}

æœ€é€‚åˆ:
{chr(10).join(f'â€¢ {use_case}' for use_case in profile.get('best_for', []))}

è®¡ç®—æˆæœ¬: {profile.get('computational_cost', 'Unknown')}
å‡†ç¡®ç‡æå‡: {profile.get('accuracy_gain', 'Unknown')}
"""
        return explanation

# ä½¿ç”¨ç¤ºä¾‹
selector = ReasoningMethodSelector()

# åœºæ™¯1ï¼šæ•°å­¦é—®é¢˜ï¼Œä½è®¡ç®—é¢„ç®—
constraints1 = {
    'computational_budget': 'low',
    'accuracy_requirement': 'medium',
    'has_tools': 'no'
}
method1 = selector.recommend_method('æ•°å­¦æ¨ç†', constraints1)
print("åœºæ™¯1 - æ•°å­¦é—®é¢˜ (ä½é¢„ç®—):")
print(selector.explain_choice(method1))

# åœºæ™¯2ï¼šéœ€è¦ä½¿ç”¨å·¥å…·
constraints2 = {
    'computational_budget': 'medium',
    'accuracy_requirement': 'high',
    'has_tools': 'yes'
}
method2 = selector.recommend_method('ä¿¡æ¯æŸ¥è¯¢', constraints2)
print("\nåœºæ™¯2 - ä¿¡æ¯æŸ¥è¯¢ (æœ‰å·¥å…·):")
print(selector.explain_choice(method2))
```

## é¢è¯•å¸¸è§é—®é¢˜

### Q1ï¼šCoTã€ReActã€Tree-of-Thought çš„æ ¸å¿ƒåŒºåˆ«æ˜¯ä»€ä¹ˆï¼Ÿ

**ç­”æ¡ˆ**ï¼š

**Chain-of-Thought (CoT)**ï¼š
- æ ¸å¿ƒï¼šæ˜¾å¼å±•ç¤ºæ¨ç†æ­¥éª¤
- æœºåˆ¶ï¼šçº¿æ€§çš„æ€ç»´é“¾ï¼Œä¸€æ­¥æ¥ä¸€æ­¥
- é€‚ç”¨ï¼šæ•°å­¦æ¨ç†ã€é€»è¾‘é—®é¢˜
- ä¼˜åŠ¿ï¼šç®€å•æœ‰æ•ˆï¼Œå¯è§£é‡Šæ€§å¼º
- å±€é™ï¼šæ— æ³•ä¸ç¯å¢ƒäº¤äº’ï¼Œè·¯å¾„å•ä¸€

**ReAct (Reasoning + Acting)**ï¼š
- æ ¸å¿ƒï¼šæ¨ç†ä¸è¡ŒåŠ¨çš„äº¤æ›¿å¾ªç¯
- æœºåˆ¶ï¼šThought â†’ Action â†’ Observation å¾ªç¯
- é€‚ç”¨ï¼šéœ€è¦å¤–éƒ¨ä¿¡æ¯æˆ–å·¥å…·çš„ä»»åŠ¡
- ä¼˜åŠ¿ï¼šèƒ½å¤Ÿä¸ç¯å¢ƒäº¤äº’ï¼Œä¿¡æ¯è·å–èƒ½åŠ›å¼º
- å±€é™ï¼šå¯èƒ½é™·å…¥åŠ¨ä½œå¾ªç¯ï¼Œä¾èµ–å·¥å…·è´¨é‡

**Tree-of-Thought (ToT)**ï¼š
- æ ¸å¿ƒï¼šæ¢ç´¢å¤šæ¡æ¨ç†è·¯å¾„çš„æ ‘å½¢æœç´¢
- æœºåˆ¶ï¼šå¹¿åº¦/æ·±åº¦ä¼˜å…ˆæœç´¢æ€ç»´ç©ºé—´
- é€‚ç”¨ï¼šåˆ›æ„ä»»åŠ¡ã€å¤æ‚è§„åˆ’ã€æ¸¸æˆæ±‚è§£
- ä¼˜åŠ¿ï¼šæ¢ç´¢å……åˆ†ï¼Œæ‰¾åˆ°æœ€ä¼˜è§£æ¦‚ç‡é«˜
- å±€é™ï¼šè®¡ç®—å¼€é”€å¤§ï¼Œå®ç°å¤æ‚

### Q2ï¼šåœ¨ä»€ä¹ˆæƒ…å†µä¸‹åº”è¯¥é€‰æ‹© Zero-shot CoT è€Œé Few-shot CoTï¼Ÿ

**ç­”æ¡ˆ**ï¼š

**é€‰æ‹© Zero-shot CoT çš„åœºæ™¯**ï¼š
1. **ç¼ºä¹ç¤ºä¾‹æ•°æ®**ï¼šæ–°é¢†åŸŸæˆ–æœªè§è¿‡çš„ä»»åŠ¡ç±»å‹
2. **å¿«é€ŸåŸå‹å¼€å‘**ï¼šéœ€è¦å¿«é€ŸéªŒè¯æƒ³æ³•
3. **é€šç”¨æ€§è¦æ±‚é«˜**ï¼šä¸€å¥—æç¤ºé€‚ç”¨å¤šç§ä»»åŠ¡
4. **ç¤ºä¾‹æ„é€ æˆæœ¬é«˜**ï¼šä¸“å®¶æ—¶é—´å®è´µæˆ–ç¤ºä¾‹éš¾è·å–
5. **é¿å…ç¤ºä¾‹åå·®**ï¼šæ‹…å¿ƒç¤ºä¾‹é™åˆ¶æ¨¡å‹æ€è·¯

**Zero-shot CoT çš„å®ç°**ï¼š
```python
# ç®€å•ä½†æœ‰æ•ˆçš„Zero-shotè§¦å‘
def zero_shot_cot_prompt(question):
    return f"{question}\n\nLet's think step by step."

# æ›´sophisticatedçš„ç‰ˆæœ¬
def advanced_zero_shot_cot(question, domain_hint=None):
    if domain_hint:
        return f"{question}\n\nAs an expert in {domain_hint}, let me think through this step by step."
    else:
        return f"{question}\n\nLet me break this down systematically:"
```

**ç»éªŒæ³•åˆ™**ï¼š
- æ¨¡å‹èƒ½åŠ›è¶³å¤Ÿå¼ºæ—¶ï¼ˆGPT-4çº§åˆ«ï¼‰ï¼ŒZero-shot CoT æ•ˆæœæ¥è¿‘ Few-shot
- ç®€å•ä»»åŠ¡ä¼˜é€‰ Zero-shotï¼Œå¤æ‚ä»»åŠ¡è€ƒè™‘ Few-shot
- ç”Ÿäº§ç¯å¢ƒå¯ä»¥å…ˆ Zero-shot åŸå‹ï¼Œå†ä¼˜åŒ–ä¸º Few-shot

### Q3ï¼šReAct æ¨¡å¼ä¸­å¦‚ä½•é˜²æ­¢ Agent é™·å…¥å·¥å…·è°ƒç”¨å¾ªç¯ï¼Ÿ

**ç­”æ¡ˆ**ï¼š

**å¸¸è§å¾ªç¯é—®é¢˜**ï¼š
1. **é‡å¤æœç´¢**ï¼šä¸æ–­æœç´¢ç›¸åŒå…³é”®è¯
2. **æ— æ•ˆå·¥å…·é“¾**ï¼šå·¥å…·è¾“å‡ºä¸èƒ½æ¨è¿›ä»»åŠ¡è¿›å±•
3. **é”™è¯¯åé¦ˆå¾ªç¯**ï¼šé”™è¯¯ç†è§£å·¥å…·è¾“å‡ºï¼Œå¯¼è‡´é”™è¯¯çš„ä¸‹ä¸€æ­¥

**é˜²æŠ¤æœºåˆ¶**ï¼š

```python
class SafeReActAgent:
    def __init__(self, tools, max_iterations=10, loop_detection=True):
        self.tools = tools
        self.max_iterations = max_iterations
        self.loop_detection = loop_detection
        self.action_history = []
        self.tool_usage_count = {}
    
    def detect_loop(self, action, action_input):
        """æ£€æµ‹åŠ¨ä½œå¾ªç¯"""
        recent_actions = self.action_history[-3:]  # æ£€æŸ¥æœ€è¿‘3ä¸ªåŠ¨ä½œ
        current_action = f"{action}:{action_input}"
        
        # æ£€æŸ¥é‡å¤åŠ¨ä½œ
        if recent_actions.count(current_action) >= 2:
            return True
        
        # æ£€æŸ¥å·¥å…·è¿‡åº¦ä½¿ç”¨
        if self.tool_usage_count.get(action, 0) >= 5:
            return True
        
        return False
    
    def execute_with_safeguards(self, action, action_input):
        """å¸¦å®‰å…¨é˜²æŠ¤çš„æ‰§è¡Œ"""
        if self.loop_detection and self.detect_loop(action, action_input):
            return "LOOP_DETECTED: Switching to alternative approach"
        
        # è®°å½•åŠ¨ä½œ
        self.action_history.append(f"{action}:{action_input}")
        self.tool_usage_count[action] = self.tool_usage_count.get(action, 0) + 1
        
        # æ‰§è¡Œå·¥å…·
        return self.tools[action].execute({"input": action_input})
```

**æœ€ä½³å®è·µ**ï¼š
1. **è®¾ç½®æœ€å¤§è¿­ä»£æ•°**ï¼šé˜²æ­¢æ— é™å¾ªç¯
2. **åŠ¨ä½œå†å²è·Ÿè¸ª**ï¼šæ£€æµ‹é‡å¤æ¨¡å¼
3. **å·¥å…·ä½¿ç”¨é™åˆ¶**ï¼šå•ä¸ªå·¥å…·è°ƒç”¨æ¬¡æ•°ä¸Šé™
4. **è¿›åº¦è¯„ä¼°**ï¼šæ¯æ­¥è¯„ä¼°æ˜¯å¦å‘ç›®æ ‡å‰è¿›
5. **å¤‡é€‰ç­–ç•¥**ï¼šæ£€æµ‹åˆ°å¾ªç¯æ—¶åˆ‡æ¢æ–¹æ³•

### Q4ï¼šå¦‚ä½•è¯„ä¼°å’Œæ¯”è¾ƒä¸åŒæ¨ç†æ–¹æ³•çš„æ•ˆæœï¼Ÿ

**ç­”æ¡ˆ**ï¼š

**è¯„ä¼°ç»´åº¦**ï¼š

1. **å‡†ç¡®ç‡ (Accuracy)**ï¼š
```python
def evaluate_accuracy(predictions, ground_truth):
    correct = sum(p == gt for p, gt in zip(predictions, ground_truth))
    return correct / len(predictions)
```

2. **æ¨ç†è´¨é‡ (Reasoning Quality)**ï¼š
- æ¨ç†æ­¥éª¤çš„é€»è¾‘æ€§
- ä¸­é—´ç»“æœçš„æ­£ç¡®æ€§
- é”™è¯¯ä¼ æ’­åˆ†æ

3. **æ•ˆç‡æŒ‡æ ‡**ï¼š
```python
def evaluate_efficiency(method_stats):
    return {
        'avg_tokens': method_stats['total_tokens'] / method_stats['total_queries'],
        'avg_time': method_stats['total_time'] / method_stats['total_queries'],
        'tool_calls': method_stats['total_tool_calls'] / method_stats['total_queries']
    }
```

4. **é²æ£’æ€§æµ‹è¯•**ï¼š
- è¾“å…¥å˜åŒ–çš„æ•æ„Ÿåº¦
- é”™è¯¯ä¿¡æ¯çš„å¤„ç†èƒ½åŠ›
- è¾¹ç•Œæƒ…å†µçš„è¡¨ç°

**A/Bæµ‹è¯•æ¡†æ¶**ï¼š
```python
class ReasoningMethodComparison:
    def __init__(self, test_dataset):
        self.test_dataset = test_dataset
        self.results = {}
    
    def run_comparison(self, methods):
        for method_name, method in methods.items():
            self.results[method_name] = self.evaluate_method(method)
    
    def evaluate_method(self, method):
        results = []
        for example in self.test_dataset:
            start_time = time.time()
            prediction = method.solve(example['question'])
            end_time = time.time()
            
            results.append({
                'prediction': prediction,
                'correct': prediction == example['answer'],
                'time': end_time - start_time,
                'reasoning_steps': len(prediction.get('steps', []))
            })
        
        return self.aggregate_results(results)
```

### Q5ï¼šåœ¨ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½²æ¨ç† Agent éœ€è¦è€ƒè™‘å“ªäº›å…³é”®å› ç´ ï¼Ÿ

**ç­”æ¡ˆ**ï¼š

**å…³é”®è€ƒè™‘å› ç´ **ï¼š

1. **å»¶è¿Ÿä¼˜åŒ–**ï¼š
```python
class ProductionReasoningAgent:
    def __init__(self, config):
        self.timeout = config.get('timeout', 30)  # 30ç§’è¶…æ—¶
        self.cache = config.get('enable_cache', True)
        self.fallback_method = config.get('fallback', 'simple')
    
    def solve_with_timeout(self, question):
        try:
            return asyncio.wait_for(
                self.solve(question), 
                timeout=self.timeout
            )
        except asyncio.TimeoutError:
            return self.fallback_solve(question)
```

2. **æˆæœ¬æ§åˆ¶**ï¼š
- Tokenä½¿ç”¨é‡ç›‘æ§
- APIè°ƒç”¨é¢‘ç‡é™åˆ¶
- è®¡ç®—èµ„æºé¢„ç®—

3. **å¯é æ€§ä¿è¯**ï¼š
```python
class ReliableAgent:
    def __init__(self):
        self.retry_count = 3
        self.confidence_threshold = 0.8
    
    def solve_with_reliability(self, question):
        for attempt in range(self.retry_count):
            result = self.solve(question)
            if result.get('confidence', 0) >= self.confidence_threshold:
                return result
        
        # å¦‚æœå¤šæ¬¡å°è¯•éƒ½ä¸æ»¡è¶³ç½®ä¿¡åº¦ï¼Œè¿”å›ä¿å®ˆç­”æ¡ˆ
        return self.conservative_solve(question)
```

4. **ç›‘æ§å’Œæ—¥å¿—**ï¼š
- æ¨ç†æ­¥éª¤è®°å½•
- é”™è¯¯æ¨¡å¼åˆ†æ
- æ€§èƒ½æŒ‡æ ‡è·Ÿè¸ª

5. **å®‰å…¨æ€§è€ƒè™‘**ï¼š
- å·¥å…·è°ƒç”¨æƒé™æ§åˆ¶
- è¾“å…¥éªŒè¯å’Œæ¸…ç†
- è¾“å‡ºå†…å®¹è¿‡æ»¤

**éƒ¨ç½²æ£€æŸ¥æ¸…å•**ï¼š
- [ ] è®¾ç½®åˆç†çš„è¶…æ—¶æ—¶é—´
- [ ] å®ç°é™çº§ç­–ç•¥
- [ ] æ·»åŠ ç¼“å­˜æœºåˆ¶
- [ ] é…ç½®ç›‘æ§å‘Šè­¦
- [ ] æµ‹è¯•è¾¹ç•Œæƒ…å†µ
- [ ] å»ºç«‹åé¦ˆæœºåˆ¶
- [ ] æ–‡æ¡£åŒ–APIæ¥å£

---

## ğŸ“š æ¨èé˜…è¯»

### åŸå§‹è®ºæ–‡
- [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903) â€” Wei et al., CoT å¼€å±±ä¹‹ä½œï¼Œåœ¨ GSM8K ä¸Šå°† PaLM-540B å‡†ç¡®ç‡ä» 17.9% æå‡åˆ° 56.9%
- [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629) â€” Yao et al., æ¨ç†+è¡ŒåŠ¨äº¤æ›¿å¾ªç¯èŒƒå¼ï¼ŒAgent æ—¶ä»£çš„åŸºç¡€æ¡†æ¶
- [Large Language Models are Zero-Shot Reasoners](https://arxiv.org/abs/2205.01068) â€” Kojima et al., "Let's think step by step" ä¸€å¥è¯æ¿€æ´»æ¨ç†èƒ½åŠ›
- [Self-Consistency Improves Chain of Thought Reasoning](https://arxiv.org/abs/2203.11171) â€” Wang et al., å¤šè·¯å¾„é‡‡æ · + å¤šæ•°æŠ•ç¥¨æå‡æ¨ç†å¯é æ€§
- [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601) â€” Yao et al., æ ‘å½¢æœç´¢æ¨ç†ç©ºé—´
- [Reflexion: Language Agents with Verbal Reinforcement Learning](https://arxiv.org/abs/2303.11366) â€” Shinn et al., è¯­è¨€åŒ–è‡ªæˆ‘åæ€ï¼Œå¤±è´¥é©±åŠ¨çš„æ”¹è¿›

### æ·±åº¦è§£è¯»
- [Reasoning Survey: A Survey of Reasoning with Foundation Models](https://arxiv.org/abs/2312.11562) â€” æ¨ç†èƒ½åŠ›ç»¼è¿° â­â­â­â­
- [LangChain å®˜æ–¹æ¨ç†æ¨¡å¼æ–‡æ¡£](https://python.langchain.com/docs/concepts/agents/) â€” å·¥ç¨‹å®ç°å‚è€ƒ â­â­â­â­

### å®è·µèµ„æº
- [LangGraph](https://langchain-ai.github.io/langgraph/) â€” ReAct Agent çš„ç”Ÿäº§çº§å®ç°æ¡†æ¶
- [DSPy](https://github.com/stanfordnlp/dspy) â€” ç¼–ç¨‹åŒ–çš„ prompt ä¼˜åŒ–æ¡†æ¶ï¼Œè‡ªåŠ¨åŒ– CoT/ReAct pipeline

---

## ğŸ”§ è½åœ°åº”ç”¨

### ç›´æ¥å¯ç”¨åœºæ™¯
- **æ•°å­¦/é€»è¾‘æ¨ç†ä»»åŠ¡**ï¼šFew-shot CoT æˆ– Zero-shot CoTï¼ˆ"Let's think step by step"ï¼‰ï¼ŒGSM8K ç±»é—®é¢˜å‡†ç¡®ç‡æå‡ 2-3 å€
- **çŸ¥è¯†é—®ç­”+å·¥å…·è°ƒç”¨**ï¼šReAct æ¨¡å¼ï¼ŒThoughtâ†’Actionâ†’Observation å¾ªç¯æ¥å…¥æœç´¢/è®¡ç®—å™¨/æ•°æ®åº“
- **åˆ›æ„/å¼€æ”¾æ€§é—®é¢˜**ï¼šTree-of-Thought æ¢ç´¢å¤šæ¡è·¯å¾„ï¼Œbeam search å¼é€‰æœ€ä¼˜
- **è¿­ä»£ä¼˜åŒ–ä»»åŠ¡**ï¼šReflexion è‡ªæˆ‘åæ€ï¼Œä»£ç ç”Ÿæˆ/è°ƒè¯•åœºæ™¯å°¤å…¶æœ‰æ•ˆï¼ˆHumanEval pass@1 ä» 80% â†’ 91%ï¼‰

### å·¥ç¨‹å®ç°è¦ç‚¹
- **CoT Few-shot ç¤ºä¾‹è´¨é‡**ï¼šç¤ºä¾‹çš„æ¨ç†æ­¥éª¤å¿…é¡»æ¸…æ™°æ­£ç¡®ï¼Œé”™è¯¯ç¤ºä¾‹ä¼šè¯¯å¯¼æ¨¡å‹ï¼›3-5 ä¸ªç¤ºä¾‹é€šå¸¸æœ€ä¼˜
- **ReAct å¾ªç¯é˜²æŠ¤**ï¼šè®¾ç½® `max_iterations`ï¼ˆæ¨è 5-10ï¼‰+ åŠ¨ä½œå†å²å»é‡æ£€æµ‹ + å•å·¥å…·è°ƒç”¨æ¬¡æ•°ä¸Šé™
- **Self-Consistency æˆæœ¬æ§åˆ¶**ï¼šé‡‡æ · 5-10 æ¡è·¯å¾„é€šå¸¸è¶³å¤Ÿï¼Œè¾¹é™…æ”¶ç›Šé€’å‡ï¼›ç”¨ temperature=0.7 å¢åŠ å¤šæ ·æ€§
- **æ¨ç†æ–¹æ³•é€‰æ‹©å…¬å¼**ï¼š

$$\text{æœ€ä¼˜æ–¹æ³•} = \begin{cases} \text{Zero-shot CoT} & \text{if æ— ç¤ºä¾‹ \& ä½é¢„ç®—} \\ \text{Few-shot CoT} & \text{if æœ‰ç¤ºä¾‹ \& ä¸­é¢„ç®—} \\ \text{ReAct} & \text{if éœ€è¦å·¥å…·äº¤äº’} \\ \text{ToT} & \text{if é«˜ç²¾åº¦ \& é«˜é¢„ç®—} \\ \text{Reflexion} & \text{if å…è®¸å¤šè½®è¿­ä»£} \end{cases}$$

### é¢è¯•é«˜é¢‘é—®æ³•
- Q: CoTã€ReActã€Tree-of-Thought æ ¸å¿ƒåŒºåˆ«ï¼Ÿ
  A: CoT = çº¿æ€§æ€ç»´é“¾ï¼ˆä¸€æ¡è·¯ï¼‰ï¼›ReAct = æ¨ç†+è¡ŒåŠ¨äº¤æ›¿ï¼ˆä¸ç¯å¢ƒäº¤äº’ï¼‰ï¼›ToT = æ ‘å½¢æœç´¢ï¼ˆå¤šæ¡è·¯+è¯„ä¼°+å›æº¯ï¼‰
- Q: ä»€ä¹ˆæ—¶å€™ç”¨ Zero-shot CoT vs Few-shot CoTï¼Ÿ
  A: Zero-shot é€‚åˆç¼ºä¹ç¤ºä¾‹/å¿«é€ŸåŸå‹/å¼ºæ¨¡å‹ï¼ˆGPT-4+ï¼‰ï¼›Few-shot é€‚åˆå¤æ‚ä»»åŠ¡/éœ€è¦é¢†åŸŸç¤ºä¾‹/å¼±æ¨¡å‹

---

## ğŸ’¡ å¯å‘ä¸æ€è€ƒ

### So Whatï¼Ÿå¯¹è€æ¿æ„å‘³ç€ä»€ä¹ˆ
- **CoT æ˜¯æœ€ä½æˆæœ¬çš„æ¨ç†å¢å¼º**ï¼šä¸€å¥ "Let's think step by step" å°±èƒ½æ˜¾è‘—æå‡æ¨ç†å‡†ç¡®ç‡ï¼Œæ˜¯æ‰€æœ‰ LLM åº”ç”¨çš„é»˜è®¤æœ€ä½³å®è·µ
- **ReAct æ˜¯ Agent çš„è®¤çŸ¥æ¶æ„åŸºçŸ³**ï¼šå‡ ä¹æ‰€æœ‰ç”Ÿäº§çº§ Agentï¼ˆLangChain/AutoGPT/OpenClawï¼‰éƒ½åŸºäº ReAct èŒƒå¼æ„å»ºï¼Œç†è§£ ReAct å°±ç†è§£äº† Agent çš„æ ¸å¿ƒå¾ªç¯
- **æ¨ç†æ–¹æ³•çš„é€‰æ‹©æ˜¯å·¥ç¨‹å†³ç­–**ï¼šä¸åŒæ–¹æ³•åœ¨å‡†ç¡®ç‡/å»¶è¿Ÿ/æˆæœ¬ä¹‹é—´æœ‰æ˜ç¡®çš„ tradeoffï¼Œåº”æ ¹æ®åœºæ™¯é€‰å‹è€Œé"æœ€æ–°=æœ€å¥½"

### æœªè§£é—®é¢˜ä¸å±€é™
- **CoT æ¨ç†é“¾æœ¬èº«å¯èƒ½åŒ…å«å¹»è§‰**ï¼šæ¨¡å‹å¯èƒ½ç”Ÿæˆçœ‹ä¼¼é€»è¾‘æ­£ç¡®ä½†å‰æé”™è¯¯çš„æ¨ç†é“¾ï¼ˆ"å¹»è§‰æ¨ç†é“¾"ï¼‰ï¼Œå‚è§ [[AI/LLM/Application/å¹»è§‰é—®é¢˜|å¹»è§‰é—®é¢˜]]
- **ReAct çš„å·¥å…·ä¾èµ–**ï¼šå¦‚æœå·¥å…·è¿”å›é”™è¯¯ä¿¡æ¯ï¼ŒReAct ä¼šåŸºäºé”™è¯¯ Observation ç»§ç»­æ¨ç†ï¼Œé”™è¯¯æ”¾å¤§
- **ToT çš„è®¡ç®—æˆæœ¬**ï¼šæ ‘å½¢æœç´¢çš„èŠ‚ç‚¹è¯„ä¼°éœ€è¦å¤§é‡ LLM è°ƒç”¨ï¼Œå¤æ‚é—®é¢˜å¯èƒ½éœ€è¦æ•°ç™¾æ¬¡æ¨ç†

### è„‘æš´ï¼šå¦‚æœå¾€ä¸‹å»¶ä¼¸
- å°† Reflexion çš„è‡ªæˆ‘åæ€ä¸ [[AI/Agent/Fundamentals/Agent ç”Ÿäº§å®è·µ|Agent ç”Ÿäº§å®è·µ]] ä¸­çš„é”™è¯¯å¤„ç†ç»“åˆï¼šAgent ä¸åªæ˜¯é‡è¯•ï¼Œè€Œæ˜¯åŸºäºå¤±è´¥åŸå› ç”Ÿæˆåæ€ â†’ ä¿®æ”¹ç­–ç•¥ â†’ é‡æ–°æ‰§è¡Œ
- CoT + [[AI/Safety/AIå®‰å…¨ä¸å¯¹é½-2026æŠ€æœ¯å…¨æ™¯|å®‰å…¨å¯¹é½]]ï¼šå¦‚æœå¼ºåˆ¶æ¨¡å‹åœ¨å›ç­”å‰å±•ç¤º CoTï¼Œæ˜¯å¦èƒ½è®©å®‰å…¨å®¡æŸ¥æ›´ç²¾å‡†ï¼Ÿï¼ˆæ£€æŸ¥æ¨ç†é“¾æ˜¯å¦è¯•å›¾ç»•è¿‡å®‰å…¨åŸåˆ™ï¼‰
- 6 ä¸ªæœˆé¢„åˆ¤ï¼šo1/o3 çš„"å†…éš CoT"ï¼ˆhidden chain-of-thoughtï¼‰å°†æˆä¸ºä¸»æµèŒƒå¼â€”â€”æ¨¡å‹å†…éƒ¨è‡ªåŠ¨ CoT è€Œéç”¨æˆ·æ˜¾å¼æç¤º

```mermaid
flowchart TD
    subgraph æ¨ç†èŒƒå¼æ¼”è¿›
        A[Standard Prompting] --> B[Few-shot CoT<br/>2022]
        A --> C[Zero-shot CoT<br/>2022]
        B --> D[Self-Consistency<br/>2022]
        B --> E[ReAct<br/>2022]
        D --> F[Tree-of-Thought<br/>2023]
        E --> G[Reflexion<br/>2023]
        F --> H[o1/o3 å†…éšæ¨ç†<br/>2024-2025]
        G --> H
    end
```

---

**ç›¸å…³é“¾æ¥**ï¼š
- [[AI/Agent/Fundamentals/Agent ç”Ÿäº§å®è·µ|Agent ç”Ÿäº§å®è·µ]] â€” Agent æ¨ç†æ¨¡å¼çš„ç”Ÿäº§è½åœ°ç»éªŒ
- [[AI/Agent/Fundamentals/Tool Use|Tool Use]] â€” ReAct ä¸­çš„å·¥å…·è°ƒç”¨æœ€ä½³å®è·µ
- [[AI/Agent/AI-Agent-2026-æŠ€æœ¯å…¨æ™¯|AI Agent æŠ€æœ¯å…¨æ™¯]] â€” Agent æ¨ç†åœ¨å…¨æ™¯ä¸­çš„ä½ç½®
- [[AI/LLM/Application/å¹»è§‰é—®é¢˜|å¹»è§‰é—®é¢˜]] â€” CoT æ¨ç†é“¾ä¸­çš„å¹»è§‰é£é™©
- [[AI/Safety/AIå®‰å…¨ä¸å¯¹é½-2026æŠ€æœ¯å…¨æ™¯|AI å®‰å…¨ä¸å¯¹é½]] â€” æ¨ç†é€æ˜åº¦å¯¹å®‰å…¨å®¡æŸ¥çš„ä»·å€¼