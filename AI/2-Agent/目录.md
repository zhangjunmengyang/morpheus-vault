---
title: "Agent æ™ºèƒ½ä½“"
type: moc
domain: ai/agent
tags:
  - ai/agent
  - type/moc
updated: 2026-02-26
---

# ğŸ¤– Agent æ™ºèƒ½ä½“

> ä»å• Agent åˆ° Multi-Agentï¼Œä» Tool Use åˆ° Agentic RL

---

## æ——èˆ°

- [[AI-Agent-2026-æŠ€æœ¯å…¨æ™¯|ğŸ”¥ AI Agent 2026 æŠ€æœ¯å…¨æ™¯]] â­ â€” é¢è¯•æ­¦å™¨åº“ï¼Œ1114è¡Œ â˜…â˜…â˜…â˜…â˜…

---

## ç¬¬ä¸€ç«  åŸºç¡€ä¸æ¶æ„

- [[Agent or Workflowï¼Ÿ|Agent or Workflowï¼Ÿ]] â€” è®¾è®¡å†³ç­–
- [[ReAct ä¸ CoT|ReAct ä¸ CoT]] â€” æ¨ç†èŒƒå¼å¯¹æ¯”
- [[ReAct-æ¨ç†æ¨¡å¼|ReAct æ¨ç†æ¨¡å¼]]
- [[åˆ†æ Agent æ¼”è¿›çš„ä¸€äº›æ€è€ƒ|Agent æ¼”è¿›æ€è€ƒ]]
- [[Building-Effective-Agents-Anthropic|Building Effective Agentsï¼ˆAnthropicï¼‰]]
- [[Context-Folding è®ºæ–‡|Context-Folding]] â€” é•¿ç¨‹ Agent
- [[HF Agent Course|HF Agent Course]]
- [[HF LLM + Agent|HF LLM + Agent]]
- [[Agent-ç”Ÿäº§è½åœ°|Agent ç”Ÿäº§è½åœ°]]
- [[Agent ç”Ÿäº§å®è·µ|Agent ç”Ÿäº§å®è·µ]]

### è®°å¿†

- [[è®°å¿†æ¨¡å—|è®°å¿†æ¨¡å—]] â€” çŸ­æœŸ/é•¿æœŸè®°å¿†
- [[Agent-Memory-æœºåˆ¶|Agent Memory æœºåˆ¶]] â€” RAG-based memory / MemGPT / Letta
- [[Agent-World-Model|Agent World Model]]
- [[Memory-R1-RL-for-LLM-Memory-Management|Memory-R1]] â­ â€” RL é©±åŠ¨è®°å¿†ç®¡ç†ï¼ˆADD/UPDATE/DELETEï¼‰ï¼Œ152æ¡æ•°æ®è¶… Mem0 F1 +28% â˜…â˜…â˜…â˜…â˜†

### å·¥å…·è°ƒç”¨

- [[Tool Use|Tool Use]] â€” å·¥å…·è°ƒç”¨åŸºç¡€
- [[Agent-Tool-Use|Agent Tool Use]] â€” Function Calling / ReAct / API å¯¹æ¯”
- [[LLMå·¥å…·è°ƒç”¨ä¸Function-Calling-2026æŠ€æœ¯å…¨æ™¯|ğŸ”¥ LLM å·¥å…·è°ƒç”¨ä¸ Function Calling 2026 å…¨æ™¯]] â­ â€” é¢è¯•æ­¦å™¨çº§ â˜…â˜…â˜…â˜…â˜…
- [[Code Agent|Code Agentï¼ˆåŸºç¡€ï¼‰]]
- [[Code-Agent-æ·±åº¦|Code Agentï¼ˆæ·±åº¦ï¼‰]]
- [[å¦‚ä½•ç»™äººæ·±åº¦ç§‘æ™®-MCP|å¦‚ä½•ç»™äººæ·±åº¦ç§‘æ™® MCP]]
- [[HF-MCP-Course|HF MCP Course]]
- [[Chrome-DevTools-MCP|Chrome DevTools MCP]] â€” æµè§ˆå™¨è°ƒè¯• MCP
- [[GitHub-Agentic-Workflows|GitHub Agentic Workflows]]

---

## ç¬¬äºŒç«  Multi-Agent ç³»ç»Ÿ

- [[Multi-Agent æ¦‚è¿°|Multi-Agent æ¦‚è¿°]]
- [[Multi-Agent-æ¶æ„æ¨¡å¼è¯¦è§£|Multi-Agent æ¶æ„æ¨¡å¼è¯¦è§£]] â€” Supervisor/Pipeline/Debate â˜…â˜…â˜…â˜…â˜†
- [[å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸åä½œæ¡†æ¶-2026æŠ€æœ¯å…¨æ™¯|ğŸ”¥ å¤šæ™ºèƒ½ä½“ç³»ç»Ÿä¸åä½œæ¡†æ¶ 2026 å…¨æ™¯]] â­ â€” é¢è¯•æ­¦å™¨çº§ â˜…â˜…â˜…â˜…â˜…
- [[Agent vs MAS|Agent vs MAS]]
- [[AI/2-Agent/Multi-Agent/Planner|Planner]]
- [[Kimi-K2.5-PARL|Kimi K2.5 & PARL]] â€” å¹¶è¡Œå¤š Agent RL
- [[IMAGINE-å¤šAgentè’¸é¦åˆ°å•æ¨¡å‹|IMAGINE]] â€” å¤š Agent è’¸é¦åˆ°å•æ¨¡å‹
- [[AdaptOrch-Task-Adaptive-Multi-Agent-Orchestration|AdaptOrch]] â­ â€” æ‹“æ‰‘é€‰æ‹©å½±å“æ¯”æ¨¡å‹é€‰æ‹©å¤§ 20xï¼ŒDAG ä¸‰æŒ‡æ ‡è‡ªåŠ¨è·¯ç”± â˜…â˜…â˜…â˜…â˜†
- [[AgentConductor-Topology-Evolution|AgentConductor]] â­ â€” RL åŠ¨æ€ç”Ÿæˆ DAG topology â˜…â˜…â˜…â˜…
- [[AgentAuditor-Reasoning-Tree-å®¡è®¡|AgentAuditor]] â€” Reasoning Tree å®¡è®¡
- [[Collective-Behaviour-Hundreds-LLM-Agents-2026|Collective Behaviourï¼ˆ100+ LLM Agentsï¼‰]] â˜…â˜…â˜…â˜…â˜†
- [[é›¶ç¢çš„ç‚¹|é›¶ç¢çš„ç‚¹]]

### æ¡†æ¶é€‰å‹

- [[Agent-æ¡†æ¶å¯¹æ¯”|Agent æ¡†æ¶å¯¹æ¯”]] â€” å…­å¤§æ¡†æ¶é€‰å‹
- [[Agent-æ¡†æ¶å¯¹æ¯”-2026|Agent æ¡†æ¶å¯¹æ¯” 2026]]
- [[AutoGen|AutoGen]]
- [[dbgpt-æ–‡æ¡£|DB-GPT]]

---

## ç¬¬ä¸‰ç«  Agentic RL è®­ç»ƒ â­

> æ ¸å¿ƒé—®é¢˜ï¼šå¦‚ä½•ç”¨ RL è®­ç»ƒé•¿ç¨‹ã€å¤šè½®ã€å¤šå·¥å…·çš„ Agent

### ç»¼åˆåˆ†æï¼ˆå…ˆè¯»è¿™é‡Œï¼‰

- [[Agentic-RL-2026å‰æ²¿ç»¼åˆåˆ†æ|ğŸ”¥ Agentic RL 2026 å‰æ²¿ç»¼åˆåˆ†æ]] â­ â€” äº”å¤§ç»´åº¦å…¨å›¾è°± â˜…â˜…â˜…â˜…â˜…
- [[Agentic-RL-å…ƒé—®é¢˜-ç“¶é¢ˆä¸çªç ´æ–¹å‘|ğŸ§  Agentic RL å…ƒé—®é¢˜ï¼šç“¶é¢ˆä¸çªç ´]] â­ â€” Wisdomå±‚ï¼Œç®—æ³•å¤Ÿäº†ï¼Œç“¶é¢ˆæ˜¯ Reward Signal Quality â˜…â˜…â˜…â˜…â˜…
- [[Agent-RL-è®­ç»ƒå®æˆ˜æŒ‡å—|ğŸ”¥ Agent RL è®­ç»ƒå®æˆ˜æŒ‡å—]] â­ â€” 1001è¡Œå®æˆ˜è¸©å‘ â˜…â˜…â˜…â˜…â˜…
- [[Agent-RL-ç¯å¢ƒå·¥ç¨‹ç³»ç»Ÿè®º|ğŸ”¥ Agent RL ç¯å¢ƒå·¥ç¨‹ç³»ç»Ÿè®º]] â­ â€” ç¯å¢ƒè®¾è®¡/Rewardå·¥ç¨‹ â˜…â˜…â˜…â˜…â˜…
- [[Long-Horizon-Credit-Assignmentä¸“é¢˜|ğŸ”¥ Long-Horizon Credit Assignment ä¸“é¢˜]] â­ â€” å…¨æ–¹æ¡ˆå›¾è°± â˜…â˜…â˜…â˜…â˜…
- [[Tool-Use-RL-è®­ç»ƒä¸“é¢˜|ğŸ”¥ Tool Use RL è®­ç»ƒä¸“é¢˜]] â­ â€” å…¨å›¾è°± â˜…â˜…â˜…â˜…â˜…
- [[Multi-Agent-RL-è®­ç»ƒä¸“é¢˜|ğŸ”¥ Multi-Agent RL è®­ç»ƒä¸“é¢˜]] â­ â€” MAGRPO/AT-GRPO/MARS2 â˜…â˜…â˜…â˜…â˜…
- [[Agentic RL Survey|Agentic RL Survey]]
- [[Agentic RL Training|Agentic RL Training]]
- [[Agentic-Reasoning-Survey-2601.12538|Agentic Reasoning Surveyï¼ˆ2601.12538ï¼‰]]
- [[Agentè‡ªæˆ‘è¿›åŒ–ç­–ç•¥-ä»è®°å¿†ä¹ æƒ¯åˆ°è‡ªä¸»æˆé•¿|Agent è‡ªæˆ‘è¿›åŒ–ç­–ç•¥]] â­ â€” 10ç§è¿›åŒ–æ¨¡å¼å®æˆ˜æ‰‹å†Œ â˜…â˜…â˜…â˜…â˜…

### æ–¹æ³•è®ºå…¨æ™¯ï¼ˆä¸€å¼ è¡¨è¯´æ¸…å…³ç³»ï¼‰

å„æ–¹æ³•è§£å†³çš„æ ¸å¿ƒé—®é¢˜åŠç›¸äº’å…³ç³»ï¼š

| æ–¹æ³• | è§£å†³ä»€ä¹ˆé—®é¢˜ | å…³é”®æ€è·¯ | å…³ç³»é“¾ |
|------|------------|---------|--------|
| **GiGPO** | step-level credit assignment | Anchor State Groupingï¼Œæ— é¢å¤–rollout | åŸºç¡€ï¼›è¢« HiPER/iStar è¶…è¶Š/äº’è¡¥ |
| **HiPER** | segment-level CAï¼Œplan+execute | HAE ä¸¤å±‚ advantageï¼Œç†è®ºæ— å | GiGPO å‡çº§ç‰ˆï¼ˆæ›´ç²—ç²’åº¦ä½†æ›´å‡†ï¼‰ |
| **iStar** | éå¯éªŒè¯ reward çš„ step CA | trajectory DPO â†’ implicit step reward | GiGPO äº’è¡¥ï¼ˆè¦†ç›– open-endedï¼‰ |
| **MIG** | ä¿¡æ¯è®ºè§†è§’ CA | è¾¹é™…ä¿¡æ¯å¢ç›Š + Watermark é˜² hacking | CA è°±ç³»å”¯ä¸€ä¿¡æ¯è®ºæ–¹æ¡ˆ |
| **CSO** | åäº‹å®éªŒè¯ CA | PRMå®šä½å¼±ç‚¹+æ›¿ä»£+éªŒè¯ï¼Œåªç£16%æ­¥éª¤ | å¤±è´¥è½¨è¿¹è§†è§’ï¼Œä¸ GiGPO æ­£äº¤ |
| **AgentPRM** | è‡ªåŠ¨æ ‡æ³¨ PRM | MC rollout æ ‡æ³¨ + InversePRM | æä¾› step reward è®­ç»ƒæ•°æ® |
| **SELAUR** | å¤±è´¥è½¨è¿¹ä¿¡æ¯æµªè´¹ | token entropy é‡å¡‘å¤±è´¥è½¨è¿¹ reward | GiGPO äº’è¡¥ï¼ˆæ¿€æ´»å¤±è´¥ä¿¡å·ï¼‰ |
| **LOOP** | é•¿ horizon æ—  critic | Leave-One-Out PPOï¼Œ1Ã— LLM | Appleæ–¹æ¡ˆï¼Œ32B > o1 |
| **SeeUPO** | multi-turn æ”¶æ•›ä¸ä¿è¯ | é€†åºæ›´æ–° HAMLï¼Œç†è®ºè¯æ˜æ”¶æ•› | GRPO çš„å¤šè½®æ›¿ä»£æ–¹æ¡ˆ |
| **RAGEN/StarPO** | å¤šè½®è®­ç»ƒä¸ç¨³å®šï¼ˆEcho Trapï¼‰ | ä¸‰æœºåˆ¶ä¿®å¤ entropy collapse | å¥ åŸºè®ºæ–‡ï¼Œåç»­éƒ½è¦è¯» |
| **Dr. MAS** | å¤š agent æ¢¯åº¦çˆ†ç‚¸ | Agent-Wise Advantage Normalization | RAGEN äº’è¡¥ï¼ˆå¤š agent ç‰ˆï¼‰ |
| **SHARP** | å¤š agent æ¨ªå‘ CA | Shapley value é‡åŒ–è¾¹é™…è´¡çŒ® | GiGPO æ­£äº¤ï¼ˆçºµvsæ¨ªï¼‰ |
| **TSR** | rollout è´¨é‡å·®/é™·é˜±ä¸å¯é€† | per-turn æ ‘æœç´¢ï¼Œoptimizer-agnostic | å¯å åŠ åˆ°ä»»ä½•æ–¹æ³•ä¸Š |
| **Tree-GRPO** | rollout é¢„ç®—æµªè´¹ | å…±äº«å‰ç¼€æ ‘ + åŒå±‚ advantage | 1/4é¢„ç®—è¶…å…¨é¢„ç®— GRPO |
| **SCoRe** | LLM è‡ªæˆ‘çº é”™ behavior collapse | ä¸¤é˜¶æ®µå¤šè½®RL + reward bonus | è‡ªæˆ‘çº é”™çš„å¥ åŸºæ–¹æ¡ˆ |
| **ERL** | åæ€èƒ½åŠ›è®­ç»ƒæ—¶å†…åŒ– | experience-reflection-consolidation | éƒ¨ç½²é›¶æˆæœ¬ï¼Œå¯å åŠ  |
| **KLong** | è¶…é•¿ horizonï¼ˆ700+ turnsï¼‰ | Trajectory-splitting SFT + Progressive RL | æé™é•¿ç¨‹æ–¹æ¡ˆ |
| **PA-MoE** | Simplicity Bias | Phase-Aware MoE | è®­ç»ƒåŠ¨æ€ä¼˜åŒ– |
| **PVPO** | ä»·å€¼é¢„ä¼°ä¸å‡† | Pre-Estimated Value-Based PO | â€” |
| **Calibrate-Then-Act** | æ¢ç´¢æˆæœ¬ | Cost-aware æ¢ç´¢ç­–ç•¥ | ä¸ E-SPL äº’è¡¥ |
| **PABU** | é«˜æ•ˆ Agent çŠ¶æ€ä¼°è®¡ | Progress-Aware Belief State | â€” |

**Tool Use RL å­çº¿**

| æ–¹æ³• | è§£å†³ä»€ä¹ˆ | æ ‡å¿—æ€§ç»“è®º |
|------|---------|-----------|
| **ToRL** | ä» base model ç›´æ¥è®­å·¥å…·è°ƒç”¨ | æ— SFTå‰æï¼Œ7B AIME24 43.3% |
| **ARTIST** | ç»Ÿä¸€å¤šå·¥å…·å¤šè½®æ¨ç† | GRPO + token maskingï¼Œè¶… GPT-4o |
| **Search-R1** | æœç´¢é›†æˆè¿› RL | retrieved token maskingï¼Œ+41% |
| **WebAgent-R1** | Web browser ç«¯åˆ°ç«¯ RL | BCçƒ­å¯åŠ¨å…³é”®ï¼Œ8B 44.8% WebArena |
| **ASTRA** | å…¨è‡ªåŠ¨è®­ç»ƒæµæ°´çº¿ | MCPå·¥å…·å›¾åˆæˆï¼Œ32B > o3 |
| **RC-GRPO** | multi-turn all-0/all-1 å´©å¡Œ | reward token conditioning |
| **CM2** | open-ended reward é‡åŒ– | Checklist æ‹†è§£ä¸ºäºŒè¿›åˆ¶ï¼Œ+8~12 |
| **VerlTool** | å·¥å…·ä½¿ç”¨ RL ç»Ÿä¸€æ¡†æ¶ | â€” |

**ç¯å¢ƒå·¥ç¨‹**

| æ–¹æ³• | è§£å†³ä»€ä¹ˆ | æ ‡å¿—æ€§ç»“è®º |
|------|---------|-----------|
| **AWM** | åˆæˆç¯å¢ƒç”Ÿæˆ | 1000ç¯å¢ƒ+35K MCPå·¥å…·ï¼Œäº”é˜¶æ®µæµæ°´çº¿ |
| **EnterpriseGym** | é«˜ä¿çœŸä¼ä¸šç¯å¢ƒ | Corecraft æ¡†æ¶ |
| **UI-TARS-2** | GUI Agent å·¥ç¨‹æè‡´ | Data Flywheel + å¼‚æ­¥ RLï¼ŒOSWorld 47.5% |
| **UI-R1** | GUI Agent æç®€è·¯çº¿ | 136æ¡æ•°æ® GRPOï¼Œ3Båª²ç¾SFT 7B |
| **ActionEngine** | Reactiveâ†’Programmatic | State Machine Graphï¼Œ11.8x æˆæœ¬èŠ‚çœ |
| **WebPilot** | Web è‡ªåŠ¨åŒ– | â€” |

**å…¶ä»–è®ºæ–‡**

- [[FlowSteer-CWRPO-Workflow-Orchestration-RL|FlowSteer]] â€” Workflow via End-to-End RL â˜…â˜…â˜…â˜†
- [[SquRL-Dynamic-Workflow-Text-to-SQL|SquRL]] â€” Dynamic Workflow for Text-to-SQL â˜…â˜…â˜…
- [[R-4B è®ºæ–‡|R-4B]] â€” MLLM Auto-Thinking
- [[PVPO è®ºæ–‡|PVPO]]
- [[WebPilot è®ºæ–‡|WebPilot]]

---

## ç¬¬å››ç«  è¯„æµ‹ä¸å®‰å…¨

- [[Agent-è¯„æµ‹ä¸-Benchmark|Agent è¯„æµ‹ä¸ Benchmark]]
- [[Agentè¯„ä¼°ä½“ç³»æ‰¹åˆ¤-Goodhartæ³•åˆ™ä¸Benchmarké™·é˜±|ğŸ”¥ Agent è¯„ä¼°ä½“ç³»æ‰¹åˆ¤ï¼šGoodhart's Law]] â­ â€” RLè®­ç»ƒè€…å¿…è¯» â˜…â˜…â˜…â˜…â˜…
- [[Evaluating-AGENTS-Context|Evaluating AGENTS: Context Files]]
- [[Gaia2-Dynamic-Async-Agent-Benchmark|Gaia2]] â­ â€” åŠ¨æ€å¼‚æ­¥ Agent benchmark â˜…â˜…â˜…â˜…â˜…
- [[DeepSynth-Deep-Information-Synthesis-Benchmark|DeepSynth]] â˜…â˜…â˜…â˜…â˜† â€” ç“¶é¢ˆæ˜¯è§„åˆ’è€Œéæ¨ç†
- [[Aletheia-Math-Research-Agent|Aletheiaï¼ˆå‰ä½œï¼‰]] â€” æ•°å­¦ç§‘ç ” Agent
- [[Aletheia-Gemini3-DeepThink-FirstProof|Aletheia FirstProof]] â­ â€” Gemini 3 é¦–æ¬¡è§£å†³ç ”ç©¶çº§æ•°å­¦ open problems â˜…â˜…â˜…â˜…â˜…
- [[CowCorpus-Human-Intervention-Modeling-Web-Agents|CowCorpus]] â€” Human-in-the-Loop å¹²é¢„å»ºæ¨¡ â˜…â˜…â˜…â˜…â˜†
- [[Agent-Skills-Security|Agent Skills Security]] â€” 26.1% ç¤¾åŒº skill å«æ¼æ´
- [[Colosseum-Multi-Agent-Collusion-Audit-2026|Colosseumï¼ˆå‹¾ç»“å®¡è®¡ï¼‰]] â€” é¦–ä¸ªç³»ç»ŸåŒ–å®¡è®¡å¤š Agent å‹¾ç»“ â˜…â˜…â˜…â˜…â˜†
- [[Agent è¯„æµ‹|Agent è¯„æµ‹]]

---

## å¯¼èˆª

- â†‘ ä¸Šçº§ï¼š[[AI/ç›®å½•]]
- â†’ äº¤å‰ï¼š[[AI/3-LLM/RL/ç›®å½•]]ï¼ˆç®—æ³•å±‚ RLï¼‰Â· [[AI/5-AI å®‰å…¨/ç›®å½•]]ï¼ˆAgent å®‰å…¨ï¼‰
