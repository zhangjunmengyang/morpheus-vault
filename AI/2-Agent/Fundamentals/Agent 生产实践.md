---
title: Agent ç”Ÿäº§è½åœ°ç»éªŒï¼šé”™è¯¯å¤„ç†ã€è¶…æ—¶ã€å¯è§‚æµ‹æ€§ã€äººæœºåä½œä¸æˆæœ¬æ§åˆ¶
brief: AI Agentä»åŸå‹åˆ°ç”Ÿäº§çš„å·¥ç¨‹å®è·µï¼šæŒ‡æ•°é€€é¿é‡è¯•+æ™ºèƒ½é”™è¯¯åˆ†ç±»ã€å¤šå±‚è¶…æ—¶è®¾è®¡(è¯·æ±‚/åˆ†æ­¥/è‡ªé€‚åº”)ã€ç†”æ–­é™çº§æœºåˆ¶ã€OpenTelemetry/LangSmithé“¾è·¯è¿½è¸ªã€Human-in-the-loopåä½œè§¦å‘ç­–ç•¥ã€Tokené¢„ç®—ç®¡ç†ä¸å¤šå±‚ç¼“å­˜ã€‚æ ¸å¿ƒæ´å¯Ÿï¼šç”Ÿäº§Agentçš„å¯é æ€§ä¸æ˜¯æ¨¡å‹èƒ½åŠ›é—®é¢˜ï¼Œæ˜¯å·¥ç¨‹ç³»ç»Ÿè®¾è®¡é—®é¢˜ã€‚
tags:
  - AI-Agent
  - production
  - reliability
  - monitoring
  - cost-control
type: tutorial
domain: ai/agent/engineering
created: 2026-02-14
updated: 2026-02-22
status: review
dikw: K
sources:
  - Anthropic Agent Engineering Blog â€” Building effective agents (2024)
  - LangGraph æ–‡æ¡£ â€” https://langchain-ai.github.io/langgraph/
  - AgentBench å¯é æ€§è¯„ä¼° â€” Liu et al. arXiv:2308.03688
  - OpenTelemetry å®˜æ–¹æ–‡æ¡£ â€” https://opentelemetry.io/
  - LangSmith è¿½è¸ªæ–‡æ¡£ â€” https://docs.smith.langchain.com/
related:
  - "[[AI/2-Agent/Fundamentals/ReAct ä¸ CoT|ReAct ä¸ CoT]]"
  - "[[AI/2-Agent/Fundamentals/Tool Use|Tool Use]]"
  - "AI Agent æŠ€æœ¯å…¨æ™¯"
  - "AI å®‰å…¨ä¸å¯¹é½"
---

# Agent ç”Ÿäº§è½åœ°ç»éªŒ

## æ¦‚è¿°

> å‚è€ƒï¼š[Anthropic â€” Building Effective Agents](https://www.anthropic.com/research/building-effective-agents) ; [AgentBench](https://arxiv.org/abs/2308.03688) â€” ç”Ÿäº§ç¯å¢ƒ Agent å¯é æ€§è¯„ä¼°æ¡†æ¶

AI Agent ä»åŸå‹æ¼”ç¤ºåˆ°ç”Ÿäº§è½åœ°å­˜åœ¨å·¨å¤§é¸¿æ²Ÿã€‚ç”Ÿäº§ç¯å¢ƒä¸­çš„ Agent éœ€è¦é¢å¯¹ç½‘ç»œå¼‚å¸¸ã€API é™æµã€ç”¨æˆ·è¾“å…¥å¤šæ ·æ€§ç­‰å¤æ‚æŒ‘æˆ˜ã€‚æœ¬æ–‡åŸºäºå®é™…é¡¹ç›®ç»éªŒï¼Œæ·±å…¥æ¢è®¨é”™è¯¯å¤„ç†ã€è¶…æ—¶ç®¡ç†ã€å¯è§‚æµ‹æ€§å»ºè®¾ã€äººæœºåä½œä»¥åŠæˆæœ¬æ§åˆ¶çš„æœ€ä½³å®è·µï¼Œä¸º Agent ç³»ç»Ÿçš„ç¨³å®šè¿è¡Œæä¾›å…¨æ–¹ä½æŒ‡å¯¼ã€‚

## é”™è¯¯å¤„ç†ç­–ç•¥

### é”™è¯¯åˆ†ç±»ä¸å¤„ç†

**ç³»ç»Ÿçº§é”™è¯¯**
- **ç½‘ç»œå¼‚å¸¸**ï¼šAPI è°ƒç”¨å¤±è´¥ã€è¶…æ—¶
- **èµ„æºä¸è¶³**ï¼šå†…å­˜æº¢å‡ºã€ç£ç›˜ç©ºé—´
- **æœåŠ¡ä¾èµ–**ï¼šæ•°æ®åº“è¿æ¥ã€ç¬¬ä¸‰æ–¹æœåŠ¡ä¸å¯ç”¨

**ä¸šåŠ¡çº§é”™è¯¯**
- **è¾“å…¥å¼‚å¸¸**ï¼šç”¨æˆ·è¾“å…¥æ ¼å¼é”™è¯¯ã€æ¶æ„è¾“å…¥
- **é€»è¾‘é”™è¯¯**ï¼šæ¨ç†é“¾æ–­è£‚ã€å·¥å…·è°ƒç”¨å¤±è´¥
- **æ•°æ®å¼‚å¸¸**ï¼šç¼ºå¤±å…³é”®ä¿¡æ¯ã€æ•°æ®æ ¼å¼ä¸åŒ¹é…

### é‡è¯•ç­–ç•¥è®¾è®¡

**æŒ‡æ•°é€€é¿é‡è¯•**
```python
import asyncio
import random
from typing import Callable, Any

class RetryConfig:
    def __init__(self):
        self.max_retries = 3
        self.base_delay = 1.0
        self.max_delay = 60.0
        self.backoff_factor = 2.0
        self.jitter = True

async def exponential_backoff_retry(
    func: Callable,
    config: RetryConfig,
    *args, **kwargs
) -> Any:
    """æŒ‡æ•°é€€é¿é‡è¯•è£…é¥°å™¨"""
    
    for attempt in range(config.max_retries + 1):
        try:
            return await func(*args, **kwargs)
        
        except Exception as e:
            if attempt == config.max_retries:
                raise e
            
            # è®¡ç®—å»¶è¿Ÿæ—¶é—´
            delay = min(
                config.base_delay * (config.backoff_factor ** attempt),
                config.max_delay
            )
            
            # æ·»åŠ æŠ–åŠ¨é¿å…é›·ç¾¤æ•ˆåº”
            if config.jitter:
                delay *= (0.5 + random.random() * 0.5)
            
            logger.warning(f"Attempt {attempt + 1} failed: {e}, retrying in {delay:.2f}s")
            await asyncio.sleep(delay)
```

**æ™ºèƒ½é‡è¯•ç­–ç•¥**
```python
class SmartRetryHandler:
    def __init__(self):
        self.retry_configs = {
            # ç½‘ç»œé”™è¯¯ï¼šå¿«é€Ÿé‡è¯•
            "ConnectionError": RetryConfig(max_retries=5, base_delay=0.5),
            # é™æµé”™è¯¯ï¼šæ…¢é‡è¯•
            "RateLimitError": RetryConfig(max_retries=3, base_delay=10.0),
            # æœåŠ¡ä¸å¯ç”¨ï¼šä¸­ç­‰é‡è¯•
            "ServiceUnavailable": RetryConfig(max_retries=4, base_delay=2.0),
            # è®¤è¯é”™è¯¯ï¼šä¸é‡è¯•
            "AuthenticationError": RetryConfig(max_retries=0)
        }
    
    def should_retry(self, error: Exception) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•"""
        error_type = type(error).__name__
        config = self.retry_configs.get(error_type)
        return config and config.max_retries > 0
    
    async def execute_with_retry(self, func, *args, **kwargs):
        """æ™ºèƒ½é‡è¯•æ‰§è¡Œ"""
        try:
            return await func(*args, **kwargs)
        except Exception as e:
            if self.should_retry(e):
                error_type = type(e).__name__
                config = self.retry_configs[error_type]
                return await exponential_backoff_retry(func, config, *args, **kwargs)
            else:
                raise e
```

### é™çº§æ–¹æ¡ˆ

**åŠŸèƒ½é™çº§**
```python
class AgentFallbackHandler:
    def __init__(self):
        self.fallback_chain = [
            self.primary_model,      # ä¸»æ¨¡å‹
            self.backup_model,       # å¤‡ç”¨æ¨¡å‹  
            self.rule_based_handler, # è§„åˆ™å¼•æ“
            self.human_handoff       # äººå·¥æ¥ç®¡
        ]
    
    async def process_with_fallback(self, request):
        """å¸¦é™çº§çš„è¯·æ±‚å¤„ç†"""
        last_error = None
        
        for handler in self.fallback_chain:
            try:
                result = await handler(request)
                if self.is_valid_result(result):
                    return result
                    
            except Exception as e:
                logger.warning(f"Handler {handler.__name__} failed: {e}")
                last_error = e
                continue
        
        # æ‰€æœ‰é™çº§æ–¹æ¡ˆéƒ½å¤±è´¥
        raise Exception(f"All fallback handlers failed. Last error: {last_error}")
    
    def is_valid_result(self, result):
        """ç»“æœè´¨é‡æ£€æŸ¥"""
        if not result or len(result.strip()) < 10:
            return False
        if "I don't know" in result or "error" in result.lower():
            return False
        return True
```

**ç†”æ–­æœºåˆ¶**
```python
import time
from enum import Enum

class CircuitState(Enum):
    CLOSED = "closed"      # æ­£å¸¸çŠ¶æ€
    OPEN = "open"          # ç†”æ–­çŠ¶æ€
    HALF_OPEN = "half_open"  # åŠå¼€çŠ¶æ€

class CircuitBreaker:
    def __init__(self, failure_threshold=5, timeout=60):
        self.failure_threshold = failure_threshold
        self.timeout = timeout
        self.failure_count = 0
        self.last_failure_time = None
        self.state = CircuitState.CLOSED
    
    async def call(self, func, *args, **kwargs):
        """ç†”æ–­å™¨åŒ…è£…çš„å‡½æ•°è°ƒç”¨"""
        
        if self.state == CircuitState.OPEN:
            if time.time() - self.last_failure_time > self.timeout:
                self.state = CircuitState.HALF_OPEN
                self.failure_count = 0
            else:
                raise Exception("Circuit breaker is OPEN")
        
        try:
            result = await func(*args, **kwargs)
            
            # æˆåŠŸæ—¶é‡ç½®è®¡æ•°
            if self.state == CircuitState.HALF_OPEN:
                self.state = CircuitState.CLOSED
            self.failure_count = 0
            
            return result
            
        except Exception as e:
            self.failure_count += 1
            self.last_failure_time = time.time()
            
            if self.failure_count >= self.failure_threshold:
                self.state = CircuitState.OPEN
                logger.error(f"Circuit breaker opened due to {self.failure_count} failures")
            
            raise e
```

## è¶…æ—¶ç®¡ç†

### å¤šå±‚è¶…æ—¶è®¾è®¡

**è¯·æ±‚çº§è¶…æ—¶æ¶æ„**
```python
import asyncio
from contextlib import asynccontextmanager

class TimeoutManager:
    def __init__(self):
        self.default_timeouts = {
            "llm_call": 30.0,      # LLM API è°ƒç”¨
            "tool_execution": 60.0, # å·¥å…·æ‰§è¡Œ
            "total_request": 300.0, # æ€»è¯·æ±‚æ—¶é—´
            "user_input": 600.0     # ç”¨æˆ·è¾“å…¥ç­‰å¾…
        }
    
    @asynccontextmanager
    async def timeout_context(self, timeout_type: str, custom_timeout=None):
        """è¶…æ—¶ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        timeout = custom_timeout or self.default_timeouts.get(timeout_type, 30.0)
        
        try:
            async with asyncio.timeout(timeout):
                yield
        except asyncio.TimeoutError:
            logger.warning(f"{timeout_type} timed out after {timeout}s")
            raise TimeoutError(f"{timeout_type} timeout ({timeout}s)")

# ä½¿ç”¨ç¤ºä¾‹
timeout_mgr = TimeoutManager()

async def call_llm_with_timeout(prompt):
    async with timeout_mgr.timeout_context("llm_call"):
        return await llm_client.chat(prompt)
```

### åˆ†æ®µè¶…æ—¶ç­–ç•¥

**å¤æ‚ä»»åŠ¡åˆ†è§£**
```python
class StepwiseTimeoutHandler:
    def __init__(self):
        self.step_timeouts = {
            "planning": 15.0,       # è®¡åˆ’ç”Ÿæˆ
            "tool_search": 10.0,    # å·¥å…·æœç´¢
            "tool_execution": 45.0, # å·¥å…·æ‰§è¡Œ
            "response_generation": 20.0  # å“åº”ç”Ÿæˆ
        }
    
    async def execute_with_step_timeouts(self, agent_workflow):
        """åˆ†æ­¥éª¤æ‰§è¡Œï¼Œæ¯æ­¥ç‹¬ç«‹è¶…æ—¶"""
        results = {}
        
        for step_name, step_func in agent_workflow.items():
            timeout = self.step_timeouts.get(step_name, 30.0)
            
            try:
                async with asyncio.timeout(timeout):
                    results[step_name] = await step_func(results)
                    logger.info(f"Step {step_name} completed")
                    
            except asyncio.TimeoutError:
                logger.error(f"Step {step_name} timed out after {timeout}s")
                # å¯ä»¥é€‰æ‹©ç»§ç»­ä¸‹ä¸€æ­¥æˆ–ç›´æ¥å¤±è´¥
                if step_name in ["planning", "response_generation"]:
                    raise  # å…³é”®æ­¥éª¤å¤±è´¥åˆ™æ•´ä½“å¤±è´¥
                else:
                    results[step_name] = None  # éå…³é”®æ­¥éª¤å¯ä»¥è·³è¿‡
        
        return results
```

### è‡ªé€‚åº”è¶…æ—¶

**åŠ¨æ€è°ƒæ•´ç­–ç•¥**
```python
class AdaptiveTimeout:
    def __init__(self):
        self.timeout_history = {}
        self.base_timeout = 30.0
        self.min_timeout = 10.0
        self.max_timeout = 120.0
    
    def get_adaptive_timeout(self, operation_type: str) -> float:
        """åŸºäºå†å²æ•°æ®åŠ¨æ€è°ƒæ•´è¶…æ—¶æ—¶é—´"""
        history = self.timeout_history.get(operation_type, [])
        
        if len(history) < 5:
            return self.base_timeout
        
        # ä½¿ç”¨ P95 ä½œä¸ºè¶…æ—¶åŸºå‡†
        p95_duration = sorted(history)[-max(1, len(history) // 20)]
        
        # æ·»åŠ  50% ç¼“å†²
        adaptive_timeout = p95_duration * 1.5
        
        # é™åˆ¶åœ¨åˆç†èŒƒå›´å†…
        return max(self.min_timeout, 
                  min(self.max_timeout, adaptive_timeout))
    
    def record_duration(self, operation_type: str, duration: float):
        """è®°å½•æ“ä½œè€—æ—¶"""
        if operation_type not in self.timeout_history:
            self.timeout_history[operation_type] = []
        
        # ä¿ç•™æœ€è¿‘ 100 æ¬¡è®°å½•
        history = self.timeout_history[operation_type]
        history.append(duration)
        if len(history) > 100:
            history.pop(0)
```

## å¯è§‚æµ‹æ€§å»ºè®¾

### åˆ†å¸ƒå¼é“¾è·¯è¿½è¸ª

**OpenTelemetry é›†æˆ**

> æ¥æºï¼š[OpenTelemetry å®˜æ–¹æ–‡æ¡£](https://opentelemetry.io/docs/) â€” åˆ†å¸ƒå¼å¯è§‚æµ‹æ€§æ ‡å‡†

```python
from opentelemetry import trace
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor

class AgentTracer:
    def __init__(self):
        # åˆå§‹åŒ– tracer
        trace.set_tracer_provider(TracerProvider())
        tracer = trace.get_tracer(__name__)
        
        # é…ç½® Jaeger å¯¼å‡º
        jaeger_exporter = JaegerExporter(
            agent_host_name="localhost",
            agent_port=14268,
        )
        
        span_processor = BatchSpanProcessor(jaeger_exporter)
        trace.get_tracer_provider().add_span_processor(span_processor)
        
        self.tracer = tracer
    
    def trace_agent_execution(self, session_id: str):
        """Agent æ‰§è¡Œé“¾è·¯è¿½è¸ª"""
        def decorator(func):
            async def wrapper(*args, **kwargs):
                with self.tracer.start_as_current_span(
                    func.__name__,
                    attributes={
                        "session_id": session_id,
                        "operation": func.__name__
                    }
                ) as span:
                    try:
                        result = await func(*args, **kwargs)
                        span.set_attribute("success", True)
                        span.set_attribute("result_length", len(str(result)))
                        return result
                    except Exception as e:
                        span.set_attribute("success", False)
                        span.set_attribute("error", str(e))
                        raise
            return wrapper
        return decorator
```

**LangSmith é›†æˆ**
```python
from langsmith import Client as LangSmithClient
from langsmith.run_helpers import traceable

class LangSmithIntegration:
    def __init__(self, api_key: str, project_name: str):
        self.client = LangSmithClient(api_key=api_key)
        self.project_name = project_name
    
    @traceable(run_type="chain", project_name="agent-production")
    async def trace_agent_workflow(self, user_input: str, session_id: str):
        """å®Œæ•´ Agent å·¥ä½œæµè¿½è¸ª"""
        
        # è®¡åˆ’é˜¶æ®µ
        plan = await self.trace_planning(user_input)
        
        # æ‰§è¡Œé˜¶æ®µ
        execution_results = []
        for step in plan.steps:
            result = await self.trace_step_execution(step)
            execution_results.append(result)
        
        # å“åº”ç”Ÿæˆ
        response = await self.trace_response_generation(execution_results)
        
        return {
            "response": response,
            "plan": plan,
            "execution_results": execution_results,
            "session_id": session_id
        }
    
    @traceable(run_type="llm", project_name="agent-production")
    async def trace_planning(self, user_input: str):
        """è®¡åˆ’ç”Ÿæˆè¿½è¸ª"""
        # LLM è°ƒç”¨ä¼šè‡ªåŠ¨è¢« LangSmith è¿½è¸ª
        return await planning_llm.generate(user_input)
```

### ç»“æ„åŒ–æ—¥å¿—

**æ—¥å¿—æ ‡å‡†åŒ–**
```python
import logging
import json
from datetime import datetime
from typing import Dict, Any

class AgentLogger:
    def __init__(self):
        self.logger = logging.getLogger("agent")
        self.logger.setLevel(logging.INFO)
        
        # JSON æ ¼å¼åŒ–å™¨
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        
        handler = logging.StreamHandler()
        handler.setFormatter(formatter)
        self.logger.addHandler(handler)
    
    def log_agent_event(self, event_type: str, session_id: str, 
                       data: Dict[str, Any], level: str = "info"):
        """ç»“æ„åŒ– Agent äº‹ä»¶æ—¥å¿—"""
        
        log_entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "event_type": event_type,
            "session_id": session_id,
            "data": data
        }
        
        log_message = json.dumps(log_entry, ensure_ascii=False)
        
        if level == "error":
            self.logger.error(log_message)
        elif level == "warning":
            self.logger.warning(log_message)
        else:
            self.logger.info(log_message)

# ä½¿ç”¨ç¤ºä¾‹
logger = AgentLogger()

async def agent_step_with_logging(step_name: str, session_id: str):
    start_time = time.time()
    
    try:
        result = await execute_step(step_name)
        
        logger.log_agent_event("step_completed", session_id, {
            "step_name": step_name,
            "duration": time.time() - start_time,
            "success": True,
            "result_summary": result[:100]
        })
        
        return result
        
    except Exception as e:
        logger.log_agent_event("step_failed", session_id, {
            "step_name": step_name,
            "duration": time.time() - start_time,
            "success": False,
            "error": str(e)
        }, level="error")
        raise
```

### æ€§èƒ½ç›‘æ§

**å…³é”®æŒ‡æ ‡è¿½è¸ª**
```python
import time
import psutil
from prometheus_client import Counter, Histogram, Gauge

class AgentMetrics:
    def __init__(self):
        # è®¡æ•°å™¨
        self.request_total = Counter(
            'agent_requests_total',
            'Total agent requests',
            ['session_type', 'success']
        )
        
        # å“åº”æ—¶é—´åˆ†å¸ƒ
        self.response_time = Histogram(
            'agent_response_seconds',
            'Agent response time',
            ['operation_type']
        )
        
        # å½“å‰çŠ¶æ€
        self.active_sessions = Gauge(
            'agent_active_sessions',
            'Number of active sessions'
        )
        
        self.memory_usage = Gauge(
            'agent_memory_usage_bytes',
            'Memory usage in bytes'
        )
    
    def track_request(self, session_type: str, success: bool):
        """è¿½è¸ªè¯·æ±‚æ•°é‡"""
        self.request_total.labels(
            session_type=session_type,
            success=str(success).lower()
        ).inc()
    
    def track_response_time(self, operation: str, duration: float):
        """è¿½è¸ªå“åº”æ—¶é—´"""
        self.response_time.labels(operation_type=operation).observe(duration)
    
    def update_system_metrics(self):
        """æ›´æ–°ç³»ç»ŸæŒ‡æ ‡"""
        process = psutil.Process()
        self.memory_usage.set(process.memory_info().rss)
```

## äººæœºåä½œæ¨¡å¼

### Human-in-the-loop è®¾è®¡

**åä½œè§¦å‘æœºåˆ¶**
```python
class HumanLoopHandler:
    def __init__(self):
        self.escalation_rules = {
            "low_confidence": 0.7,     # ç½®ä¿¡åº¦é˜ˆå€¼
            "sensitive_operation": ["delete", "modify", "send"],
            "high_value_decision": 1000,  # é‡‘é¢é˜ˆå€¼
            "error_retry_limit": 3
        }
    
    def should_escalate(self, context: dict) -> tuple[bool, str]:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥"""
        
        # ä½ç½®ä¿¡åº¦æ£€æŸ¥
        if context.get("confidence", 1.0) < self.escalation_rules["low_confidence"]:
            return True, "low_confidence"
        
        # æ•æ„Ÿæ“ä½œæ£€æŸ¥
        operation = context.get("operation", "").lower()
        if any(sensitive in operation for sensitive in self.escalation_rules["sensitive_operation"]):
            return True, "sensitive_operation"
        
        # é«˜ä»·å€¼å†³ç­–æ£€æŸ¥
        value = context.get("value", 0)
        if value > self.escalation_rules["high_value_decision"]:
            return True, "high_value_decision"
        
        # é”™è¯¯é‡è¯•æ¬¡æ•°æ£€æŸ¥
        retry_count = context.get("retry_count", 0)
        if retry_count >= self.escalation_rules["error_retry_limit"]:
            return True, "max_retries_exceeded"
        
        return False, ""
    
    async def request_human_input(self, context: dict, reason: str):
        """è¯·æ±‚äººå·¥è¾“å…¥"""
        request_data = {
            "session_id": context["session_id"],
            "reason": reason,
            "context": context,
            "timestamp": datetime.utcnow().isoformat(),
            "priority": self.get_priority(reason)
        }
        
        # å‘é€åˆ°äººå·¥å®¡æ ¸é˜Ÿåˆ—
        await self.send_to_human_queue(request_data)
        
        # ç­‰å¾…äººå·¥å“åº”
        return await self.wait_for_human_response(context["session_id"])
    
    def get_priority(self, reason: str) -> str:
        """æ ¹æ®åŸå› ç¡®å®šä¼˜å…ˆçº§"""
        priority_map = {
            "low_confidence": "medium",
            "sensitive_operation": "high", 
            "high_value_decision": "high",
            "max_retries_exceeded": "low"
        }
        return priority_map.get(reason, "medium")
```

**åä½œç•Œé¢è®¾è®¡**
```python
class HumanCollaborationUI:
    def __init__(self):
        self.pending_requests = {}
        self.ui_components = {
            "context_display": self.render_context,
            "action_selector": self.render_actions,
            "feedback_input": self.render_feedback
        }
    
    def render_collaboration_request(self, request_data: dict):
        """æ¸²æŸ“äººå·¥åä½œè¯·æ±‚ç•Œé¢"""
        return {
            "title": f"Human Input Required: {request_data['reason']}",
            "context": {
                "session_id": request_data["session_id"],
                "user_query": request_data["context"]["user_input"],
                "agent_analysis": request_data["context"]["agent_analysis"],
                "confidence_score": request_data["context"]["confidence"],
                "suggested_actions": request_data["context"]["suggestions"]
            },
            "actions": [
                {"type": "approve", "label": "Approve Agent Action"},
                {"type": "modify", "label": "Modify and Continue"},
                {"type": "takeover", "label": "Take Over Manually"},
                {"type": "escalate", "label": "Escalate to Expert"}
            ],
            "feedback_form": {
                "fields": [
                    {"name": "comments", "type": "textarea", "required": False},
                    {"name": "confidence", "type": "slider", "min": 0, "max": 100}
                ]
            }
        }
```

## æˆæœ¬æ§åˆ¶ç­–ç•¥

### Token é¢„ç®—ç®¡ç†

**é¢„ç®—åˆ†é…**
```python
class TokenBudgetManager:
    def __init__(self):
        self.budgets = {
            "daily_limit": 100000,      # æ¯æ—¥æ€»é¢„ç®—
            "session_limit": 5000,      # å•ä¼šè¯é¢„ç®—
            "operation_limits": {
                "planning": 1000,       # è®¡åˆ’ç”Ÿæˆ
                "tool_calls": 2000,     # å·¥å…·è°ƒç”¨
                "response": 1500,       # å“åº”ç”Ÿæˆ
                "reflection": 500       # åæ€ä¼˜åŒ–
            }
        }
        
        self.usage_tracker = {
            "daily_used": 0,
            "session_usage": {},
            "operation_usage": {}
        }
    
    def check_budget(self, operation: str, estimated_tokens: int, 
                    session_id: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿé¢„ç®—"""
        
        # æ£€æŸ¥æ—¥é¢„ç®—
        if self.usage_tracker["daily_used"] + estimated_tokens > self.budgets["daily_limit"]:
            return False
        
        # æ£€æŸ¥ä¼šè¯é¢„ç®—
        session_used = self.usage_tracker["session_usage"].get(session_id, 0)
        if session_used + estimated_tokens > self.budgets["session_limit"]:
            return False
        
        # æ£€æŸ¥æ“ä½œé¢„ç®—
        operation_limit = self.budgets["operation_limits"].get(operation, 1000)
        if estimated_tokens > operation_limit:
            return False
        
        return True
    
    def consume_budget(self, operation: str, actual_tokens: int, 
                      session_id: str):
        """æ¶ˆè´¹é¢„ç®—"""
        self.usage_tracker["daily_used"] += actual_tokens
        
        if session_id not in self.usage_tracker["session_usage"]:
            self.usage_tracker["session_usage"][session_id] = 0
        self.usage_tracker["session_usage"][session_id] += actual_tokens
        
        if operation not in self.usage_tracker["operation_usage"]:
            self.usage_tracker["operation_usage"][operation] = 0
        self.usage_tracker["operation_usage"][operation] += actual_tokens
```

### ç¼“å­˜ç­–ç•¥

**å¤šå±‚ç¼“å­˜è®¾è®¡**
```python
import hashlib
import json
from typing import Optional, Any

class AgentCacheManager:
    def __init__(self):
        self.memory_cache = {}  # å†…å­˜ç¼“å­˜
        self.redis_client = redis.Redis()  # åˆ†å¸ƒå¼ç¼“å­˜
        
        self.cache_policies = {
            "llm_responses": {
                "ttl": 3600,  # 1å°æ—¶
                "max_size": 1000
            },
            "tool_results": {
                "ttl": 1800,  # 30åˆ†é’Ÿ
                "max_size": 500
            },
            "user_profiles": {
                "ttl": 86400,  # 24å°æ—¶
                "max_size": 100
            }
        }
    
    def generate_cache_key(self, cache_type: str, content: Any) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        content_str = json.dumps(content, sort_keys=True, ensure_ascii=False)
        content_hash = hashlib.md5(content_str.encode()).hexdigest()
        return f"{cache_type}:{content_hash}"
    
    async def get_cached_response(self, cache_type: str, 
                                content: Any) -> Optional[Any]:
        """è·å–ç¼“å­˜å“åº”"""
        cache_key = self.generate_cache_key(cache_type, content)
        
        # å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
        if cache_key in self.memory_cache:
            return self.memory_cache[cache_key]
        
        # å†æ£€æŸ¥ Redis ç¼“å­˜
        cached_data = await self.redis_client.get(cache_key)
        if cached_data:
            result = json.loads(cached_data)
            # å›å¡«å†…å­˜ç¼“å­˜
            self.memory_cache[cache_key] = result
            return result
        
        return None
    
    async def cache_response(self, cache_type: str, content: Any, 
                           response: Any):
        """ç¼“å­˜å“åº”"""
        cache_key = self.generate_cache_key(cache_type, content)
        policy = self.cache_policies.get(cache_type, {})
        
        # æ›´æ–°å†…å­˜ç¼“å­˜
        self.memory_cache[cache_key] = response
        self._trim_memory_cache(cache_type)
        
        # æ›´æ–° Redis ç¼“å­˜
        await self.redis_client.setex(
            cache_key,
            policy.get("ttl", 3600),
            json.dumps(response, ensure_ascii=False)
        )
```

### æˆæœ¬ç›‘æ§å‘Šè­¦

**æˆæœ¬ç›‘æ§ä»ªè¡¨æ¿**
```python
class CostMonitor:
    def __init__(self):
        self.cost_config = {
            "gpt-4": {"input": 0.03, "output": 0.06},   # per 1K tokens
            "gpt-3.5": {"input": 0.001, "output": 0.002},
            "claude-3": {"input": 0.015, "output": 0.075}
        }
        
        self.alerts = {
            "daily_budget": {"threshold": 100, "current": 0},
            "session_spike": {"threshold": 10, "lookback": "1h"},
            "error_rate": {"threshold": 0.1, "lookback": "5m"}
        }
    
    def calculate_cost(self, model: str, input_tokens: int, 
                      output_tokens: int) -> float:
        """è®¡ç®—å•æ¬¡è°ƒç”¨æˆæœ¬"""
        if model not in self.cost_config:
            return 0.0
        
        config = self.cost_config[model]
        input_cost = (input_tokens / 1000) * config["input"]
        output_cost = (output_tokens / 1000) * config["output"]
        
        return input_cost + output_cost
    
    def check_cost_alerts(self) -> list:
        """æ£€æŸ¥æˆæœ¬å‘Šè­¦"""
        alerts = []
        
        # æ£€æŸ¥æ—¥é¢„ç®—
        if self.alerts["daily_budget"]["current"] > self.alerts["daily_budget"]["threshold"]:
            alerts.append({
                "type": "budget_exceeded",
                "message": f"Daily budget exceeded: ${self.alerts['daily_budget']['current']:.2f}"
            })
        
        return alerts
```

## é¢è¯•å¸¸è§é—®é¢˜

### Q1: Agent ç”Ÿäº§ç¯å¢ƒä¸­æœ€å¸¸è§çš„é—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹ï¼š**
- **ç½‘ç»œå¼‚å¸¸**ï¼šAPI è°ƒç”¨å¤±è´¥ã€è¶…æ—¶ï¼Œéœ€è¦å®Œå–„çš„é‡è¯•æœºåˆ¶
- **æˆæœ¬æ§åˆ¶**ï¼šToken æ¶ˆè´¹å¤±æ§ï¼Œéœ€è¦é¢„ç®—ç®¡ç†å’Œç¼“å­˜ä¼˜åŒ–
- **è´¨é‡ç¨³å®šæ€§**ï¼šè¾“å‡ºä¸ä¸€è‡´ï¼Œéœ€è¦ç½®ä¿¡åº¦è¯„ä¼°å’Œäººå·¥å…œåº•
- **å¹¶å‘å¤„ç†**ï¼šé«˜å¹¶å‘æ—¶çš„èµ„æºäº‰æŠ¢å’Œæ€§èƒ½ä¸‹é™

### Q2: å¦‚ä½•è®¾è®¡ Agent çš„é”™è¯¯å¤„ç†ç­–ç•¥ï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹ï¼š**
- **åˆ†ç±»å¤„ç†**ï¼šç³»ç»Ÿé”™è¯¯ vs ä¸šåŠ¡é”™è¯¯ï¼Œä¸åŒçš„é‡è¯•ç­–ç•¥
- **æŒ‡æ•°é€€é¿**ï¼šé¿å…é›·ç¾¤æ•ˆåº”ï¼ŒåŠ å…¥æŠ–åŠ¨æœºåˆ¶
- **ç†”æ–­é™çº§**ï¼šæœåŠ¡ä¸å¯ç”¨æ—¶å¿«é€Ÿå¤±è´¥ï¼Œé¿å…çº§è”æ•…éšœ
- **å…œåº•æ–¹æ¡ˆ**ï¼šè§„åˆ™å¼•æ“ â†’ äººå·¥æ¥ç®¡çš„å¤šå±‚é™çº§

### Q3: Agent çš„å¯è§‚æµ‹æ€§å¦‚ä½•å»ºè®¾ï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹ï¼š**
- **é“¾è·¯è¿½è¸ª**ï¼šå®Œæ•´çš„æ‰§è¡Œæµç¨‹è¿½è¸ªï¼Œé—®é¢˜å¿«é€Ÿå®šä½
- **ç»“æ„åŒ–æ—¥å¿—**ï¼šç»Ÿä¸€æ ¼å¼ï¼Œä¾¿äºæœç´¢å’Œåˆ†æ
- **æ€§èƒ½ç›‘æ§**ï¼šå“åº”æ—¶é—´ã€æˆåŠŸç‡ã€èµ„æºä½¿ç”¨ç­‰å…³é”®æŒ‡æ ‡
- **ä¸šåŠ¡ç›‘æ§**ï¼šç”¨æˆ·æ»¡æ„åº¦ã€ä»»åŠ¡å®Œæˆç‡ç­‰ä¸šåŠ¡æŒ‡æ ‡

### Q4: ä½•æ—¶å¼•å…¥äººå·¥ä»‹å…¥ï¼ˆHuman-in-the-loopï¼‰ï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹ï¼š**
- **ä½ç½®ä¿¡åº¦**ï¼šAgent å¯¹ç»“æœä¸ç¡®å®šæ—¶
- **æ•æ„Ÿæ“ä½œ**ï¼šæ¶‰åŠåˆ é™¤ã€ä¿®æ”¹ã€å‘é€ç­‰å…³é”®æ“ä½œ
- **é«˜ä»·å€¼å†³ç­–**ï¼šè¶…è¿‡ä¸€å®šé‡‘é¢æˆ–å½±å“èŒƒå›´çš„å†³ç­–
- **å¼‚å¸¸æƒ…å†µ**ï¼šå¤šæ¬¡é‡è¯•å¤±è´¥æˆ–å‡ºç°æœªçŸ¥é”™è¯¯

### Q5: Agent ç³»ç»Ÿçš„æˆæœ¬å¦‚ä½•æ§åˆ¶ï¼Ÿ

**ç­”æ¡ˆè¦ç‚¹ï¼š**
- **é¢„ç®—ç®¡ç†**ï¼šæ—¥/å‘¨/æœˆé¢„ç®—é™åˆ¶ï¼Œè¶…é¢„ç®—è‡ªåŠ¨åœæ­¢
- **æ™ºèƒ½ç¼“å­˜**ï¼šç»“æœç¼“å­˜ã€è¯­ä¹‰ç¼“å­˜å‡å°‘é‡å¤è°ƒç”¨
- **æ¨¡å‹é€‰æ‹©**ï¼šæ ¹æ®ä»»åŠ¡å¤æ‚åº¦é€‰æ‹©åˆé€‚è§„æ¨¡çš„æ¨¡å‹
- **ç›‘æ§å‘Šè­¦**ï¼šå®æ—¶ç›‘æ§æˆæœ¬å¼‚å¸¸ï¼ŒåŠæ—¶ä»‹å…¥å¤„ç†

---

## ğŸ“š æ¨èé˜…è¯»

### åŸå§‹è®ºæ–‡ / æ–‡æ¡£
- [Building Effective Agents â€” Anthropic](https://www.anthropic.com/research/building-effective-agents) â€” ç”Ÿäº§ Agent è®¾è®¡çš„æœ€æƒå¨å·¥ç¨‹æŒ‡å— â­â­â­â­â­
- [AgentBench: Evaluating LLMs as Agents](https://arxiv.org/abs/2308.03688) â€” Liu et al., 8 ä¸ªç»´åº¦è¯„ä¼° Agent å¯é æ€§
- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/) â€” æœ‰çŠ¶æ€ Agent å·¥ä½œæµçš„ç”Ÿäº§çº§æ¡†æ¶ â­â­â­â­
- [Practices for Governing Agentic AI Systems â€” OpenAI](https://cdn.openai.com/papers/practices-for-governing-agentic-ai-systems.pdf) â€” Agent æ²»ç†ä¸å®‰å…¨çš„å®è·µæŒ‡å—

### æ·±åº¦è§£è¯»
- [OpenTelemetry for LLM Observability](https://opentelemetry.io/blog/2024/llm-observability/) â€” LLM åº”ç”¨å¯è§‚æµ‹æ€§æœ€ä½³å®è·µ â­â­â­â­
- [LangSmith Cookbook](https://docs.smith.langchain.com/cookbook) â€” Agent è¿½è¸ªä¸è°ƒè¯•çš„å®æˆ˜æ¡ˆä¾‹é›† â­â­â­

### å®è·µèµ„æº
- [LangGraph](https://github.com/langchain-ai/langgraph) â€” åŸºäºå›¾çš„ Agent å·¥ä½œæµæ¡†æ¶ï¼ŒåŸç”Ÿæ”¯æŒæŒä¹…åŒ–/ä¸­æ–­/æ¢å¤
- [CrewAI](https://github.com/joaomdmoura/crewAI) â€” å¤š Agent åä½œæ¡†æ¶ï¼Œå†…ç½®è§’è‰²åˆ†å·¥ä¸ä»»åŠ¡ç¼–æ’
- [Prometheus + Grafana Agent ç›‘æ§æ¨¡æ¿](https://grafana.com/) â€” å¼€ç®±å³ç”¨çš„ Agent æ€§èƒ½ç›‘æ§ä»ªè¡¨æ¿

---

## ğŸ”§ è½åœ°åº”ç”¨

### ç›´æ¥å¯ç”¨åœºæ™¯
- **API å¯†é›†å‹ Agent**ï¼šä½¿ç”¨æœ¬æ–‡çš„æŒ‡æ•°é€€é¿é‡è¯• + ç†”æ–­æœºåˆ¶ï¼ˆCircuitBreakerï¼‰å¤„ç† LLM API çš„é™æµå’Œä¸ç¨³å®š
- **ä¼ä¸šå®¢æœ Agent**ï¼šHuman-in-the-loop è®¾è®¡ï¼ˆä½ç½®ä¿¡åº¦/æ•æ„Ÿæ“ä½œè‡ªåŠ¨å‡çº§äººå·¥ï¼‰ï¼Œæˆæœ¬æ§åˆ¶ç”¨ Token é¢„ç®—ç®¡ç†
- **é•¿æ—¶ä»»åŠ¡ Agent**ï¼šåˆ†æ®µè¶…æ—¶ç­–ç•¥ï¼ˆStepwiseTimeoutHandlerï¼‰+ è‡ªé€‚åº”è¶…æ—¶ï¼ˆP95 å†å²æ•°æ®åŠ¨æ€è°ƒæ•´ï¼‰

### å·¥ç¨‹å®ç°è¦ç‚¹
- **é‡è¯•ç­–ç•¥é»„é‡‘æ³•åˆ™**ï¼šç½‘ç»œé”™è¯¯ â†’ å¿«é‡è¯•ï¼ˆ0.5s base, 5 retriesï¼‰ï¼›é™æµ â†’ æ…¢é‡è¯•ï¼ˆ10s base, 3 retriesï¼‰ï¼›è®¤è¯é”™è¯¯ â†’ ä¸é‡è¯•
- **æˆæœ¬æ§åˆ¶æ ¸å¿ƒå…¬å¼**ï¼š

$$C_{total} = \sum_{i=1}^{N} \frac{T_{input}^{(i)}}{1000} \cdot P_{input} + \frac{T_{output}^{(i)}}{1000} \cdot P_{output}$$

å…¶ä¸­ $T$ æ˜¯ token æ•°ï¼Œ$P$ æ˜¯æ¯åƒ token ä»·æ ¼ã€‚æ—¥é¢„ç®—ä¸Šé™ + ä¼šè¯é¢„ç®— + æ“ä½œé¢„ç®—ä¸‰å±‚æ§åˆ¶

- **å¯è§‚æµ‹æ€§ä¸‰æ”¯æŸ±**ï¼šTracesï¼ˆé“¾è·¯è¿½è¸ªï¼Œæ¯æ­¥éª¤è€—æ—¶+å‚æ•°ï¼‰+ Metricsï¼ˆQPS/å»¶è¿Ÿ/æˆåŠŸç‡ï¼‰+ Logsï¼ˆç»“æ„åŒ– JSONï¼Œå« session_idï¼‰

### é¢è¯•é«˜é¢‘é—®æ³•
- Q: Agent ç”Ÿäº§ç¯å¢ƒæœ€å¸¸è§çš„é—®é¢˜ï¼Ÿ
  A: ç½‘ç»œå¼‚å¸¸ï¼ˆé‡è¯•+ç†”æ–­ï¼‰ã€æˆæœ¬å¤±æ§ï¼ˆé¢„ç®—ç®¡ç†+ç¼“å­˜ï¼‰ã€è´¨é‡ä¸ç¨³å®šï¼ˆç½®ä¿¡åº¦è¯„ä¼°+äººå·¥å…œåº•ï¼‰ã€å¹¶å‘æ€§èƒ½ï¼ˆè¿æ¥æ± +é™æµï¼‰
- Q: ä½•æ—¶å¼•å…¥ Human-in-the-loopï¼Ÿ
  A: ä½ç½®ä¿¡åº¦(<0.7) / æ•æ„Ÿæ“ä½œ(delete/send/pay) / é«˜ä»·å€¼å†³ç­–(>é˜ˆå€¼é‡‘é¢) / å¤šæ¬¡é‡è¯•å¤±è´¥

---

## ğŸ’¡ å¯å‘ä¸æ€è€ƒ

### So Whatï¼Ÿå¯¹è€æ¿æ„å‘³ç€ä»€ä¹ˆ
- **Agent å¯é æ€§ = ç³»ç»Ÿå·¥ç¨‹ï¼Œä¸æ˜¯æ¨¡å‹èƒ½åŠ›**ï¼šæœ€å¼ºçš„ GPT-4 ä¹Ÿéœ€è¦é‡è¯•/ç†”æ–­/é™çº§/ç›‘æ§ï¼Œç”Ÿäº§ Agent çš„æ ¸å¿ƒç«äº‰åŠ›åœ¨å·¥ç¨‹ä½“ç³»è€Œéæ¨¡å‹é€‰å‹
- **æˆæœ¬æ§åˆ¶æ˜¯ Agent è§„æ¨¡åŒ–çš„å…³é”®ç“¶é¢ˆ**ï¼šToken æ¶ˆè´¹éš Agent å¤æ‚åº¦æŒ‡æ•°å¢é•¿ï¼Œæ™ºèƒ½ç¼“å­˜ï¼ˆè¯­ä¹‰ç¼“å­˜ï¼‰+ æ¨¡å‹è·¯ç”±ï¼ˆç®€å•ä»»åŠ¡ç”¨å°æ¨¡å‹ï¼‰æ˜¯å¿…å¤‡èƒ½åŠ›

### æœªè§£é—®é¢˜ä¸å±€é™
- **ç«¯åˆ°ç«¯å»¶è¿Ÿä¼˜åŒ–**ï¼šå¤š tool è°ƒç”¨åœºæ™¯ä¸‹ï¼Œæ€»å»¶è¿Ÿ = Î£(LLMæ¨ç† + toolæ‰§è¡Œ) å¯èƒ½è¶…è¿‡ç”¨æˆ·å®¹å¿é˜ˆå€¼ï¼ˆé€šå¸¸ <30sï¼‰ï¼Œæµå¼è¾“å‡º+å¹¶è¡Œ tool è°ƒç”¨æ˜¯æ–¹å‘ä½†å®ç°å¤æ‚
- **Agent çŠ¶æ€æŒä¹…åŒ–**ï¼šé•¿æ—¶ Agent çš„ä¸­é—´çŠ¶æ€å¦‚ä½•å®‰å…¨å­˜å‚¨å’Œæ¢å¤ï¼ŸLangGraph çš„ checkpointing æ˜¯å½“å‰æœ€ä½³å®è·µä½†ä»æœ‰åºåˆ—åŒ–é™åˆ¶
- **å¤š Agent åä½œçš„å¯è§‚æµ‹æ€§**ï¼šå½“å¤šä¸ª Agent å¹¶è¡Œæ‰§è¡Œï¼Œtrace çš„å› æœå…³ç³»å’Œæ—¶åºå¯¹é½å˜å¾—æä¸ºå¤æ‚

### è„‘æš´ï¼šå¦‚æœå¾€ä¸‹å»¶ä¼¸
- å°†æœ¬æ–‡çš„ç†”æ–­é™çº§æ¨¡å¼ä¸ [[AI/2-Agent/Fundamentals/ReAct ä¸ CoT|ReAct]] çš„ Reflexion ç»“åˆï¼šAgent åœ¨ç†”æ–­åä¸åªæ˜¯é™çº§åˆ°è§„åˆ™å¼•æ“ï¼Œè€Œæ˜¯åŸºäºå¤±è´¥åŸå› åæ€å¹¶è‡ªåŠ¨åˆ‡æ¢æ¨ç†ç­–ç•¥
- Token é¢„ç®—ç®¡ç† + [[AI/3-LLM/Application/å¹»è§‰é—®é¢˜|å¹»è§‰æ£€æµ‹]]ï¼šé¢„ç®—ç´§å¼ æ—¶ Agent å€¾å‘äºç”Ÿæˆæ›´çŸ­å›ç­” â†’ å¯èƒ½å¢åŠ å¹»è§‰ç‡ã€‚éœ€è¦åœ¨æˆæœ¬å’Œè´¨é‡ä¹‹é—´å»ºç«‹åŠ¨æ€å¹³è¡¡æœºåˆ¶
- 6 ä¸ªæœˆé¢„åˆ¤ï¼šAgent å¯è§‚æµ‹æ€§å°†ä»"è‡ªå»º"èµ°å‘"æ ‡å‡†åŒ–"ï¼ŒOpenTelemetry çš„ LLM è¯­ä¹‰çº¦å®šå°†æˆä¸ºè¡Œä¸šæ ‡å‡†

```mermaid
flowchart TD
    subgraph Agentç”Ÿäº§æ¶æ„
        A[ç”¨æˆ·è¯·æ±‚] --> B{è¾“å…¥éªŒè¯}
        B --> C[Agent æ¨ç†å¾ªç¯]
        C --> D{Tool è°ƒç”¨}
        D -->|æˆåŠŸ| E[ç»“æœå¤„ç†]
        D -->|å¤±è´¥| F{é‡è¯•ç­–ç•¥}
        F -->|é‡è¯•| D
        F -->|ç†”æ–­| G[é™çº§æ–¹æ¡ˆ]
        G --> H[è§„åˆ™å¼•æ“]
        G --> I[äººå·¥æ¥ç®¡]
        E --> J{ç½®ä¿¡åº¦æ£€æŸ¥}
        J -->|é«˜| K[è¿”å›ç»“æœ]
        J -->|ä½| I
    end
```

---

## ç›¸å…³æ¦‚å¿µ

- [[AI/2-Agent/Fundamentals/ReAct ä¸ CoT|ReAct ä¸ CoT]] â€” Agent æ¨ç†æ¨¡å¼çš„ç†è®ºåŸºç¡€
- [[AI/2-Agent/Fundamentals/Tool Use|Tool Use]] â€” å·¥å…·è°ƒç”¨å®‰å…¨ä¸æœ€ä½³å®è·µ
- AI Agent æŠ€æœ¯å…¨æ™¯ â€” Agent ç”Ÿäº§æ¶æ„åœ¨å…¨æ™¯ä¸­çš„ä½ç½®
- AI å®‰å…¨ä¸å¯¹é½ â€” Agent å®‰å…¨é˜²æŠ¤çš„å®Œæ•´æ¡†æ¶
- [[AI/3-LLM/Application/å¹»è§‰é—®é¢˜|å¹»è§‰é—®é¢˜]] â€” Agent è¾“å‡ºå¯é æ€§çš„æ ¸å¿ƒæŒ‘æˆ˜