---
title: "3. Spark 生产运维"
category: "工程"
tags: [Join, SQL, Spark, YARN, 流处理]
created: "2026-02-13"
updated: "2026-02-13"
---

# 3. Spark 生产运维

Spark出问题主要分为这几类

1. 作业失败
1. 作业跑得慢
1. 计算结果不符合预期
**分析思路**

1. 逐步缩小出问题的范围（首先要知道问题出在哪）
1. Spark作业是主从架构的，分为Driver和Executor，我们需要区分是Driver出问题还是Executor出问题
1. Spark是三个层次的计算——Job、Stage、Task，如果我们要定位作业的失败原因，那我们可以先定位失败的Job，然后定位失败的Stage，最后定位失败的Task
1. 可以把计算结果不符合预期的最小的点抽取出来，比如一个大SQL，需要逐步拆分SQL，直到找到出问题的子查询、Select或Join或Where或Group by等等
1. 分析关键日志（具体看出问题的原因）
1. 根据[Spark作业的日志查看指南](https%3A%2F%2Fkm.sankuai.com%2Fpage%2F28449367)，我们知道比较重要的组件是Driver、Executor、ApplicationMaster，每种组件都有自己的stdout(标准输出日志)、stderr(标准错误日志)、syslog(spark的日志)，优先级别是Driver = Executor > ApplicationMaster，syslog > stdout = stderr
1. 对于yarn-client模式来说，driver的日志在客户端，在spark-ui上会看不到，需要找用户拿到客户端日志
### 一、看 Executor 日志

1. Syslog
syslog是spark的日志，由于Executor上可能会并发运行多个Task，因此日志中可能会有多个Task的日志交叉在一起

如果我们要搜Task 0的日志，可以搜索“Executor task launch worker for task 0 ”，有些线程的名字不一定是“Executor task launch worker for task xxx”，但也有可能是task 0启动的子线程（比如开了子线程去请求hdfs），或者与该Task有关（比如“CoarseGrainedExecutorBackend: Got assigned task 0”的线程名是CoarseGrainedExecutorBackend，但与task 0有关）

正常情况下，一个Task xxx开始的日志是“Got assigned task xxx”，结束的日志是“Executor task launch worker for task xxx Executor: Finished task xxx.yyy in stage”

1. Stdlog
一般是用户自己打印的日志，比如java的System.out.println，scala的println，pyspark的print

用来给用户定位问题，比如说打印当前步骤在干嘛，参数是什么，耗时多少，遇到什么异常

1. Stderr
会有spark每隔10分钟打印的jstack，用来分析一个作业曾经卡在那哪逻辑中（如果作业正在跑，我们也可以看Spark-ui的Executors页面的Thread dump链接）

还有gc累计时间，还有包含用户自己打印的stderr日志，比如java的System.err.println

我们可以按线程名来所有某个跑得很慢的task在干嘛，格式是“Executor task launch worker for task xxx”

### 二、看 Diver 日志

1. Syslog
包含yarn的启动命令、资源文件、执行的SQL，Executor的申请、Job、Stage的提交周期打印Executor资源情况，sparkContext的关闭等等日志

在分析作业失败原因时，同在异常会打印在“SparkContext: SparkContext already stopped.”日志的上面

比如发现作业执行时间变长，但真正计算时间没太大变化，可能是 Driver 引起的，排查：

- **commit job 时间**：在syslog中搜索“Committer commit job use”
- **get split 时间**：在syslog中搜索“getSplits finished using” 
1. Stdlog：同 Executor
1. Stderr
会有spark每隔10分钟打印的jstack，用来分析一个作业曾经卡在哪段逻辑中，在Driver中，我们主要分析线程名叫“Driver”的线程（如果作业正在跑，我们也可以看Spark-ui的Executors页面的Thread dump链接）

还有gc累计时间，还有包含用户自己打印的stderr日志，比如java的System.err.println

在某些情况下，可能是Driver卡住（比如输入数据的getSplits，表的commit）,用这个日志进行分析尤其有用

### 三、AM 日志

AM日志（和Driver日志类似，一般情况下看到Driver日志即可）

1. Spark streaming以及基本工作原理？
https://blog.csdn.net/qq_21125183/article/details/87917075

1. DStream以及基本工作原理？
1. Spark主备切换机制原理知道吗？
[spark内核源码深度剖析(五):Master主备切换机制原理剖析与源码分析 - 墨天轮](https%3A%2F%2Fwww.modb.pro%2Fdb%2F133772)

Spark HA（High Availability，高可用性）主从切换的具体流程主要涉及以下几个步骤：

1. **故障检测**：在Spark HA集群中，通常使用ZooKeeper来监控Master节点的状态。ZooKeeper通过心跳机制检测Master节点是否存活。如果Master节点出现故障，ZooKeeper将无法收到心跳信号，从而触发故障检测机制。
1. **选举新Master**：一旦检测到当前活动的Master节点故障，ZooKeeper将启动选举机制，从剩余的备用（Standby）Master节点中选出一台成为新的活动Master节点。这个过程利用了ZooKeeper的Leader Election机制，确保同一时间只有一个Master是活动状态的。**1**
1. **状态恢复**：新选举出来的Master节点会从ZooKeeper中恢复集群的状态信息，包括所有的Worker、Driver和Application信息。这些信息对于集群的正常运行至关重要，因为它们记录了集群中各个组件的当前状态和配置。**1**
1. **服务切换**：在新Master节点恢复状态信息后，它将接管原Master节点的职责，开始接收客户端的请求并管理集群资源。此时，客户端可以继续提交新的应用程序，而不会受到Master故障的影响。**1**
1. **故障节点隔离**：如果故障的Master节点恢复后，它将作为备用节点加入集群，但不会立即提供服务，直到当前活动Master再次出现故障并触发新一轮的选举过程。**1**
1. **通知客户端**：在主从切换过程中，客户端可能需要重新连接到新的活动Master节点。这通常通过在客户端配置中指定ZooKeeper的地址来实现，客户端可以通过ZooKeeper发现当前活动的Master节点并建立连接。**2**
1. **监控和日志**：整个切换过程应该被详细记录，以便后续分析和审计。监控工具可以用于实时监控系统状态，而日志记录则有助于追踪问题和优化切换流程。
需要注意的是，Spark HA的主从切换过程对正在运行的应用程序影响较小，因为应用程序在运行前已经向Master申请了资源，运行时Driver负责与Executor进行通信，管理整个应用程序。因此，Master的故障对应用程序的运行不会产生影响，但是会影响新应用程序的提交。

如何确保切换平滑性？

确保Spark HA（High Availability，高可用性）主从切换的平滑性，主要涉及到Spark集群的故障恢复能力和负载均衡策略。以下是一些关键的措施和步骤：

1. **基于ZooKeeper的Standby Masters**：
- Spark可以利用ZooKeeper的Leader Election机制来实现多个Master之间的无缝切换。在这种模式下，集群中会启动多个Master，它们都向ZooKeeper注册，但同一时间只有一个Master是活动状态（Active），其他的是备用状态（Standby）。当Active Master出现故障时，ZooKeeper会自动从Standby Master中选举一个新的Active Master，从而实现故障的自动恢复。
1. **配置参数**：
- 在Spark的配置文件`spark-env.sh`中，需要设置`spark.deploy.recoveryMode`为`ZOOKEEPER`，以开启基于ZooKeeper的恢复模式。同时，还需要配置`spark.deploy.zookeeper.url`指向ZooKeeper集群的地址，以及`spark.deploy.zookeeper.dir`指定Spark信息在ZooKeeper中的保存目录。
1. **负载均衡**：
- 为了确保主从切换后的负载均衡，Spark的JDBCServer可以采用多主实例模式。在这种模式下，集群中同时共存多个JDBCServer服务，客户端可以随机连接其中的任意一个服务进行业务操作。这样，当一个JDBCServer服务停止工作时，客户端可以自动连接到其他正常的JDBCServer服务，从而实现服务的不中断或少中断。
1. **会话管理**：
- 在HA方案中，每个JDBCServer实例都是独立且等同的，当其中一个实例在升级或者业务中断时，其他的实例也能接受客户端的连接请求。但是，当一个实例异常退出时，其他实例不会接管此实例上的会话，也不会接管此实例上运行的业务。这意味着会话和任务的恢复需要由客户端或者应用程序本身来处理。
1. Spark master HA主从切换过程不会影响到集群已有作业的运行，为什么
Spark master HA（高可用性）主从切换过程不会影响集群已有作业的运行，主要原因如下：

1. **资源申请已完成**：在Spark作业开始运行之前，Driver程序已经通过Cluster Manager（如YARN、Mesos等）申请了所需的计算资源。一旦资源分配完成，作业的调度和处理就不再依赖于Master节点。
1. **Driver与Executors的通信**：在作业运行过程中，Driver程序负责作业的调度和Task的分配，而Executor负责执行具体的计算任务。Driver与Executors之间的通信并不需要通过Master节点，因此Master节点的切换不会影响它们之间的通信和数据交换。
1. **作业的独立性**：Spark作业在运行过程中具有独立性，它们不依赖于Master节点的状态。这意味着即使Master节点发生故障或进行切换，已经运行的作业仍然可以继续执行，直到完成。
1. spark master使用zookeeper进行ha，有哪些源数据保存到Zookeeper里面
在 Apache Spark 集群中配置 Zookeeper 进行高可用性 (HA) 时，以下是详细的源数据信息，可以被保存到 Zookeeper 中：

1. **Spark Master 的状态信息**：
- **Leader 选举信息**：Spark Master 使用 Zookeeper 进行领导者（Leader）选举。当前的活动 Master 角色会记录在 Zookeeper 中，这样从节点可以随时找到当前的主控节点。
- **Master Endpoints**：记录活跃主节点的地址信息（IP地址和端口）。当主节点发生变化时，新的主节点信息会更新到 Zookeeper。
- **健康检查信息**：各个 Master 节点的健康状态及心跳信息，以便于进行故障切换。
1. **Driver 和 Application 信息**：
- **Application 状态**：当前正在运行的应用程序的状态信息，包括应用程序ID、名称、提交时间、运行状态（如RUNNING, COMPLETED, FAILED）等。
- **Driver 信息**：Driver 的相关信息，包括 Driver ID、所在的节点、运行状态等。
- **调度数据**：应用程序的调度信息，如等待中的任务、正在执行的任务等。
1. **Executor 信息**：
- **Executor 配置**：包括每个 Executor 的内存配置、CPU 核心数配置等。
- **Executor 状态**：当前分配的 Executors 的状态信息，如已分配的资源、所在节点地址、运行状态（如ACTIVE, LOST, FAILED）等。
- **资源心跳信息**：与 Executors 之间的心跳信息，以确保资源状态的及时同步。
1. **临时状态及控制信息**：
- **任务状态和进度**：各个 Stage 和 Task 的状态、进度、执行节点等信息。
- **失败信息及重试记录**：关于任务失败的相关信息以及重试策略记录。
- **资源分配和调度信息**：记录集群中资源的实时分配情况和调度策略信息。
通过将以上信息保存到 Zookeeper，Spark 集群可以在 Master 节点发生故障时快速进行角色转换，新的 Master 节点可以从 Zookeeper 中读取之前保存的数据，继续集群的管理和调度工作。这一机制保证了集群的高可用性和计算任务的持续性。
