一、背景与目标

现阶段，对于固化类的场景（xBR异动分析、播报等），已实践证明可采用工作流编排的方式来为业务提效（住宿在业务小助手平台已沉淀730+工作流，覆盖战役播报、周报月报、销售定策略及xBR监控分析等各类场景），工作流编排的好处在于：将复杂问题人为拆解成多个节点，并编排成工作流，执行稳定，结果可解释。但其弊端也很明显：有学习成本，依赖人梳理SOP，需要时间配置。

对于非固化类场景，分析思路不固定，即无法通过工作流编排的方式来穷举分析路径，对于这类场景，业务也不希望千篇一律地按照固有思路去分析，更希望借助LLM的能力，来启发式地给一些建议和策略。对于业界有几个比较知名的开源框架：MetaGPT、AutoGen、LangGraph等，但是司内司外尚未有最佳实践。为此我们亟需探索LLM自主规划并完成复杂任务的范式，并积累经验。

目标：以节假日场景为试点，结合工程化手段来探索模型的能力边界。驱动升级框架能力，扩展工具，不断打磨效果，为未来进一步泛化到其他分析场景铺路。

二、关键成果

节假日场景探索：单纯依赖模型尚无法完成L3阶段的分析能力，基于Multi-Agent框架，利用工程化手段（细节见第三、四章）结合LLM，主Planner将复杂问题拆解成专题（跨数据域），并由分析数据子Agent和生成报告子Agent完成节假日分析报告的撰写。

对标L6商分能力矩阵，通过90%简单题+10%困难题构成的评测集考察模型表现，当前评测得分在70分左右（春节70分、五一可评测项中各项得分略优于春节、清明暂未经最新模型实验）。

区分4大能力项来看：

数据准确性（100分）：在商分可接受的数据源差异和基期差异范围内，模型可做到基期选择和指标统计完全准确；

分析覆盖度（77分）：核心指标召回较为全面（85%+），核心维度召回不全（～50%），单次执行时交叉分析和维度下钻次数受限、输出不稳定；

业务洞察力（33分）：趋势性洞察数量丰富但有效召回不足（～50%），贡献性洞察有但丰富度不足（<20%），关联性洞察基本没有（0%）；

文档可读性（100分）：模型可做到稳定输出分析所选当期和基期，同时按照总-分结构输出报告。

表 不同节假日场景下模型能力评测结果


数据准确性

     基期选择准确性

     指标统计准确性（共用）

分析覆盖度

     分析指标召回率（共用）

     分析维度召回率

     交叉分析维度得分

     维度下钻层级得分

业务洞察力

     趋势性洞察召回率

     贡献性洞察召回率

     关联性洞察召回率

文档可读性

     基期选择召回率

     结构合理度



关键技术迭代

跑通框架流程



优化 planning，确保包含节假日时间

增加子 Agent 分析方法论

增加子 Agent [output-structure]

优化取数工具、code工具的准确性

优化记忆管理模块，提升分步指令准确性，减少幻觉



通过prompt调优对分析深度（包括维度交叉分析和维度下钻分析两方面）进行了优化

提高复杂SQL取数能力

分析方法升级：支持下钻 和 多维分析

抽象table_analysis工具

数据准确性提升及报告产出稳定性提升

“爆发系数+业务量级” 作为知识给到大模型，辅助选择有价值的枚举值进一步下钻分析

通过SFT训练分析子agent模型推理、工具调用能力

取数准确性和指标口径迭代

维度下钻能力强化

架构说明：

层级上分为主Planner、子Agent和工具三层，工具绑定到子Agent上，主Planner调度子Agent完成任务，三者可以通过记忆模块共享必要记忆，过滤无用信息。

对于涉密数据及知识，均使用Friday本地部署的商用开源模型。按照任务类型不同，选择规划和分析能力更强的Deepseek-R1模型支持主Planner和分析子Agent；选择速度更快的Deepseek-V3模型来做最终文档的整合和撰写。

分析子agent中大模型对于工具调用（function call）结合分析过程中推理总结能力有Gap，因此将分析agent 抽象成 取数、代码生成等节点以及用于专门做表格分析的推理工具节点。


4.1 主Planner

主Planner 在框架中扮演着“大管家”的角色。其核心是将用户复杂的分析请求转化为一份清晰的、可执行的“任务账本”， 它可以将具体的任务分发给各子Agent，并参照动态更新的“编排进展账本”来引导、监控和调整整个分析流程，确保多步骤、多维度的分析任务能够系统、高效且准确地完成，并最终交付一个全面“分析报告”。

plan:
  create: |-
    为了满足这个请求，我们组建了以下团队：
    {{#team}}
    - {{id}}: {{description}}
    {{/team}}
    基于业务知识的领域分析框架：
    {{{RAG_Domain_AnalysisMethod}}}
    领域信息知识结束。
    根据团队组成、领域信息以及已知和未知的事实，请制定一个简短的要点计划来处理原始请求。请记住，不需要所有团队成员参与——团队成员的特定专业知识可能不需要完成这项任务。"""

  update: |-
    请简要解释上次运行中出了什么问题（失败的根本原因），然后制定一个新计划，其中应采取措施和/或提供一些提示来克服之前的挑战，尤其要避免重蹈覆辙。与之前一样，新计划应简洁明了，以要点形式表达，并考虑以下团队组成（请勿涉及任何其他外部人员，因为我们无法联系其他任何人）：
    {{#team}}
    - {{id}}: {{description}}
    {{/team}}

progress:
  create: |-
    请记住我们正在处理以下请求：
    {{{task}}}
    我们已经创建了以下计划：
    {{{plan}}}
    并且我们已经组建了以下团队：
    {{#team}}
    - {{id}}: {{description}}
    {{/team}}
    为了推进该请求，请回答以下问题，包括必要的推理过程：
    - 该请求是否已完全满足？（如果已完成则为True，如果原始请求尚未被成功且完整地解决则为False）
    - 是否在按计划列表进行？（如果是则为True，如果已经偏离原计划则为False）
    - 我们是否陷入循环，即重复相同的请求和/或得到相同的回复？循环可能跨越多个回合，并包括重复操作，例如多次上下滚动。
    - 我们是否在取得进展？（如果刚刚开始或最近的消息增加了价值，则为True；如果最近的消息显示陷入循环或存在重大障碍如无法读取所需文件，则为False）
    - 接下来应该由谁发言？（从以下选项中选择：{{{agentIds}}}）
    - 您会给这位团队成员什么指示或问题？（直接对他们说话，并包括他们可能需要的任何具体信息）
    请根据以下模式以纯JSON格式输出答案。JSON对象必须可直接解析。除了JSON外不要输出任何内容，并且不要偏离此模式：
    {
      "is_request_satisfied": {
        "reason": string,
        "answer": boolean
      },
      "is_following_plan":{
        "reason": string,
        "answer": boolean
      },
      "is_in_loop": {
        "reason": string,
        "answer": boolean
      },
      "is_progress_being_made": {
        "reason": string,
        "answer": boolean
      },
      "next_speaker": {
        "reason": string,
        "answer": string (从以下选项中选择: {{{agentIds}}})
      },
      "instruction_or_question": {
        "reason": string,
        "answer": string
      }
    }
    注意，如果没有历史对话信息或其他状态信息，说明请求尚未开始具体执行，当前处于任务初始阶段。

finalAnswer: |-
  我们正在执行以下任务：

  {{{task}}}

  我们已完成该任务。
  以上消息包含完成该任务所需的对话。
  根据收集到的信息，请提供对原始请求的最终答复。

  主Planner主要功能如下：

准备与知识获取：接收用户请求后，Planner 会查询知识库，获取与请求相关的指标定义、分析方法等背景信息，为后续制定任务清单提供专业支持。

任务清单的制定：基于用户请求和获取的知识，Planner 会引导LLM制定一份结构化的、多步骤的“任务账本 (Task Ledger)”。这份账本是整个分析任务的行动指南，明确了各分析步骤的主题和关键指标。

执行与监控： 任务清单账本一旦确立，Planner 就转入执行指挥与监控阶段；它会参照“任务账本”中当前待执行的步骤，决定下一步应由哪个智能体（专项分析子Agent 或 报告生成子Agent）承接工作。然后，它会向选定的智能体发出明确、聚焦的任务指令；Planner 会持续维护一个“编排进展账本 (Progress Ledger)”，动态记录任务的执行历史、当前状态（是否按计划进行、是否有进展、是否遇阻等）。

调整与优化（修正任务）：若“编排进展账本”显示执行不畅或任务清单不再适用，Planner 会启动调整。它会引导LLM分析问题原因，并据此修正“任务账本”或制定新的执行策略，以克服障碍。

4.2 数据分析Agent

该Agent负责应对每个专题的分析报告生成，可调用三种工具：取数工具(get_data)、代码工具(python_code)和表格分析(table_analysis)。

对于涉及复杂工具链调用、复杂分析逻辑的场景，模型能力有限，具体现象是随着分析层级变深，指令遵循能力明显变差。核心问题主要体现在三个方面：

LLM复述能力欠缺：对要求精准性极高的分析场景，对表格错误容忍程度极低。而经过大量对比实验，我们发现LLM 并不擅长复述表格和大段文本001-表格处理&复述能力实验。因此我们采取单独解读表格的处理方式，并对比了多种模型的解读效果009-table 解读能力对比，实现数据解读的可信度和专业度。

2. 工具调用以及解读效果变差：输入过长后，数据分析Agent调用Tool 时会出现大量幻觉，以及无依据的计算或分析：

--->"query":"对bi_query_75cc4fa4.xlsx文件执行以下操作：1.计算各BU的DAU贡献度=日均DAU(2025.5.1-5.5)/SUM(日均DAU) 2.计算交易频次=日均支付订单量/日均DTU 3.流量质量指数=0.4*访购率+0.3*用户ARPU+0.3*交易频次 4.筛选条件：DAU贡献度>5% & 实付GTV爆发系数>1.2 5.按流量质量指数倒序排列取TOP5，输出[业务BU,DAU贡献度,流量质量指数,实付GTV爆发系数]四列"

解决方案是减少 system prompt 的长度，为此我们使用消融 prompt 的方式，在不降低效果的前提下，尽可能减少 system prompt 的长度，例如006-子Agent Prompt 消融，经过上述优化 system prompt token 数量大幅降低（3w -> 1.5w），整个项目中进行多次prompt消融，保证 system prompt 长度不会过长。

3. 上下文堆叠导致分析崩溃现象：分析崩溃会使多 Agent 系统直接不可用。而且经过实践发现，这种“崩溃”会随着ReAct进一步变差，因此难以通过提示手段或反思机制来解决这种问题，唯一的方式是减少 user context，使模型不会因过长上下文而失控。解决方式是减少内循环和外循环的 user context 长度。

减少外循环  user context 长度：我们配合工程尝试了多种上下文处理方式，包括基于规则的裁剪、基于 LLM 的上下文压缩、结合裁剪+压缩等。在节假日场景中，不同章节之间分析相对独立，比如交易主题数据通常不会和流量主题数据重复分析，而是分别分析，基于这种共识，我们对数据分析Agent的 每一轮任务分析前，清空所有历史上文，这样保证了避免因 user context 输入过长导致初始时分析崩溃。

减少内循环  user context 长度：我们发现随着工具调用次数增多，消息会不断堆叠导致分析效果显著变差，因此也对历史工具调用的消息例如 JSON、失败消息等进行了裁剪，仅保留有效的如数据描述信息。

解决方案是将数据分析Agent与数据解读解耦，将原属于数据分析Agent的任务拆分成“表格分析”工具。每轮数据分析 Agent 进行工具调用时，表格分析工具会围绕相关主题对已经获取到的数据进行分析，输出报告片段。

为什么要使用工程化手段来保障报告的生成效果，而非利用LLM的总结摘要能力写报告？

数据处理能力：模型处理长上下文能力弱（各独立分析子报告汇总后长度过长）

信息丢失：LLM在一次处理中能够有效编码和理解的输入文本长度（即“上下文窗口”）是有限的。当输入的子报告总体量过大（数据表过多），超出此窗口限制时，模型可能无法完整、准确地保留所有输入信息，尤其是较早输入的内容，从而导致最终报告在内容覆盖上出现遗漏或偏差。

数据幻觉：在处理大规模、高信息密度的输入时，LLM存在一定概率生成与源数据不符、缺乏依据甚至凭空捏造的内容，这种现象被称为“幻觉”。对于以事实为基础、追求高度准确性的分析报告而言，任何形式的内容失实都是不可接受的。

数据输出能力：模型输出长文本能力弱

无法控制模型输出长度：LLM单次调用所能生成的文本长度通常存在一个实际的上限（实践发现，我们拿到3篇2K字的报告，要求模型汇总输出一个7K字的报告，但是实际上模型只能输出3K字）此外：对于需要生成篇幅较长、分析层次较深、结构复杂的综合报告，单一、泛化的指令难以精确控制其输出达到预期的篇幅、细节丰富度、逻辑深度和章节编排。此外，LLM的本质其实是一个“概率模型”，在进行长文本输出时，越到后面幻觉的可能会越大。

缺乏精细化的结构规划与风格定制能力：一份高质量的综合报告往往需要清晰的章节布局、统一的论证风格、明确的逻辑主线和突出的核心观点。简单的“整合并总结所有输入”这类指令，不足以引导LLM自主完成如此精细的报告规划和内容定制。

“生成报告Agent” 利用大模型的规划能力将一个复杂、庞大的报告生成任务，拆解为一系列更小、更易于管理、更可控的子任务。逐章节产出符合预期的中间结果，最终汇集成高质量的综合报告。

流程详解：

准备阶段：收集生成完整报告的所有原材料（各个表格分析的输出，即子报告）。

子报告摘要化：对每一份输入的子报告，引导LLM提炼出包含核心主题、关键发现和数据范围的结构化摘要。

章节结构设计：拥有全局视角，确保报告的逻辑性和完整性，并为后续每个章节确定依赖的原始“子报告”。

逐章节生成报告：

对于专题章节，在生成其内容时，会向LLM提供两个核心的上下文输入：

已生成的上文内容：即当前章节之前所有已完成章节的文本。

本章节所依赖的原始子报告（归属关系由“章节设计”确定）

“后置生成”摘要：借鉴了人类专业写作的常见实践，从直觉上看，人类自己本身通常也是在完成主体内容的撰写和梳理后，才回过头来撰写能够精准概括全文并吸引读者的引言或摘要。

集成与输出：将前序步骤中独立生成的各个组成部分按照预定的逻辑顺序和格式规范进行拼接组合。作为整个自动化报告生成流程的收尾环节，它将所有经过模块化、精细化处理的优质内容片段，整合成一份结构完整、内容连贯、格式统一的最终交付成果。


工具名称

简述

主要优化点

取数工具

取数工具能够深入理解用户意图，解读用户需求并完成查询，最终工具输出为S3 存储的xlsx格式文件，用于后续Agent分析。

为防止产生大查询，如果时间跨度过大，会自动进行时间分区截取，防止集群压力过大。

基于ReAct机制进行反思，遇到执行错误时会根据错误信息以及用户的意图进行自动修复，进行自动生成和查询，重试机制确保了服务稳定性。

根据召回的实体，匹配能支持查询的最小表集合，精简上下文，提升生成稳定性。

提取高频的复杂query的核心逻辑作为模板，通过向量匹配召回模板，大幅提升hard级别查询准确性、泛化性。

代码工具

生成Python统计或查询代码，并执行返回结果。支持各种主流库如 pandas、numpy、scikit-learn、statsmodels、scipy、nltk等，可以进行复杂的数据统计和分析操作。

代码安全检测：实现基于ast语法树分析的危险代码检测机制；第三方库白名单机制。

基于自定义进程池执行代码，解决数据量太大导致机器卡死的问题。

自动纠错机制：采用ReAct机制，从一步生成所有代码，修改为分单步执行，每一步执行之后观察结果再继续执行。执行python code 返回错误时，会将报错信息以及记忆做为上下文，再请求模型。

多结果、多模态输出：支持一个query返回多个结果（包括文本、图片、数据表等类型）。

支持多种任务：复杂计算、异常检测、预测分析、可视化。

表格分析

用于深度解读和分析的工具，能够对输入的数据文件进行深入解读和分析，从不同视角洞察数据含义，产生有洞察力的商业分析报告。工具通过LLM对数据进行专业分析并生成结构化的分析报告片段。

分析思路先验知识，通过 prompt 与商分分析习惯进行人类偏好对齐，保证分析思路的有效性。

返回表格分析调用次数，LLM 会根据数据的情况进行深入分析和关联性分析，但可能因分析深度过审导致执行时间过长以及分析结果无意义，通过返回消息中添加调用次数信息，帮助数据分析 agent 判断是否应该停止分析。

表格占位符，为了防止上下文过长以及LLM 不适合复述的特性（参 4.2 case 举例），通过表格占位符实现分析内容的传入，防止调用工具过程中的数据损失。

根据报告结果，给出后续分析行动建议，比如发现某个亮点需要下钻，表格分析工具会返回对应的下钻建议及理由，辅助数据分析Agent做出最佳分析路径的判断。


五、算法SFT进展

5.1 进展

根据多Agent框架方案及初步摸底，优先优化核心分析子agent模块，目标建设能够端到端思考、工具调用、反思的推理模型，内化节假日分析业务知识，减少框架prompt工程。

完成模型训练路径从报告撰写能力->端到端分析推理能力迭代，在分析子agent评测上超越deepseekv3、qwen3-32b模型，端到端评测逼近目前最好商业模型版本。


实验版本

数据

测试结果

v0.1.0

配合初版架构，训练分析子agent模型报告撰写能力，构造了人工完整数据（9 条） + 半合成数据（48 条） + 全合成数据（427 条）的SFT数据

长度分布gap明显：SFT模型生成报告长度贴近人工ground-truth，是通用baseline长度的 1/5

格式差异：SFT后，生成的报告经常描述与结论穿插着行文，更贴近人工数据，而其他 baseline 更多是总分总+规整的markdown

用词差异：SFT后，相比于 baseline 的平庸用词，观察到 SFT 模型会生成诸如“显示节日期间"变美经济"持续升温”的精彩表述

v0.2.1

基于 Holiday Data v0.2，初步进行“agent 伪链路 -> 合成取数结果 -> 合成code结果 -> 合成分析结果”的数据构造。

全部使用合成数据，总共～120 session，～1400 轮次（1400 条训练样本）

发现诸多LLM停不下来、模拟工具不好用、构造方式不对齐工程等问题

v0.2.2

继承 v0.2.2，新合成16 session，现在要求每个步骤的 think 中增加步骤数、重试次数的记录，增强模型对步骤的感知；

测试工具：最关键的取数工具换成了真实工具，调用api

LLM效果略有提升，但会出现【10/8】这种即使超过步骤数依旧进行的case

真实取数工具带来测试稳定性大幅提升

v0.2.3

【彻底换了数据】

获取到真正agent工程的调用日志，考虑直接做数据蒸馏（经过数据处理）；

训练数据量为 442 条，混入10多条之前from scratch 合成的报告生成的样本

能符合逻辑的执行子分析全链路

能 self-correct，能初步审视工具环节的结果是否符合预期

还是略停不下来（参见case）；但可以人为限制 readFile工具的最大调用次数（当前prompt里也是这个逻辑）

v0.2.4

数据继承v0.2.3，但解决了 v0.2.3 agent 链路无法正常结束的 bug（没有加入"[分析结束]"的训练样本）；

训练长度从16K扩充到24K

解决分析不终止问题，但偶尔存在提前终止、错误终止问题

v0.3.0

继承 v0.2.4，同时增加以下 feature：

增加 claude 合成的 agent 链路 ～ 400 条

增加规则过滤掉训练样本中连续调用 表格分析模型、前后发出重复query 的 bad case

增加 think / no think 输出格式，增强模型鲁棒性

节日场景 分析模型 SFT 测评

5.3 评测

完成节日场景下自研模型(分析子agent)端到端测评，自研模型得分 74 分，基本持平商业模型（70分/ qwq 76分）；

分析子agent在benchmark上比deepseek v3有一定优势（19：15），支持更丰富的下钻及多维分析

六、问题及对应解决思路

分类

现存问题

未来优化方向

框架层

分析执行时间过长：子Agent的各项任务均以串行方式执行，导致整体处理时间较长，影响系统响应效率。

结合LangGraph，使用LLM动态生成DAG再执行的方式，实现Agent和工具（Tools）的并行调用，提升系统处理效率与任务调度灵活性。

记忆共享机制不健全：尚不具备长期记忆能力，Agent之间的上下文信息通过硬编码规则共享。限制了Agent协作的灵活性和系统扩展性。

构建记忆服务模块，实现较为准确的记忆共享机制，并能够有效识别和记录用户偏好，为个性化服务提供数据支持。

AA之间通信问题：子Agent之间无法实现直接通信，所有信息均需通过Planner进行中转。可能导致信息在传递过程中出现损失，从而影响Agent协作效率和任务执行的准确性。

建立Agent间通信机制，确保各Agent之间的信息流转顺畅，提高协作能力，从而增强整体系统的智能水平与响应速度。

模型能力

分析子agent模型推理能力、复杂多轮调用工具能力长下文能力弱

通过知识蒸馏、复杂合数数据合成、长下文训练，提升分析子agent模型推理，探索端到端RL方案提升模型能力上限。

模型对业务知识内化不足，需要复杂Prompt、SOP，泛化性不足，撰写幻觉率高

沉淀场景业务知识，配合BA算法合成+人工review方式构建场景业务训练数据，内化复杂SOP，提升模型泛化性；通过continue train提升模型业务知识理解，降低幻觉率。

取数模块生成复杂SQL能力弱

针对BA取数特点，摸底外部开源SQL模型，训练适合BA场景的SQL-LLM

取数工具

起源部分的元数据对大语言模型（LLM）的适配性较弱，自建知识管理系统也尚不完善。可能导致LLM在处理相关任务时信息获取不充分，从而影响结果的准确性。

利用已建设的AI友好型元数据及相关服务，进一步完善取数所需的元数据体系和知识库，为高效、准确的数据获取提供基础支撑。

起源数据集已支持指标和维度的扩展，但nl2sql尚未具备对扩展规则的解析能力，仅能实现将直接绑定在表上的指标和维度与相应字段进行匹配。这一限制影响了复杂场景下的数据灵活获取与管理。

魔数的指标维度仓库服务已实现对数据集扩展指标和维度的解析能力，可在取数过程中复用，从而有效提升数据查询的灵活性与系统的扩展性。

nl2sql、nl2param和智能答疑等自然语言取数功能分别分散在不同的入口，尚未实现统一对外提供一站式能力。这种分散的服务模式不利于用户体验提升，也影响了系统整体的集成效率。

联动“魔数”等团队，构建统一的取数Agent入口。该入口集成nl2sql、nl2param以及智能答疑等功能，实现一站式数据查询与交互体验。



评测体系

目前评测体系以及评测问题集设计均主要适配于当前分析Agent能力发展阶段而构建，如关联性洞察相关题目偏少、未涉及性能与体验维度、重点关注召回率等，后续需根据模型能力迭代而调整。

持续动态迭代评测体系，包括评测指标体系、评测问题集、以及评分标准。考察覆盖的功能维度，将视分析Agent能力迭代而扩充；此外评分标准也将由重点考察召回率评估大模型的完成度改为综合考察准确率和召回率。

评测环节标注人力投入较大，随着模型频繁的持续迭代，投入资源及时效性均需要优化。

借助大模型替代人工标注目前已实现标注率90%+，准确率80%+，初步应用于标注环节，实现评测的半自动化，提效约40%。后续进一步提升大模型标注召回率与准确率，实现评测自动化。同时，为提升评测的及时性，期望将智能化评测系统与分析Agent打通，串行输出分析报告的评测结论与优化方向，帮助分析Agent高效自迭代。