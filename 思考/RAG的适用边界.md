---
title: RAG 的适用边界
type: 思考
date: 2026-02-26
tags:
  - ai/rag
  - 思考/技术决策
  - ai/llm/application
---

# RAG 的适用边界

## RAG 真正解决的问题

RAG 解决的核心问题只有一个：**让 LLM 在生成时访问它训练数据之外的信息**。

这个定义比大多数人理解的要窄。RAG 不解决推理能力问题，不解决格式定制问题，不解决领域术语理解问题。它只做一件事——把相关的外部文本塞进 prompt，让模型「开卷考试」。

开卷考试的价值取决于三个前提：

1. **答案确实存在于你的文档中**——如果知识只存在于模型参数里（如通用常识），RAG 是多此一举
2. **检索能找到正确的文档**——如果语义鸿沟太大，检索不到就等于没有
3. **模型能理解并正确使用检索到的内容**——塞了 context 不代表模型会用

三个前提任何一个不成立，RAG 就失效。

## Naive RAG 和 Advanced RAG 的本质区别

Naive RAG 的管线是：`query → embedding → 向量搜索 Top-K → 拼进 prompt → 生成`。

这个管线的隐含假设是：**用户的 query 和文档的语义表达是对齐的**。现实中这个假设几乎不成立。用户说「这个功能怎么用」，文档写的是「API Reference: POST /v2/features」。Naive RAG 找不到。

Advanced RAG 的本质不是「加了更多组件」，而是**承认并修补这个语义鸿沟**：

- **Query Rewrite / HyDE**：把用户的口语化问题翻译成文档的「语言」
- **Hybrid Search**：向量搜索抓语义，BM25 抓关键词，两条腿走路
- **Reranking**：粗排召回 100 个，精排挑出真正相关的 5 个
- **Parent-Child Chunking**：用小块检索保精度，用大块送入模型保上下文

每一步都在解同一个问题：**让检索更准**。RAG 系统 80% 的质量由检索质量决定，不是由 LLM 决定。

## 向量检索的三个致命局限

向量检索在很多场景下是 RAG 的瓶颈，不是解法：

**1. 精确匹配无能**
向量检索做的是「语义相似度」，不是「精确匹配」。搜产品型号 "iPhone 15 Pro Max"、法律条文编号 "第 42 条第 3 款"、报错码 "ERR_SSL_PROTOCOL_ERROR"——这些场景 BM25 碾压向量搜索。这就是 Hybrid Search 成为生产标配的原因。

**2. 全局问题束手无策**
「这份年报的核心结论是什么？」——答案分散在整篇文档的不同段落中，没有单一 chunk 包含完整答案。向量检索找到的是局部碎片，不是全局概括。这正是 Graph RAG 试图解决的——用社区摘要提供全局视角——但代价是知识图谱的构建和维护成本极高。

**3. 多跳推理不可达**
「A 公司 CEO 的母校在哪个城市？」需要三跳：A 公司 → CEO 是谁 → 母校 → 城市。向量检索是单跳的，一次检索找不到完整的推理链。Agentic RAG（如 Self-RAG、CRAG）通过多轮自适应检索来缓解，但本质上是把简单架构变成了复杂的 Agent 系统。

## RAG vs Fine-tune：选型决策框架

这两个不是竞争关系，是解决不同问题的：

| 你的需求 | 选 RAG | 选 Fine-tune | 两者结合 |
|---------|--------|-------------|---------|
| 让模型知道私有数据的内容 | ✅ | ❌ | — |
| 让模型用特定格式/风格回答 | ❌ | ✅ | — |
| 让模型理解领域术语 | ❌ | ✅ | — |
| 知识频繁更新 | ✅ | ❌ | — |
| 需要 citation 溯源 | ✅ | ❌ | — |
| 领域专业 + 数据实时 | — | — | ✅ |

一个简单的判断标准：**如果你的问题本质是「模型不知道某个信息」，用 RAG；如果本质是「模型知道但表达方式不对」，用 Fine-tune。**

## 什么情况下 RAG 是错误答案

以下场景如果还在用 RAG，说明方向走偏了：

1. **文档量可控、不更新**——一份合同、一篇论文。直接塞进长上下文窗口，比 RAG 简单十倍，效果更好
2. **问题需要推理而非检索**——数学证明、逻辑推导、代码 debug。这些问题的答案不在任何文档里，而在模型的推理能力里
3. **知识已经在模型参数中**——问「什么是光合作用」不需要 RAG，GPT-4 训练时就学过了
4. **数据高度结构化**——表格数据、数据库。Text-to-SQL 比 RAG over 序列化表格精确得多
5. **对延迟极端敏感**——检索 + Reranking + LLM 生成的完整管线，P99 很难压到 200ms 以下。如果产品要求实时响应，RAG 的延迟可能不可接受

## 结论

RAG 不是万能药。它是一个特定问题（让 LLM 访问外部知识）的工程方案，有明确的适用边界。把 RAG 用在正确的地方，它是最成熟的 AI 应用架构之一；用在错误的地方，它就是一个过度工程化的 prompt stuffing。

做技术决策的第一步不是选什么架构，而是问清楚：**你的问题到底是知识缺失、推理不足、还是表达不对？** 答案不同，路径完全不同。
