---
title: 多Agent协作的核心设计问题
type: 思考
date: 2026-02-26
tags:
  - ai/agent
  - multi-agent
  - 系统设计
  - type/思考
---

# 多Agent协作的核心设计问题

## 一句话判断

**多Agent系统的核心矛盾不是"怎么让Agent协作"，而是"什么时候值得付出协作的代价"。** 大多数场景，一个好Agent + 好Prompt + 好工具，胜过一群平庸Agent的喧嚣。

---

## 多Agent协作为什么难

不是技术问题，是系统复杂性问题。本质上和管理一个团队一样难，且多了几个特有的坑：

| 困难 | 本质原因 | 工程后果 |
|------|---------|---------|
| **推理链断裂** | Agent A 的输出是 Agent B 的输入，每一跳都有信息损耗 | 5个Agent串联，每步95%准确率 → 总体77%，比单Agent还差 |
| **幻觉传播** | Agent不会说"我不确定"，下游Agent把幻觉当事实引用 | 最终输出看似"多方验证"，实则错误被逐步强化 |
| **通信开销吞噬收益** | Agent间传递的context本身消耗token，且大量是冗余的 | 多Agent的token消耗是单Agent的3-10x，大部分花在"互相解释" |
| **涌现不可控** | 群体行为无法从个体行为推导 | 群体极化、社交惰化、共谋——在LLM Agent中已被实验验证 |

**关键洞察**：人类团队之所以能协作，是因为有共享常识、文化规范、反馈信号（表情、语气）。LLM Agent之间靠文本传递的"共识"极其脆弱——它们没有真正的"理解"，只是在传递token。

---

## 通信拓扑：一张表说清本质权衡

选拓扑不是技术选型，是**你愿意为全局最优付出多大的延迟和脆弱性代价**。

| 拓扑 | 通信量 | 核心优势 | 致命缺陷 | 什么时候选 |
|------|--------|---------|---------|-----------|
| **集中式（Orchestrator）** | O(n) | 全局视角，决策最优 | 单点故障 + Orchestrator自身成为瓶颈 | Agent<10，流程明确，需要可预测性 |
| **去中心化（P2P）** | O(n²) | 无单点故障，容错强 | 无法保证全局一致性，可能死锁 | 对抗/辩论，或不信任任何中心节点 |
| **层级式（Hierarchical）** | O(n log n) | 模拟真实组织，信息逐层压缩 | "传话游戏"——每层都有信息失真 | Agent 10-50，有明确的层级分工 |
| **混合式** | 可变 | 灵活，局部最优 | 实现复杂度最高 | **2026生产环境的事实标准** |

**我的判断**：2026年没有人在生产中用纯去中心化架构。全连接P2P的O(n²)通信开销在LLM场景下完全不可承受——每次"通信"都是一次昂贵的LLM调用。混合式（全局集中路由 + 子团队内灵活通信）是唯一务实的选择。

---

## 角色分工 vs 能力复用：一个被忽略的设计决策

大部分框架（CrewAI、MetaGPT）默认走"角色分工"路线——给每个Agent一个profile和backstory。但这里有一个根本性的问题：

**角色分工的隐含假设是Agent真的拥有差异化能力。但当所有Agent背后都是同一个LLM时，"角色"只是system prompt的区别。**

| 策略 | 逻辑 | 真正的优势 | 陷阱 |
|------|------|-----------|------|
| **角色分工** | 每个Agent有明确职责，减少歧义 | 缩小了每个Agent的上下文空间，减少干扰 | 角色边界模糊时反复推诿；过度特化导致灵活性丧失 |
| **能力复用** | 同构Agent，按任务动态分配 | 可水平扩展，负载均衡简单 | 缺乏专业化，每个Agent都"什么都会一点" |
| **混合（正确答案）** | 核心差异化能力用专业Agent，通用任务用同构池 | 兼顾专业深度和弹性 | 需要智能的路由决策 |

**工程判断**：角色分工的真正价值不是"Agent扮演不同角色"，而是**限制上下文范围**。一个"只看安全问题"的Agent比"什么都看"的Agent在安全审查上表现更好，不是因为它更聪明，而是因为它的attention不需要分散。

---

## 什么时候多Agent反而不如单Agent

这是最重要的判断，也是最多人忽略的。

**多Agent有负收益的场景：**

1. **任务高度耦合，无法有效分解**
   - 例：写一篇2000字的连贯文章。你可以让3个Agent分别写开头/中间/结尾，但拼起来的文章几乎一定比一个Agent从头写的差。

2. **延迟敏感（<3秒响应）**
   - 多Agent最少也是2-3次串行LLM调用。每次调用1-3秒，加上通信开销，总延迟轻松超过10秒。

3. **成本预算有限**
   - 3个Agent的简单协作 ≈ 单Agent成本的5-8倍（包括Orchestrator的决策开销）。

4. **团队缺乏分布式系统经验**
   - 多Agent系统的调试复杂度不是线性增长，是指数增长。3个Agent的交互路径有6种，5个有20种。

**判断公式**：

> **如果单Agent + 好的工具链能在合理token预算内完成任务 → 不要用多Agent。**
> **只有当任务的并行度、专业化需求或上下文规模确实超出单Agent能力边界时，多Agent才有正收益。**

---

## 框架选型：不是选框架，是选抽象层级

| 你需要什么 | 选什么 | 为什么 |
|-----------|--------|--------|
| 快速原型，验证想法 | CrewAI | API最简，半天能跑起来 |
| 生产级复杂流程（分支/循环/人工审批） | LangGraph | 唯一真正支持任意图结构 + checkpoint + HITL |
| 对话驱动的协作 | AutoGen v0.4 | GroupChat + 分布式运行时 |
| SOP驱动的软件工程 | MetaGPT | Pub-Sub模式天然适合瀑布流 |
| 理解多Agent设计模式 | Swarm（教学用） | 500行代码讲清Handoff模式 |

**我的判断**：LangGraph是2026年生产级多Agent编排的事实标准。不是因为它最好用（它学习曲线最陡），而是因为**只有它提供了任意流程控制 + 状态持久化 + 人工审批**这三个生产必需品。

---

## 安全：多Agent系统的阿喀琉斯之踵

多Agent把单Agent的安全问题放大了一个数量级：

| 威胁 | 单Agent | 多Agent（为什么更严重） |
|------|---------|----------------------|
| Prompt Injection | 攻击者 → Agent | 攻击者 → Agent A → **传播到** Agent B/C/D |
| 幻觉 | 一个错误输出 | 幻觉在Agent间传播并被"交叉引用"，看起来像多方验证 |
| 权限滥用 | 一个Agent的权限 | 低权限Agent通过高权限Agent间接执行特权操作 |
| 调试难度 | 线性 | 指数（n个Agent的交互路径 = n!） |

**核心防御原则**：

1. **永远不信任来自其他Agent的输入**——当它是外部用户输入处理
2. **权限不可升级**——子Agent权限 ⊆ 父Agent权限，用代码强制，不靠prompt
3. **委托链深度限制**——最多3跳，每跳信任自动衰减

---

## 落地箴言

> 1. **从1个Agent开始**。先证明价值，再加复杂度。
> 2. **可观测性是Day 0的事**，不是Day 30。多Agent系统不可观测 = 不可调试 = 不可运维。
> 3. **成本模型先算清**。3个Agent用Opus协作 vs 1个Agent用Opus + 好工具，后者几乎总是更优。
> 4. **人在回路不是妥协，是设计**。2026年没有任何多Agent系统能在高风险场景无人值守。
> 5. **混合式是唯一的生产答案**。全局路由 + 子团队灵活协作 + 简单任务用小模型。

---

## See Also

- AI-Agent-2026-技术全景 — Agent基础概念
- [[思考/对齐问题的本质]] — Agent安全的上游问题
- LLM工具调用与Function-Calling-2026技术全景 — 工具调用是多Agent的基础设施
