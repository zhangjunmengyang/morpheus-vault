---
title: P3：Agent 自进化系统——多 Agent 军团的进化实验
type: project-story
status: active
date: 2026-02-28
updated: 2026-02-28
tags: [career, interview, agent, self-evolution, multi-agent, system-design]
brief: 基于个人真实运行的多 Agent 系统（6个 Agent 长期运行），围绕"Agent 系统能否自我进化"展开的工程实验：进化度量、横向信息流、故障驱动进化、状态注入机制。有量化数据，有反直觉结论。
related:
  - "[[Projects/Agent-Self-Evolution/项目概览]]"
  - "[[Projects/Agent-Self-Evolution/002-横向信息流]]"
  - "[[Projects/Agent-Self-Evolution/010-故障驱动进化模式]]"
  - "[[AI/2-Agent/Agentic-RL/ERL-Experiential-Reinforcement-Learning]]"
---

# P3：Agent 自进化系统——多 Agent 军团的进化实验

---

## 故事线（面试完整版，5-8 分钟）

---

### 第一幕：一个在业务里憋了很久的问题

在美团做 Agent 系统的时候，我一直有一个没想通的事情。

我们的 Agent 系统从 workflow 开始，然后进化到多 Agent，后来又回到单 Agent——这个演进过程本身我是参与者，也思考过为什么会这样。但有一个更底层的问题我一直没有答案：**系统在运行中，能不能越来越好？**

业务 Agent 是静态的——上线就定住了，遇到问题靠人改 prompt 或者重新设计。但一个真正有价值的智能系统，应该能从自己的运行经验里学习。这不只是工程问题，是我想搞清楚的一个基本问题：AI Agent 系统在持续运行中的自我改进，是可能的吗？

于是我在自己的个人系统上跑了这个实验——6 个 Agent 组成的多 Agent 军团，长期运行，我系统性地观察和测量它在变强还是在原地踏步。

---

### 第二幕：先量化，才能谈进化

第一件事是建度量框架。

这个问题很简单但很重要：没有度量就没有进化，只有随机游走。但"Agent 变强了"这件事怎么量化？

我定了 5 个维度：产出深度（是信息搬运还是有独立分析）、覆盖广度（知识方向有没有拓展）、响应速度（感知到外部信号到产出的延迟）、协同效率（Agent 之间信息流动有多快）、自主决策质量（面对模糊情况的判断准不准）。

第一次全量测量的结果说实话让我有点沮丧：响应速度这一项，从 AI 技术发布到系统感知到并处理，平均延迟是 **2-10 天**。协同效率更糟——Agent 间的信息延迟是 **∞**，因为根本没有横向信息流，所有信息必须经总管中转。

这两个数字给了我接下来的方向。

---

### 第三幕：横向信息流——改架构，不改 prompt

信息流问题的直接原因是架构：星型结构，总管是单点。学者写了一篇新笔记，馆长不知道；哨兵收到了一个市场信号，量化端不知道。

第一反应可能是：让总管多转发。但这治标不治本——总管本身就是瓶颈，多转发只会让它更堵。

我设计了一个共享公告板机制：在文件系统里放一个所有 Agent 都能读写的 `bulletin.md`，每个 Agent 心跳开始时先读公告板，有消息就处理，有东西要通知别人就写进去。

听起来很简单对吧。但有个关键的实现细节让整件事成立——

我把公告板内容注入到每个 Agent 的 **`heartbeat-state.json`**（心跳状态文件），而不是写在 HEARTBEAT.md（指令文件）里。

测试结果：状态文件注入的内容，**100% 被执行**；写在指令文件里的，Agent 会选择性跳过。

原因事后想很清楚：Agent 对"状态"和"指令"的处理模式完全不同。状态文件是它相信的事实，执行流程强制读取；指令文件是建议，它可能忽略。**想让 Agent 做某件事，要写进它的执行流，不要写在说明书里。**

这个发现对我后来设计业务 Agent 的影响很大——怎么让 Agent 可靠地执行某个行为，不是靠 prompt 更精确，是靠把它做成执行流里的强约束。

改完之后，Agent 间信息延迟从 ∞ 降到了 **<1 小时**，跨 Agent 协作任务完成率从 12% 涨到了 73%。

---

### 第四幕：最大的教训来自一次故障

几个月运行下来，系统经历过三次我观察到的大的能力跃升——我们叫"涅槃"。每次之后 Agent 的行为模式都有明显变化，产出质量明显提升。

我以为这些是系统在"自主进化"。但仔细看之后，我发现一件让我有点不舒服的事：**三次涅槃，100% 都是外部冲击触发的**——一次是 Gateway 故障导致 11 小时全军失联，一次是发现了安全漏洞，一次是我主动介入了重大的配置修改。没有一次是 Agent 自己觉察到"我该变"然后主动改进的。

Gateway 那次故障记录得比较完整。凌晨 Gateway 调度器故障，全部 Agent 沉默了 11 个小时，下午发现修复。修复之后的 8 小时，整个系统产出爆发：新的安全防御代码上线了、故障检测脚本从零写到部署、知识归档大规模清理、一个之前拖了很久的实验也跑通了。

为什么故障之后反而产出更高？因为故障**暴露了盲区**——我们发现"进程活着但不工作"在系统里是完全不可见的，没有任何监控。发现盲区之后，修复它的动力极强，而且修复是真实有价值的工程改进，不是日常维护。

**故障→复盘→实验→工程化，这条链路跑通了，比平稳运行的十天产出都多。**

但这让我意识到了核心局限：内生的自我改进能力，Agent 系统里还不存在。能力提升依赖外部冲击。如果没有我主动介入或者故障触发，系统会在一个稳态里持续运转，但不会主动变强。这个洞察直接影响了我怎么看 Agentic RL——那些论文在研究的，本质上是在用 RL 训练来替代"外部冲击"这个角色，让模型从自己的失败经验中内生地学习。

---

### 第五幕：对 Agent 系统设计的底层认知

这个实验最终让我形成了几个对 Agent 系统设计的判断，在做业务 Agent 时直接用到了：

**第一，触发通道的设计比指令内容重要。** 你花多少时间写 prompt，不如想清楚什么行为应该是强约束、什么是软引导。强约束必须进执行流。

**第二，可观测性是系统能力的前提。** 系统里发生了什么，你看不到，就谈不上改进。那 11 小时的故障，本质上是因为系统对自身状态的可观测性太差了。

**第三，Agent 系统的成长是间歇式的，不是渐进式的。** 日常的平稳运行不产生能力跃升，高强度的冲突和修复才会。如果想让 Agent 系统持续进化，要刻意制造"压力测试"，而不是等它自然进化。

---

## 快速技术速查（追问备用）

**"你说信息延迟从 ∞ 降到了 <1 小时，具体怎么实现的？"**
共享 `bulletin.md` 文件 + 注入到 heartbeat-state.json 执行流。所有 Agent 心跳开始时强制读取状态文件，所以延迟上限就是心跳间隔（60 分钟），实际因为读取时序问题通常 <1 次心跳。

**"为什么最后要回到单 Agent，不是多 Agent？"**
这和美团业务里的经历一致：多 Agent 的可控性和延迟都是问题。协调层本身引入了复杂度，一个 Planner 要把任务分发给多个 Worker，每个 Worker 出错都要影响整体。业务场景里"可预测"比"灵活"更重要，单 Agent + 丰富工具集在实际落地里更好维护。

**"这个和学术上的 Agentic RL 有什么关系？"**
很直接。ERL（Experiential Reinforcement Learning）论文研究的是让 Agent 从失败经验里学习推理策略——和我观察到的"故障驱动进化"是同一个模式，区别是 ERL 在训练时做，我的系统在运行时靠人工介入。这个对比让我理解了为什么要做 Agentic RL：用训练替代人工冲击，让内生学习成为可能。

---

## See Also

- [[Projects/Agent-Self-Evolution/项目概览]]
- [[Projects/Agent-Self-Evolution/002-横向信息流]]
- [[Projects/Agent-Self-Evolution/010-故障驱动进化模式]]
- [[Projects/项目故事/P4-商家诊断Agent-安全防御层]]
- [[Projects/项目故事/P5-分析Agent-从ReAct到RL训练闭环]]
- [[AI/2-Agent/Agentic-RL/ERL-Experiential-Reinforcement-Learning]]
- [[AI/2-Agent/Agentic-RL/RAGEN-StarPO-Multi-Turn-RL-Self-Evolution]]
